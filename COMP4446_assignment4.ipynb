{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4a395e-cb52-4e26-95ca-df5a22c2e77f",
   "metadata": {},
   "source": [
    "# COMP4446 Assignment4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10852205-1d16-4300-9995-491fcba72f73",
   "metadata": {},
   "source": [
    "Team Member: cche0200 zhua0621"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12531a0-82d5-4662-810e-cd4698f89753",
   "metadata": {},
   "source": [
    "*Note: The code for exploring experiment is located at the bottom of this document*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66558c-b5f3-49a8-b32c-501eae976341",
   "metadata": {},
   "source": [
    "## Task1 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96b9cae-8123-4c55-a69a-8d9e051c76fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72a6e2c-e12a-4ab9-8aa0-e2f6ce660d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d6b23b-5c24-4ff9-a16e-5a06c71465cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class atisDataProcessor:\n",
    "    def __init__(self, data_file, type_file, glove_path):\n",
    "        # Tags Loading\n",
    "        # self.variable_names = []\n",
    "        self.var2idx = {}\n",
    "        self.idx2var = {}\n",
    "        self.var2idx[\"-\"] = 0 # Add additional variable \"-\" as other type\n",
    "        self.idx2var[0] = \"-\"\n",
    "        self.var_idx = 1\n",
    "        self.var2dtype = {}\n",
    "\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        # print(f\"{self.idx2var}\")\n",
    "        # print(f\"{self.var2idx}\")\n",
    "        self.name2idx = {} # tags mapping\n",
    "        self.idx2name = {}\n",
    "        self.name_idx = 2\n",
    "        self.name2idx[\"-\"] = 0\n",
    "        self.idx2name[0] = \"-\"\n",
    "        self.name2idx[\"PAD\"] = 1\n",
    "        self.idx2name[1] = \"PAD\"\n",
    "        \n",
    "        self.word2idx = {} # word mapping\n",
    "        self.idx2word = {}\n",
    "        self.word_idx = 1\n",
    "        self.word2idx[\"PAD\"] = 0\n",
    "        self.idx2word[0] = \"PAD\"\n",
    "        self.word2idx[\"UNK\"] = 1\n",
    "        self.idx2word[1] = \"UNK\"\n",
    "        \n",
    "        self.template2idx = {} # sql template mapping\n",
    "        self.idx2template = {}\n",
    "        self.template_idx = 0\n",
    "        self.var2dtype = {} # variable & datatype mapping\n",
    "        \n",
    "        self.train_data = [] # Training Dataset\n",
    "        self.dev_data = [] # Dev Dataset\n",
    "        self.test_data = [] # Testing Dataset\n",
    "\n",
    "        with open(type_file, 'r', encoding='utf-8') as tf:\n",
    "            print(f\"Loading datatype of variables for additional information on learning...\")\n",
    "            next(tf)\n",
    "            for line in tf:\n",
    "                parts = line.replace(\",\", \"\").strip().split()\n",
    "                self.var2dtype[parts[1].lower()] = parts[-1].lower()\n",
    "                # print(f\"Loading new datatype {parts[1].lower()} : {parts[-1].lower()}\")\n",
    "            type_set = sorted(set(self.var2dtype.values()))\n",
    "            self.dtype2idx = {t:i for i, t in enumerate(type_set)}\n",
    "            self.idx2dtype = {i:t for t, i in self.dtype2idx.items()}\n",
    "        # print(self.dtype2idx)\n",
    "        # print(self.var2dtype)\n",
    "        with open(data_file, 'r', encoding='utf-8') as df:\n",
    "            print(f\"Loading all data in json...\")\n",
    "            dataset = json.load(df)\n",
    "            print(f\"Loading sql template...\")\n",
    "            for obj in dataset:\n",
    "                template = min(obj['sql'], key=len)\n",
    "                template_with_default = []\n",
    "                template_with_default.append(template)\n",
    "                for var, value in obj['sentences'][0]['variables'].items():\n",
    "                    template_with_default.append({var: value})\n",
    "                if template not in self.template2idx:\n",
    "                    self.template2idx[template] = self.template_idx\n",
    "                    self.idx2template[self.template_idx] = template_with_default\n",
    "                    self.template_idx += 1\n",
    "                    # print(f\"add a new template: {self.template_idx}\")\n",
    "                    # print(f\"{template_with_default}\")\n",
    "            print(len(self.template2idx))\n",
    "            self.template_classes = len(self.template2idx)\n",
    "            var_type = {}\n",
    "            print(f\"processing samples...\")\n",
    "            for obj in dataset:\n",
    "                # split = obj['query-split'] # split method for query split\n",
    "                for v in obj['variables']:\n",
    "                    var_type[v['name']] = v['type'].lower()\n",
    "                    if v['type'] not in self.var2idx:\n",
    "                        self.var2idx[v['type']] = self.var_idx\n",
    "                        self.idx2var[self.var_idx] = v['type']\n",
    "                        self.var_idx += 1\n",
    "                    if v['name'] not in self.name2idx:\n",
    "                        self.name2idx[v['name']] = self.name_idx\n",
    "                        self.idx2name[self.name_idx] = v['name']\n",
    "                        self.name_idx += 1\n",
    "                \n",
    "                for sentence in obj['sentences']:\n",
    "                    split = sentence['question-split'] # split method for question split\n",
    "                    for var in sentence['variables'].keys():\n",
    "                        self.nlp.tokenizer.add_special_case(var, [{ORTH: var}]) # add variable to special case preventing tokensisation \n",
    "                    text = sentence['text']\n",
    "                    doc = self.nlp(text)\n",
    "                    tokens = [tok.text.lower() for tok in doc]\n",
    "                    labels = [self.name2idx['-']] * len(tokens)\n",
    "                    types = [self.var2idx['-']] * len(tokens)\n",
    "                    dtypes = [self.dtype2idx[self.var2dtype['-']]] * len(tokens)\n",
    "                    template_variables = sentence['variables']\n",
    "                    for i, tok in enumerate(tokens):\n",
    "                        if tok in var_type and var_type[tok] in self.var2idx:\n",
    "                            labels[i] = self.name2idx[tok]\n",
    "                            dtypes[i] = self.dtype2idx[self.var2dtype[var_type[tok]]]\n",
    "                            types[i] = self.var2idx[var_type[tok]]\n",
    "                        tokens_sp = [sentence['variables'].get(tok, tok) for tok in tokens]\n",
    "                        template_id = self.template2idx[min(obj['sql'], key=len)]\n",
    "                        sample = {'tokens': tokens_sp, 'vars': labels, 'type':types, 'dtype': dtypes, 'template': template_id, 'variables': template_variables, 'split': split}\n",
    "                        # structure of samples:\n",
    "                        # tokens: texts with tokenisation(SpaCy) and word embedding(GloVe)\n",
    "                        # vars: tags of each word(default: '-') with name2idx mapping\n",
    "                        # types: type of each word(default: '-') with var2idx mapping\n",
    "                        # dtypes: datatype of each word(default: '-') with dtype2idx mapping for additional information support\n",
    "                        # template_id: SQL template of each text, as there is probably more than one template for a text, I store the (question, sql) template with full connection\n",
    "                        # split: reference by query-split/question split for dividing samples to diff datasets\n",
    "                        # print(f\"Add a new sample with {split}: {sample}\")\n",
    "                        if split == 'train':\n",
    "                            self.train_data.append(sample)\n",
    "                        elif split == 'dev':\n",
    "                            self.dev_data.append(sample)\n",
    "                        elif split == 'test':\n",
    "                            self.test_data.append(sample)\n",
    "                        else:\n",
    "                            print(f\"this sample not belongs to any dataset, adding it to training dataset..\")\n",
    "                            self.train_data.append(sample)\n",
    "            print(f\"length of training set: {len(self.train_data)}\")\n",
    "            print(f\"length of training set: {len(self.dev_data)}\")\n",
    "            print(f\"length of training set: {len(self.test_data)}\")\n",
    "        \n",
    "        \n",
    "        self.wordmapping()\n",
    "        self.glovemapping()\n",
    "\n",
    "\n",
    "    def wordmapping(self):\n",
    "        # traverse all samples to construct vocabulary graph and mapping to index\n",
    "        for sample in self.train_data:\n",
    "            for token in sample['tokens']:\n",
    "                if token not in self.word2idx:\n",
    "                    self.word2idx[token] = self.word_idx\n",
    "                    self.idx2word[self.word_idx] = token\n",
    "                    self.word_idx += 1\n",
    "                    # print(f\"add a new word: {token}\")\n",
    "\n",
    "    def glovemapping(self):\n",
    "        # using GloVe for embedding word vectors\n",
    "        glove_dict = {}\n",
    "        with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i == 0: dims = len(line.split()) - 1\n",
    "                parts = line.strip().split()\n",
    "                word = parts[0]\n",
    "                vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float)\n",
    "                glove_dict[word] = vec\n",
    "        vocab_size = len(self.word2idx)\n",
    "\n",
    "        self.embedding_matrix = torch.randn(vocab_size, dims) * 0.1\n",
    "        self.embedding_matrix[0] = torch.zeros(dims)\n",
    "        for word, idx in self.word2idx.items():\n",
    "            if word in glove_dict:\n",
    "                self.embedding_matrix[idx] = glove_dict[word]\n",
    "        del glove_dict\n",
    "\n",
    "    def getDataLoader(self, split=\"train\", batch_size=32, shuffle=True):\n",
    "        # return specific dataloader\n",
    "        if split == \"train\":\n",
    "            dataset = TextDataset(self.train_data)\n",
    "        elif split == \"dev\":\n",
    "            dataset = TextDataset(self.dev_data)\n",
    "        elif split == \"test\":\n",
    "            dataset = TextDataset(self.test_data)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown split: {}\".format(split))\n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=self.collate_fn)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        max_len = (max(len(sample[\"tokens\"]) for sample in batch))\n",
    "        word_idx = torch.zeros(batch_size, max_len, dtype=torch.long)  # word2idx[0] = PAD\n",
    "        label_idx = torch.full((batch_size, max_len), fill_value=-100, dtype=torch.long) # labels of each word\n",
    "        type_idx = torch.zeros(batch_size, max_len, dtype=torch.long)   # type of labels\n",
    "        dtype_idx = torch.zeros(batch_size, max_len, dtype=torch.long)  # datatype of types\n",
    "        class_labels = torch.zeros(batch_size, dtype=torch.long)        # SQL template of each sample\n",
    "        for i, sample in enumerate(batch):\n",
    "            seq_len = len(sample[\"tokens\"])\n",
    "            for j, token in enumerate(sample[\"tokens\"]):\n",
    "                word_idx[i, j] = self.word2idx.get(token, self.word2idx['UNK'])\n",
    "            label_idx[i, :seq_len] = torch.tensor(sample[\"vars\"], dtype=torch.long)\n",
    "            type_idx[i, :seq_len] = torch.tensor(sample[\"type\"], dtype=torch.long)\n",
    "            dtype_idx[i, :seq_len] = torch.tensor(sample[\"dtype\"], dtype=torch.long)\n",
    "            class_labels[i] = sample[\"template\"]\n",
    "        return word_idx, label_idx, type_idx, dtype_idx, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9b390ef-0ec2-4312-af0b-095ef3dd78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9bd142-34a8-4cf6-a50e-8cad81707b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModels(nn.Module):\n",
    "    \"\"\"\n",
    "    models for classification task:\n",
    "    Linear:\n",
    "    FFN:\n",
    "    LSTM:\n",
    "    Transformer:\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_matrix, type_vocab_size, dtype_vocab_size, type_emb_dim=50, dtype_emb_dim=50, \n",
    "                 model_type=\"linear\", hidden_dim=128, template_classes=0, tag_classes=0, num_layers=1, nhead=4):\n",
    "        super(ClassificationModels, self).__init__()\n",
    "        self.model_type = model_type\n",
    "        vocab_size, word_emb_dim = embedding_matrix.size()\n",
    "        self.word_emb = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=0)\n",
    "        self.type_emb = nn.Embedding(type_vocab_size, type_emb_dim, padding_idx=0)\n",
    "        self.dtype_emb = nn.Embedding(dtype_vocab_size, dtype_emb_dim, padding_idx=0)\n",
    "        input_dim = word_emb_dim + type_emb_dim + dtype_emb_dim\n",
    "        print(f\"Initialize {model_type} model...\")\n",
    "        if model_type == \"linear\":\n",
    "            self.fc_cls = nn.Linear(input_dim, template_classes)\n",
    "            self.fc_tag = nn.Linear(input_dim, tag_classes)\n",
    "        elif model_type == \"feedforward\":\n",
    "            self.ff_cls = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, template_classes)\n",
    "            )\n",
    "            self.ff_tag = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, tag_classes)\n",
    "            )\n",
    "        elif model_type == \"lstm\":\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                                  batch_first=True, bidirectional=True)\n",
    "            self.fc_cls = nn.Linear(hidden_dim*2, template_classes)\n",
    "            self.fc_tag = nn.Linear(hidden_dim*2, tag_classes)\n",
    "        elif model_type == \"transformer\":\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead)\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "            self.fc_cls = nn.Linear(input_dim, template_classes)\n",
    "            self.fc_tag = nn.Linear(input_dim, tag_classes)\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect model type\")\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, word_idx, type_idx, dtype_idx):\n",
    "        word_emb = self.word_emb(word_idx)        # [batch, seq_len, word_emb_dim]\n",
    "        type_emb = self.type_emb(type_idx)        # [batch, seq_len, type_emb_dim]\n",
    "        dtype_emb = self.dtype_emb(dtype_idx)     # [batch, seq_len, dtype_emb_dim]\n",
    "        x = torch.cat((word_emb, type_emb, dtype_emb), dim=2)  # [batch, seq_len, input_dim]\n",
    "        \n",
    "        if self.model_type == \"linear\":\n",
    "            cls_feat = x.mean(dim=1)  # [batch, input_dim]\n",
    "            class_logits = self.fc_cls(cls_feat)\n",
    "            tag_logits = self.fc_tag(x)  # [batch, seq_len, tag_classes]\n",
    "        elif self.model_type == \"feedforward\":\n",
    "            cls_feat = x.mean(dim=1)\n",
    "            class_logits = self.ff_cls(cls_feat)\n",
    "            tag_logits = self.ff_tag(x)\n",
    "        elif self.model_type == \"lstm\":\n",
    "            lstm_out, _ = self.lstm(x)  # [batch, seq_len, 2*hidden_dim]\n",
    "            cls_feat = lstm_out.mean(dim=1)\n",
    "            class_logits = self.fc_cls(cls_feat)\n",
    "            tag_logits = self.fc_tag(lstm_out)  # [batch, seq_len, tag_classes]\n",
    "        elif self.model_type == \"transformer\":\n",
    "            x_t = x.permute(1, 0, 2)  # [seq_len, batch, input_dim]\n",
    "            trans_out = self.transformer(x_t)  # [seq_len, batch, input_dim]\n",
    "            trans_out = trans_out.permute(1, 0, 2)  # [batch, seq_len, input_dim]\n",
    "            cls_feat = trans_out.mean(dim=1)\n",
    "            class_logits = self.fc_cls(cls_feat)\n",
    "            tag_logits = self.fc_tag(trans_out)\n",
    "        else:\n",
    "            raise ValueError(\"Incorrect model type\")\n",
    "        return class_logits, tag_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca46ba19-0a71-4d64-9726-c51522defc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(processor, model, epochs=10, lr=1e-3, weight_cls=1.0, weight_tag=1.0, patience=3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # device = \"cpu\"\n",
    "    model = model.to(device)\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_tag = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_val_acc = 0.0\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        train_corr_cls = 0\n",
    "        train_corr_tag = 0\n",
    "        train_total_cls = 0\n",
    "        train_total_tag = 0\n",
    "        train_loader = processor.getDataLoader(\"train\", shuffle=True)\n",
    "        for word_idx, label_idx, type_idx, dtype_idx, class_labels in train_loader:\n",
    "            word_idx = word_idx.to(device)\n",
    "            label_idx = label_idx.to(device)\n",
    "            type_idx = type_idx.to(device)\n",
    "            dtype_idx = dtype_idx.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            class_logits, tag_logits = model(word_idx, type_idx, dtype_idx)\n",
    "            # print(f\"class_logit: {class_logits}\")\n",
    "            # print(f\"class_labels: {class_labels}\")\n",
    "            # print(\"class_logits shape:\", class_logits.shape)      # [B, num_classes]\n",
    "            # print(\"class_labels max:\", class_labels.max().item())\n",
    "\n",
    "            loss_cls = criterion_cls(class_logits, class_labels)\n",
    "\n",
    "            loss_tag = criterion_tag(tag_logits.permute(0, 2, 1), label_idx)\n",
    "            loss = weight_cls * loss_cls + weight_tag * loss_tag\n",
    "            loss.backward()\n",
    "            torch.cuda.synchronize()\n",
    "            optimizer.step()\n",
    "            \n",
    "            preds = class_logits.argmax(dim=1)\n",
    "            train_corr_cls += (preds == class_labels).sum().item()\n",
    "            train_total_cls += class_labels.size(0)\n",
    "            pred_tags = tag_logits.argmax(dim=2)  # [batch, seq_len]\n",
    "            mask = (label_idx != -100)\n",
    "            train_corr_tag += ((pred_tags == label_idx) & mask).sum().item()\n",
    "            train_total_tag += mask.sum().item()\n",
    "        \n",
    "        train_acc_cls = train_corr_cls / train_total_cls if train_total_cls else 0\n",
    "        train_acc_tag = train_corr_tag / train_total_tag if train_total_tag else 0\n",
    "        \n",
    "        model.eval()\n",
    "        val_corr_cls = 0\n",
    "        val_corr_tag = 0\n",
    "        val_total_cls = 0\n",
    "        val_total_tag = 0\n",
    "        with torch.no_grad():\n",
    "            val_loader = processor.getDataLoader(\"dev\", shuffle=False)\n",
    "            for word_idx, label_idx, type_idx, dtype_idx, class_labels in val_loader:\n",
    "                word_idx = word_idx.to(device)\n",
    "                type_idx = type_idx.to(device)\n",
    "                dtype_idx = dtype_idx.to(device)\n",
    "                class_labels = class_labels.to(device)\n",
    "                label_idx = label_idx.to(device)\n",
    "                class_logits, tag_logits = model(word_idx, type_idx, dtype_idx)\n",
    "                \n",
    "                preds = class_logits.argmax(dim=1)\n",
    "                val_corr_cls += (preds == class_labels).sum().item()\n",
    "                val_total_cls += class_labels.size(0)\n",
    "                \n",
    "                pred_tags = tag_logits.argmax(dim=2)\n",
    "                mask = (label_idx != -100)\n",
    "                val_corr_tag += ((pred_tags == label_idx) & mask).sum().item()\n",
    "                val_total_tag += mask.sum().item()\n",
    "        val_acc_cls = val_corr_cls / val_total_cls if val_total_cls else 0\n",
    "        val_acc_tag = val_corr_tag / val_total_tag if val_total_tag else 0\n",
    "        \n",
    "        print(f\"Epoch {epoch}: Train_cls_acc={train_acc_cls:.4f}, Train_tag_acc={train_acc_tag:.4f}, \" +\n",
    "              f\"Val_cls_acc={val_acc_cls:.4f}, Val_tag_acc={val_acc_tag:.4f}\")\n",
    "        \n",
    "        if val_acc_cls > best_val_acc:\n",
    "            best_val_acc = val_acc_cls\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(f\"The accuracy of dev set seems not increase for {patience} epoches, stop training...\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a1cb72-98cd-4c1c-94c0-f3497d32cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(processor, model, batch_size=32):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    corr_cls = corr_tag = total_cls = total_tag = 0\n",
    "    strict_corr = strict_total = 0\n",
    "\n",
    "    loader = processor.getDataLoader(split=\"test\",\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False)\n",
    "    global_idx = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for word_idx, label_idx, type_idx, dtype_idx, class_labels in loader:\n",
    "            B, L = word_idx.size()\n",
    "            word_idx   = word_idx.to(device)\n",
    "            type_idx   = type_idx.to(device)\n",
    "            dtype_idx  = dtype_idx.to(device)\n",
    "            class_labels = class_labels.to(device)\n",
    "            label_idx  = label_idx.to(device)\n",
    "\n",
    "            class_logits, tag_logits = model(word_idx, type_idx, dtype_idx)\n",
    "            preds = class_logits.argmax(dim=1)\n",
    "\n",
    "            corr_cls += (preds == class_labels).sum().item()\n",
    "            total_cls += B\n",
    "\n",
    "            pred_tags = tag_logits.argmax(dim=2)\n",
    "            mask = (label_idx != -100)\n",
    "            corr_tag += ((pred_tags == label_idx) & mask).sum().item()\n",
    "            total_tag += mask.sum().item()\n",
    "\n",
    "            word_idx_cpu = word_idx.cpu().tolist()\n",
    "            pred_tags_cpu = pred_tags.cpu().tolist()\n",
    "\n",
    "            for b in range(B):\n",
    "                pred_tid = preds[b].item()\n",
    "                tokens = [\n",
    "                    processor.idx2word[idx]\n",
    "                    for idx in word_idx_cpu[b]\n",
    "                    if idx != processor.word2idx[\"PAD\"]\n",
    "                ]\n",
    "                tags = pred_tags_cpu[b][:len(tokens)]\n",
    "                pred_var_map = {}\n",
    "                for tok, tag in zip(tokens, tags):\n",
    "                    if tag != 0:\n",
    "                        placeholder = processor.idx2name[tag]\n",
    "                        true_val = processor.test_data[global_idx][\"variables\"].get(placeholder)\n",
    "                        pred_var_map[placeholder] = true_val\n",
    "\n",
    "                true_tid     = class_labels[b].item()\n",
    "                true_var_map = processor.test_data[global_idx][\"variables\"]\n",
    "\n",
    "                if pred_tid == true_tid and pred_var_map == true_var_map:\n",
    "                    strict_corr += 1\n",
    "                strict_total += 1\n",
    "                global_idx += 1\n",
    "\n",
    "    acc_cls    = corr_cls / total_cls    if total_cls else 0.0\n",
    "    acc_tag    = corr_tag / total_tag    if total_tag else 0.0\n",
    "    acc_strict = strict_corr / strict_total if strict_total else 0.0\n",
    "\n",
    "    return acc_cls, acc_tag, acc_strict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1910a588-994c-419e-9c13-984857207b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datatype of variables for additional information on learning...\n",
      "Loading all data in json...\n",
      "Loading sql template...\n",
      "944\n",
      "processing samples...\n",
      "length of training set: 46419\n",
      "length of training set: 5207\n",
      "length of training set: 4030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caesarchen\\AppData\\Local\\Temp\\ipykernel_19200\\1173778113.py:148: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: 找不到指定的模块。 (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  vec = torch.tensor([float(x) for x in parts[1:]], dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "data_file = \"atis.json\"\n",
    "type_file = \"atis-schema.csv\"     \n",
    "glove_path = \"glove.6B.50d.txt\"  \n",
    "    \n",
    "processor = atisDataProcessor(data_file, type_file, glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d78d854-230e-4a14-a7c9-4f9b1eaeec48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1791, Train_tag_acc=0.9070, Val_cls_acc=0.2944, Val_tag_acc=0.9195\n",
      "Epoch 2: Train_cls_acc=0.4348, Train_tag_acc=0.9198, Val_cls_acc=0.4836, Val_tag_acc=0.9219\n",
      "Epoch 3: Train_cls_acc=0.6325, Train_tag_acc=0.9200, Val_cls_acc=0.5581, Val_tag_acc=0.9223\n",
      "Epoch 4: Train_cls_acc=0.7710, Train_tag_acc=0.9195, Val_cls_acc=0.6207, Val_tag_acc=0.9137\n",
      "Epoch 5: Train_cls_acc=0.8543, Train_tag_acc=0.9199, Val_cls_acc=0.6570, Val_tag_acc=0.9233\n",
      "Epoch 6: Train_cls_acc=0.9020, Train_tag_acc=0.9198, Val_cls_acc=0.6535, Val_tag_acc=0.9240\n",
      "Epoch 7: Train_cls_acc=0.9326, Train_tag_acc=0.9195, Val_cls_acc=0.6733, Val_tag_acc=0.9139\n",
      "Epoch 8: Train_cls_acc=0.9518, Train_tag_acc=0.9194, Val_cls_acc=0.6781, Val_tag_acc=0.9246\n",
      "Epoch 9: Train_cls_acc=0.9636, Train_tag_acc=0.9196, Val_cls_acc=0.6754, Val_tag_acc=0.9184\n",
      "Epoch 10: Train_cls_acc=0.9737, Train_tag_acc=0.9196, Val_cls_acc=0.6630, Val_tag_acc=0.9188\n",
      "Epoch 11: Train_cls_acc=0.9800, Train_tag_acc=0.9193, Val_cls_acc=0.6626, Val_tag_acc=0.9220\n",
      "Epoch 12: Train_cls_acc=0.9851, Train_tag_acc=0.9194, Val_cls_acc=0.6710, Val_tag_acc=0.9182\n",
      "Epoch 13: Train_cls_acc=0.9884, Train_tag_acc=0.9192, Val_cls_acc=0.6697, Val_tag_acc=0.9245\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4953,  Tagging Acc: 0.9173, Overall Acc:0.1767\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3483, Train_tag_acc=0.9141, Val_cls_acc=0.4970, Val_tag_acc=0.9219\n",
      "Epoch 2: Train_cls_acc=0.7546, Train_tag_acc=0.9197, Val_cls_acc=0.6017, Val_tag_acc=0.9174\n",
      "Epoch 3: Train_cls_acc=0.8991, Train_tag_acc=0.9200, Val_cls_acc=0.6259, Val_tag_acc=0.9256\n",
      "Epoch 4: Train_cls_acc=0.9447, Train_tag_acc=0.9202, Val_cls_acc=0.6205, Val_tag_acc=0.9277\n",
      "Epoch 5: Train_cls_acc=0.9663, Train_tag_acc=0.9202, Val_cls_acc=0.6447, Val_tag_acc=0.9243\n",
      "Epoch 6: Train_cls_acc=0.9780, Train_tag_acc=0.9204, Val_cls_acc=0.6330, Val_tag_acc=0.9210\n",
      "Epoch 7: Train_cls_acc=0.9854, Train_tag_acc=0.9203, Val_cls_acc=0.6359, Val_tag_acc=0.9244\n",
      "Epoch 8: Train_cls_acc=0.9890, Train_tag_acc=0.9204, Val_cls_acc=0.6612, Val_tag_acc=0.9257\n",
      "Epoch 9: Train_cls_acc=0.9927, Train_tag_acc=0.9208, Val_cls_acc=0.6591, Val_tag_acc=0.9256\n",
      "Epoch 10: Train_cls_acc=0.9945, Train_tag_acc=0.9206, Val_cls_acc=0.6503, Val_tag_acc=0.9247\n",
      "Epoch 11: Train_cls_acc=0.9961, Train_tag_acc=0.9206, Val_cls_acc=0.6355, Val_tag_acc=0.9240\n",
      "Epoch 12: Train_cls_acc=0.9970, Train_tag_acc=0.9209, Val_cls_acc=0.6612, Val_tag_acc=0.9222\n",
      "Epoch 13: Train_cls_acc=0.9978, Train_tag_acc=0.9210, Val_cls_acc=0.6679, Val_tag_acc=0.9247\n",
      "Epoch 14: Train_cls_acc=0.9984, Train_tag_acc=0.9205, Val_cls_acc=0.6597, Val_tag_acc=0.9279\n",
      "Epoch 15: Train_cls_acc=0.9984, Train_tag_acc=0.9206, Val_cls_acc=0.6739, Val_tag_acc=0.9237\n",
      "Epoch 16: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6505, Val_tag_acc=0.9247\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6530, Val_tag_acc=0.9241\n",
      "Epoch 18: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6639, Val_tag_acc=0.9256\n",
      "Epoch 19: Train_cls_acc=0.9994, Train_tag_acc=0.9209, Val_cls_acc=0.6583, Val_tag_acc=0.9222\n",
      "Epoch 20: Train_cls_acc=0.9997, Train_tag_acc=0.9208, Val_cls_acc=0.6727, Val_tag_acc=0.9257\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4407,  Tagging Acc: 0.9122, Overall Acc:0.1486\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4783, Train_tag_acc=0.9520, Val_cls_acc=0.5201, Val_tag_acc=0.9606\n",
      "Epoch 2: Train_cls_acc=0.8962, Train_tag_acc=0.9801, Val_cls_acc=0.6126, Val_tag_acc=0.9680\n",
      "Epoch 3: Train_cls_acc=0.9656, Train_tag_acc=0.9883, Val_cls_acc=0.6399, Val_tag_acc=0.9709\n",
      "Epoch 4: Train_cls_acc=0.9848, Train_tag_acc=0.9929, Val_cls_acc=0.6036, Val_tag_acc=0.9708\n",
      "Epoch 5: Train_cls_acc=0.9899, Train_tag_acc=0.9955, Val_cls_acc=0.6194, Val_tag_acc=0.9714\n",
      "Epoch 6: Train_cls_acc=0.9917, Train_tag_acc=0.9971, Val_cls_acc=0.6357, Val_tag_acc=0.9728\n",
      "Epoch 7: Train_cls_acc=0.9939, Train_tag_acc=0.9981, Val_cls_acc=0.6359, Val_tag_acc=0.9711\n",
      "Epoch 8: Train_cls_acc=0.9941, Train_tag_acc=0.9986, Val_cls_acc=0.6190, Val_tag_acc=0.9702\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3563,  Tagging Acc: 0.9732, Overall Acc:0.2236\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caesarchen\\anaconda3\\envs\\NLPCodingTest\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "C:\\Users\\caesarchen\\anaconda3\\envs\\NLPCodingTest\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train_cls_acc=0.6924, Train_tag_acc=0.9153, Val_cls_acc=0.6261, Val_tag_acc=0.9225\n",
      "Epoch 2: Train_cls_acc=0.9541, Train_tag_acc=0.9243, Val_cls_acc=0.6520, Val_tag_acc=0.9244\n",
      "Epoch 3: Train_cls_acc=0.9749, Train_tag_acc=0.9332, Val_cls_acc=0.6557, Val_tag_acc=0.9307\n",
      "Epoch 4: Train_cls_acc=0.9831, Train_tag_acc=0.9434, Val_cls_acc=0.6883, Val_tag_acc=0.9377\n",
      "Epoch 5: Train_cls_acc=0.9855, Train_tag_acc=0.9529, Val_cls_acc=0.6994, Val_tag_acc=0.9381\n",
      "Epoch 6: Train_cls_acc=0.9889, Train_tag_acc=0.9615, Val_cls_acc=0.6868, Val_tag_acc=0.9397\n",
      "Epoch 7: Train_cls_acc=0.9918, Train_tag_acc=0.9685, Val_cls_acc=0.6457, Val_tag_acc=0.9426\n",
      "Epoch 8: Train_cls_acc=0.9940, Train_tag_acc=0.9735, Val_cls_acc=0.6679, Val_tag_acc=0.9433\n",
      "Epoch 9: Train_cls_acc=0.9966, Train_tag_acc=0.9782, Val_cls_acc=0.7042, Val_tag_acc=0.9435\n",
      "Epoch 10: Train_cls_acc=0.9919, Train_tag_acc=0.9796, Val_cls_acc=0.6866, Val_tag_acc=0.9431\n",
      "Epoch 11: Train_cls_acc=0.9941, Train_tag_acc=0.9821, Val_cls_acc=0.6605, Val_tag_acc=0.9455\n",
      "Epoch 12: Train_cls_acc=0.9961, Train_tag_acc=0.9843, Val_cls_acc=0.6866, Val_tag_acc=0.9444\n",
      "Epoch 13: Train_cls_acc=0.9952, Train_tag_acc=0.9857, Val_cls_acc=0.6441, Val_tag_acc=0.9460\n",
      "Epoch 14: Train_cls_acc=0.9964, Train_tag_acc=0.9865, Val_cls_acc=0.6808, Val_tag_acc=0.9455\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4811,  Tagging Acc: 0.9256, Overall Acc:0.2419\n"
     ]
    }
   ],
   "source": [
    "model_set = [\"linear\", \"feedforward\", \"lstm\", \"transformer\"]\n",
    "for model_type in model_set:\n",
    "    model = ClassificationModels(embedding_matrix=processor.embedding_matrix,\n",
    "                           type_vocab_size=len(processor.var2idx),\n",
    "                           dtype_vocab_size=len(processor.dtype2idx),\n",
    "                           type_emb_dim=50, dtype_emb_dim=50,\n",
    "                           model_type=model_type,\n",
    "                           hidden_dim=128,\n",
    "                           template_classes=processor.template_classes,\n",
    "                           tag_classes=len(processor.name2idx),\n",
    "                           num_layers=1, nhead=5)\n",
    "    print(f\"===============Training Model=================\")\n",
    "    train_model(processor, model, epochs=20, lr=1e-3, patience=5)\n",
    "    print(f\"===============Testing Model=================\")\n",
    "    acc_cls, acc_tag, acc_strict = evaluate_model(processor, model)\n",
    "    print(f\"Test set {model_type} —  Classification Acc: {acc_cls:.4f},  Tagging Acc: {acc_tag:.4f}, Overall Acc:{acc_strict:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92308e76-d3e4-471c-9763-3af049e487bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, processor, question):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    tokens = [tok.text for tok in processor.nlp(question.strip())]\n",
    "    word_idxs = torch.tensor([[ processor.word2idx.get(tok.lower(), processor.word2idx[\"UNK\"]) \n",
    "                                 for tok in tokens ]], dtype=torch.long)\n",
    "    type_idxs = torch.zeros_like(word_idxs)\n",
    "    dtype_idxs = torch.zeros_like(word_idxs)\n",
    "    word_idxs = word_idxs.to(device)\n",
    "    type_idxs = type_idxs.to(device)\n",
    "    dtype_idxs = dtype_idxs.to(device)\n",
    "    with torch.no_grad():\n",
    "        class_logits, tag_logits = model(word_idxs, type_idxs, dtype_idxs)\n",
    "    pred_class = class_logits.argmax(dim=1).item()\n",
    "    pred_tags = tag_logits.argmax(dim=2).squeeze(0).tolist()  # [seq_len]\n",
    "    variables = []\n",
    "    for tok, tag in zip(tokens, pred_tags):\n",
    "        if tag != 0:\n",
    "            type_name = processor.idx2type.get(tag, \"UNK\")\n",
    "            variables.append((tok, type_name))\n",
    "    return pred_class, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67693b2a-ce11-4a88-be3f-c4d6b32ab3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template ID: ['SELECT DISTINCT FLIGHTalias0.FLIGHT_ID FROM AIRPORT AS AIRPORTalias0 , FLIGHT AS FLIGHTalias0 WHERE AIRPORTalias0.AIRPORT_CODE = \"airport_code0\" AND FLIGHTalias0.TO_AIRPORT = AIRPORTalias0.AIRPORT_CODE ;', {'airport_code0': 'MKE'}]\n",
      "variables: []\n"
     ]
    }
   ],
   "source": [
    "question = \"show me the flights arriving at MKE\"\n",
    "pred_id, vars_detected = inference(model, processor, question)\n",
    "print(f\"template ID: {processor.idx2template[pred_id]}\")\n",
    "print(f\"variables: {vars_detected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3813cb-c25a-47a9-9b69-78f3f7942f60",
   "metadata": {},
   "source": [
    "## Task2 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94bdecf8-236d-4278-b1b6-895b1afd2637",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datatype of variables for additional information on learning...\n",
      "Loading all data in json...\n",
      "Loading sql template...\n",
      "944\n",
      "processing samples...\n",
      "length of training set: 46419\n",
      "length of training set: 5207\n",
      "length of training set: 4030\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1432, Train_tag_acc=0.9030, Val_cls_acc=0.2020, Val_tag_acc=0.9190\n",
      "Epoch 2: Train_cls_acc=0.3292, Train_tag_acc=0.9201, Val_cls_acc=0.4204, Val_tag_acc=0.9167\n",
      "Epoch 3: Train_cls_acc=0.5245, Train_tag_acc=0.9202, Val_cls_acc=0.5429, Val_tag_acc=0.9178\n",
      "Epoch 4: Train_cls_acc=0.6845, Train_tag_acc=0.9204, Val_cls_acc=0.6011, Val_tag_acc=0.9250\n",
      "Epoch 5: Train_cls_acc=0.8037, Train_tag_acc=0.9204, Val_cls_acc=0.6357, Val_tag_acc=0.9251\n",
      "Epoch 6: Train_cls_acc=0.8725, Train_tag_acc=0.9201, Val_cls_acc=0.6476, Val_tag_acc=0.9243\n",
      "Epoch 7: Train_cls_acc=0.9130, Train_tag_acc=0.9204, Val_cls_acc=0.6482, Val_tag_acc=0.9197\n",
      "Epoch 8: Train_cls_acc=0.9391, Train_tag_acc=0.9201, Val_cls_acc=0.6510, Val_tag_acc=0.9241\n",
      "Epoch 9: Train_cls_acc=0.9565, Train_tag_acc=0.9200, Val_cls_acc=0.6487, Val_tag_acc=0.9262\n",
      "Epoch 10: Train_cls_acc=0.9681, Train_tag_acc=0.9200, Val_cls_acc=0.6570, Val_tag_acc=0.9268\n",
      "Epoch 11: Train_cls_acc=0.9764, Train_tag_acc=0.9198, Val_cls_acc=0.6576, Val_tag_acc=0.9188\n",
      "Epoch 12: Train_cls_acc=0.9819, Train_tag_acc=0.9198, Val_cls_acc=0.6522, Val_tag_acc=0.9225\n",
      "Epoch 13: Train_cls_acc=0.9864, Train_tag_acc=0.9199, Val_cls_acc=0.6547, Val_tag_acc=0.9229\n",
      "Epoch 14: Train_cls_acc=0.9893, Train_tag_acc=0.9201, Val_cls_acc=0.6522, Val_tag_acc=0.9233\n",
      "Epoch 15: Train_cls_acc=0.9918, Train_tag_acc=0.9199, Val_cls_acc=0.6568, Val_tag_acc=0.9199\n",
      "Epoch 16: Train_cls_acc=0.9933, Train_tag_acc=0.9198, Val_cls_acc=0.6566, Val_tag_acc=0.9203\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4801,  Tagging Acc: 0.9113, Overall Acc:0.2040\n",
      "Overall Acc:0.2040, Params: (type_emb_dim: 8, dtype_emb_dim:8)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1433, Train_tag_acc=0.8919, Val_cls_acc=0.2157, Val_tag_acc=0.9149\n",
      "Epoch 2: Train_cls_acc=0.3350, Train_tag_acc=0.9199, Val_cls_acc=0.4250, Val_tag_acc=0.9183\n",
      "Epoch 3: Train_cls_acc=0.5404, Train_tag_acc=0.9205, Val_cls_acc=0.5370, Val_tag_acc=0.9224\n",
      "Epoch 4: Train_cls_acc=0.7035, Train_tag_acc=0.9202, Val_cls_acc=0.6101, Val_tag_acc=0.9252\n",
      "Epoch 5: Train_cls_acc=0.8161, Train_tag_acc=0.9202, Val_cls_acc=0.6336, Val_tag_acc=0.9258\n",
      "Epoch 6: Train_cls_acc=0.8815, Train_tag_acc=0.9204, Val_cls_acc=0.6501, Val_tag_acc=0.9177\n",
      "Epoch 7: Train_cls_acc=0.9169, Train_tag_acc=0.9201, Val_cls_acc=0.6666, Val_tag_acc=0.9187\n",
      "Epoch 8: Train_cls_acc=0.9441, Train_tag_acc=0.9201, Val_cls_acc=0.6662, Val_tag_acc=0.9155\n",
      "Epoch 9: Train_cls_acc=0.9600, Train_tag_acc=0.9196, Val_cls_acc=0.6630, Val_tag_acc=0.9197\n",
      "Epoch 10: Train_cls_acc=0.9703, Train_tag_acc=0.9202, Val_cls_acc=0.6551, Val_tag_acc=0.9204\n",
      "Epoch 11: Train_cls_acc=0.9775, Train_tag_acc=0.9199, Val_cls_acc=0.6637, Val_tag_acc=0.9208\n",
      "Epoch 12: Train_cls_acc=0.9830, Train_tag_acc=0.9199, Val_cls_acc=0.6685, Val_tag_acc=0.9252\n",
      "Epoch 13: Train_cls_acc=0.9877, Train_tag_acc=0.9202, Val_cls_acc=0.6676, Val_tag_acc=0.9213\n",
      "Epoch 14: Train_cls_acc=0.9899, Train_tag_acc=0.9198, Val_cls_acc=0.6712, Val_tag_acc=0.9189\n",
      "Epoch 15: Train_cls_acc=0.9925, Train_tag_acc=0.9198, Val_cls_acc=0.6626, Val_tag_acc=0.9237\n",
      "Epoch 16: Train_cls_acc=0.9936, Train_tag_acc=0.9197, Val_cls_acc=0.6714, Val_tag_acc=0.9233\n",
      "Epoch 17: Train_cls_acc=0.9953, Train_tag_acc=0.9198, Val_cls_acc=0.6626, Val_tag_acc=0.9231\n",
      "Epoch 18: Train_cls_acc=0.9959, Train_tag_acc=0.9196, Val_cls_acc=0.6647, Val_tag_acc=0.9242\n",
      "Epoch 19: Train_cls_acc=0.9965, Train_tag_acc=0.9198, Val_cls_acc=0.6622, Val_tag_acc=0.9272\n",
      "Epoch 20: Train_cls_acc=0.9972, Train_tag_acc=0.9192, Val_cls_acc=0.6631, Val_tag_acc=0.9242\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4730,  Tagging Acc: 0.9093, Overall Acc:0.1834\n",
      "Overall Acc:0.1834, Params: (type_emb_dim: 8, dtype_emb_dim:16)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1571, Train_tag_acc=0.9035, Val_cls_acc=0.2464, Val_tag_acc=0.9249\n",
      "Epoch 2: Train_cls_acc=0.3763, Train_tag_acc=0.9198, Val_cls_acc=0.4500, Val_tag_acc=0.9240\n",
      "Epoch 3: Train_cls_acc=0.5744, Train_tag_acc=0.9202, Val_cls_acc=0.5443, Val_tag_acc=0.9213\n",
      "Epoch 4: Train_cls_acc=0.7327, Train_tag_acc=0.9200, Val_cls_acc=0.6021, Val_tag_acc=0.9214\n",
      "Epoch 5: Train_cls_acc=0.8355, Train_tag_acc=0.9204, Val_cls_acc=0.6345, Val_tag_acc=0.9219\n",
      "Epoch 6: Train_cls_acc=0.8934, Train_tag_acc=0.9196, Val_cls_acc=0.6474, Val_tag_acc=0.9241\n",
      "Epoch 7: Train_cls_acc=0.9247, Train_tag_acc=0.9198, Val_cls_acc=0.6374, Val_tag_acc=0.9236\n",
      "Epoch 8: Train_cls_acc=0.9481, Train_tag_acc=0.9200, Val_cls_acc=0.6541, Val_tag_acc=0.9203\n",
      "Epoch 9: Train_cls_acc=0.9630, Train_tag_acc=0.9196, Val_cls_acc=0.6549, Val_tag_acc=0.9269\n",
      "Epoch 10: Train_cls_acc=0.9726, Train_tag_acc=0.9193, Val_cls_acc=0.6451, Val_tag_acc=0.9277\n",
      "Epoch 11: Train_cls_acc=0.9795, Train_tag_acc=0.9198, Val_cls_acc=0.6535, Val_tag_acc=0.9214\n",
      "Epoch 12: Train_cls_acc=0.9838, Train_tag_acc=0.9197, Val_cls_acc=0.6562, Val_tag_acc=0.9215\n",
      "Epoch 13: Train_cls_acc=0.9869, Train_tag_acc=0.9197, Val_cls_acc=0.6562, Val_tag_acc=0.9254\n",
      "Epoch 14: Train_cls_acc=0.9903, Train_tag_acc=0.9197, Val_cls_acc=0.6574, Val_tag_acc=0.9246\n",
      "Epoch 15: Train_cls_acc=0.9919, Train_tag_acc=0.9198, Val_cls_acc=0.6560, Val_tag_acc=0.9203\n",
      "Epoch 16: Train_cls_acc=0.9935, Train_tag_acc=0.9196, Val_cls_acc=0.6655, Val_tag_acc=0.9254\n",
      "Epoch 17: Train_cls_acc=0.9946, Train_tag_acc=0.9197, Val_cls_acc=0.6612, Val_tag_acc=0.9261\n",
      "Epoch 18: Train_cls_acc=0.9956, Train_tag_acc=0.9194, Val_cls_acc=0.6620, Val_tag_acc=0.9251\n",
      "Epoch 19: Train_cls_acc=0.9964, Train_tag_acc=0.9199, Val_cls_acc=0.6639, Val_tag_acc=0.9288\n",
      "Epoch 20: Train_cls_acc=0.9969, Train_tag_acc=0.9196, Val_cls_acc=0.6622, Val_tag_acc=0.9176\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4814,  Tagging Acc: 0.9146, Overall Acc:0.2077\n",
      "Overall Acc:0.2077, Params: (type_emb_dim: 8, dtype_emb_dim:32)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1580, Train_tag_acc=0.8966, Val_cls_acc=0.2431, Val_tag_acc=0.9230\n",
      "Epoch 2: Train_cls_acc=0.3835, Train_tag_acc=0.9202, Val_cls_acc=0.4513, Val_tag_acc=0.9198\n",
      "Epoch 3: Train_cls_acc=0.5892, Train_tag_acc=0.9203, Val_cls_acc=0.5625, Val_tag_acc=0.9250\n",
      "Epoch 4: Train_cls_acc=0.7390, Train_tag_acc=0.9200, Val_cls_acc=0.6073, Val_tag_acc=0.9259\n",
      "Epoch 5: Train_cls_acc=0.8386, Train_tag_acc=0.9202, Val_cls_acc=0.6428, Val_tag_acc=0.9233\n",
      "Epoch 6: Train_cls_acc=0.8935, Train_tag_acc=0.9200, Val_cls_acc=0.6453, Val_tag_acc=0.9250\n",
      "Epoch 7: Train_cls_acc=0.9253, Train_tag_acc=0.9196, Val_cls_acc=0.6447, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9475, Train_tag_acc=0.9195, Val_cls_acc=0.6497, Val_tag_acc=0.9293\n",
      "Epoch 9: Train_cls_acc=0.9637, Train_tag_acc=0.9195, Val_cls_acc=0.6539, Val_tag_acc=0.9177\n",
      "Epoch 10: Train_cls_acc=0.9732, Train_tag_acc=0.9198, Val_cls_acc=0.6537, Val_tag_acc=0.9182\n",
      "Epoch 11: Train_cls_acc=0.9792, Train_tag_acc=0.9196, Val_cls_acc=0.6505, Val_tag_acc=0.9162\n",
      "Epoch 12: Train_cls_acc=0.9843, Train_tag_acc=0.9199, Val_cls_acc=0.6480, Val_tag_acc=0.9237\n",
      "Epoch 13: Train_cls_acc=0.9877, Train_tag_acc=0.9197, Val_cls_acc=0.6647, Val_tag_acc=0.9216\n",
      "Epoch 14: Train_cls_acc=0.9908, Train_tag_acc=0.9195, Val_cls_acc=0.6668, Val_tag_acc=0.9236\n",
      "Epoch 15: Train_cls_acc=0.9926, Train_tag_acc=0.9198, Val_cls_acc=0.6616, Val_tag_acc=0.9259\n",
      "Epoch 16: Train_cls_acc=0.9939, Train_tag_acc=0.9193, Val_cls_acc=0.6601, Val_tag_acc=0.9244\n",
      "Epoch 17: Train_cls_acc=0.9950, Train_tag_acc=0.9198, Val_cls_acc=0.6630, Val_tag_acc=0.9228\n",
      "Epoch 18: Train_cls_acc=0.9959, Train_tag_acc=0.9195, Val_cls_acc=0.6570, Val_tag_acc=0.9184\n",
      "Epoch 19: Train_cls_acc=0.9964, Train_tag_acc=0.9193, Val_cls_acc=0.6653, Val_tag_acc=0.9195\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4789,  Tagging Acc: 0.9138, Overall Acc:0.2275\n",
      "Overall Acc:0.2275, Params: (type_emb_dim: 8, dtype_emb_dim:50)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1693, Train_tag_acc=0.8991, Val_cls_acc=0.2589, Val_tag_acc=0.9257\n",
      "Epoch 2: Train_cls_acc=0.3912, Train_tag_acc=0.9201, Val_cls_acc=0.4644, Val_tag_acc=0.9272\n",
      "Epoch 3: Train_cls_acc=0.5965, Train_tag_acc=0.9204, Val_cls_acc=0.5554, Val_tag_acc=0.9231\n",
      "Epoch 4: Train_cls_acc=0.7478, Train_tag_acc=0.9201, Val_cls_acc=0.6180, Val_tag_acc=0.9286\n",
      "Epoch 5: Train_cls_acc=0.8447, Train_tag_acc=0.9200, Val_cls_acc=0.6466, Val_tag_acc=0.9214\n",
      "Epoch 6: Train_cls_acc=0.8969, Train_tag_acc=0.9200, Val_cls_acc=0.6437, Val_tag_acc=0.9200\n",
      "Epoch 7: Train_cls_acc=0.9282, Train_tag_acc=0.9199, Val_cls_acc=0.6522, Val_tag_acc=0.9209\n",
      "Epoch 8: Train_cls_acc=0.9506, Train_tag_acc=0.9197, Val_cls_acc=0.6532, Val_tag_acc=0.9166\n",
      "Epoch 9: Train_cls_acc=0.9642, Train_tag_acc=0.9197, Val_cls_acc=0.6512, Val_tag_acc=0.9237\n",
      "Epoch 10: Train_cls_acc=0.9728, Train_tag_acc=0.9197, Val_cls_acc=0.6630, Val_tag_acc=0.9189\n",
      "Epoch 11: Train_cls_acc=0.9795, Train_tag_acc=0.9195, Val_cls_acc=0.6614, Val_tag_acc=0.9200\n",
      "Epoch 12: Train_cls_acc=0.9841, Train_tag_acc=0.9193, Val_cls_acc=0.6701, Val_tag_acc=0.9204\n",
      "Epoch 13: Train_cls_acc=0.9875, Train_tag_acc=0.9194, Val_cls_acc=0.6585, Val_tag_acc=0.9246\n",
      "Epoch 14: Train_cls_acc=0.9905, Train_tag_acc=0.9197, Val_cls_acc=0.6701, Val_tag_acc=0.9197\n",
      "Epoch 15: Train_cls_acc=0.9924, Train_tag_acc=0.9196, Val_cls_acc=0.6668, Val_tag_acc=0.9192\n",
      "Epoch 16: Train_cls_acc=0.9936, Train_tag_acc=0.9196, Val_cls_acc=0.6672, Val_tag_acc=0.9227\n",
      "Epoch 17: Train_cls_acc=0.9949, Train_tag_acc=0.9196, Val_cls_acc=0.6624, Val_tag_acc=0.9263\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4836,  Tagging Acc: 0.9124, Overall Acc:0.2062\n",
      "Overall Acc:0.2062, Params: (type_emb_dim: 8, dtype_emb_dim:64)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1443, Train_tag_acc=0.8962, Val_cls_acc=0.2314, Val_tag_acc=0.9229\n",
      "Epoch 2: Train_cls_acc=0.3468, Train_tag_acc=0.9202, Val_cls_acc=0.4482, Val_tag_acc=0.9259\n",
      "Epoch 3: Train_cls_acc=0.5441, Train_tag_acc=0.9202, Val_cls_acc=0.5368, Val_tag_acc=0.9234\n",
      "Epoch 4: Train_cls_acc=0.7053, Train_tag_acc=0.9204, Val_cls_acc=0.5998, Val_tag_acc=0.9231\n",
      "Epoch 5: Train_cls_acc=0.8134, Train_tag_acc=0.9200, Val_cls_acc=0.6341, Val_tag_acc=0.9203\n",
      "Epoch 6: Train_cls_acc=0.8789, Train_tag_acc=0.9200, Val_cls_acc=0.6457, Val_tag_acc=0.9230\n",
      "Epoch 7: Train_cls_acc=0.9167, Train_tag_acc=0.9202, Val_cls_acc=0.6434, Val_tag_acc=0.9283\n",
      "Epoch 8: Train_cls_acc=0.9421, Train_tag_acc=0.9198, Val_cls_acc=0.6397, Val_tag_acc=0.9166\n",
      "Epoch 9: Train_cls_acc=0.9591, Train_tag_acc=0.9202, Val_cls_acc=0.6466, Val_tag_acc=0.9231\n",
      "Epoch 10: Train_cls_acc=0.9694, Train_tag_acc=0.9199, Val_cls_acc=0.6459, Val_tag_acc=0.9225\n",
      "Epoch 11: Train_cls_acc=0.9774, Train_tag_acc=0.9200, Val_cls_acc=0.6382, Val_tag_acc=0.9225\n",
      "Epoch 12: Train_cls_acc=0.9822, Train_tag_acc=0.9198, Val_cls_acc=0.6449, Val_tag_acc=0.9268\n",
      "Epoch 13: Train_cls_acc=0.9859, Train_tag_acc=0.9195, Val_cls_acc=0.6434, Val_tag_acc=0.9254\n",
      "Epoch 14: Train_cls_acc=0.9891, Train_tag_acc=0.9198, Val_cls_acc=0.6484, Val_tag_acc=0.9256\n",
      "Epoch 15: Train_cls_acc=0.9917, Train_tag_acc=0.9200, Val_cls_acc=0.6547, Val_tag_acc=0.9198\n",
      "Epoch 16: Train_cls_acc=0.9930, Train_tag_acc=0.9197, Val_cls_acc=0.6628, Val_tag_acc=0.9218\n",
      "Epoch 17: Train_cls_acc=0.9949, Train_tag_acc=0.9198, Val_cls_acc=0.6491, Val_tag_acc=0.9144\n",
      "Epoch 18: Train_cls_acc=0.9956, Train_tag_acc=0.9195, Val_cls_acc=0.6407, Val_tag_acc=0.9221\n",
      "Epoch 19: Train_cls_acc=0.9965, Train_tag_acc=0.9197, Val_cls_acc=0.6637, Val_tag_acc=0.9202\n",
      "Epoch 20: Train_cls_acc=0.9970, Train_tag_acc=0.9198, Val_cls_acc=0.6628, Val_tag_acc=0.9242\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4697,  Tagging Acc: 0.9128, Overall Acc:0.2062\n",
      "Overall Acc:0.2062, Params: (type_emb_dim: 16, dtype_emb_dim:8)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1505, Train_tag_acc=0.9091, Val_cls_acc=0.2485, Val_tag_acc=0.9193\n",
      "Epoch 2: Train_cls_acc=0.3722, Train_tag_acc=0.9201, Val_cls_acc=0.4398, Val_tag_acc=0.9237\n",
      "Epoch 3: Train_cls_acc=0.5642, Train_tag_acc=0.9205, Val_cls_acc=0.5433, Val_tag_acc=0.9162\n",
      "Epoch 4: Train_cls_acc=0.7218, Train_tag_acc=0.9201, Val_cls_acc=0.6051, Val_tag_acc=0.9224\n",
      "Epoch 5: Train_cls_acc=0.8284, Train_tag_acc=0.9203, Val_cls_acc=0.6249, Val_tag_acc=0.9227\n",
      "Epoch 6: Train_cls_acc=0.8867, Train_tag_acc=0.9203, Val_cls_acc=0.6459, Val_tag_acc=0.9214\n",
      "Epoch 7: Train_cls_acc=0.9222, Train_tag_acc=0.9201, Val_cls_acc=0.6455, Val_tag_acc=0.9217\n",
      "Epoch 8: Train_cls_acc=0.9457, Train_tag_acc=0.9201, Val_cls_acc=0.6411, Val_tag_acc=0.9225\n",
      "Epoch 9: Train_cls_acc=0.9618, Train_tag_acc=0.9200, Val_cls_acc=0.6468, Val_tag_acc=0.9217\n",
      "Epoch 10: Train_cls_acc=0.9711, Train_tag_acc=0.9202, Val_cls_acc=0.6366, Val_tag_acc=0.9246\n",
      "Epoch 11: Train_cls_acc=0.9785, Train_tag_acc=0.9200, Val_cls_acc=0.6395, Val_tag_acc=0.9229\n",
      "Epoch 12: Train_cls_acc=0.9833, Train_tag_acc=0.9199, Val_cls_acc=0.6401, Val_tag_acc=0.9252\n",
      "Epoch 13: Train_cls_acc=0.9867, Train_tag_acc=0.9199, Val_cls_acc=0.6453, Val_tag_acc=0.9175\n",
      "Epoch 14: Train_cls_acc=0.9899, Train_tag_acc=0.9199, Val_cls_acc=0.6451, Val_tag_acc=0.9216\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4873,  Tagging Acc: 0.9138, Overall Acc:0.2020\n",
      "Overall Acc:0.2020, Params: (type_emb_dim: 16, dtype_emb_dim:16)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1601, Train_tag_acc=0.8903, Val_cls_acc=0.2597, Val_tag_acc=0.9236\n",
      "Epoch 2: Train_cls_acc=0.3815, Train_tag_acc=0.9201, Val_cls_acc=0.4617, Val_tag_acc=0.9228\n",
      "Epoch 3: Train_cls_acc=0.5809, Train_tag_acc=0.9200, Val_cls_acc=0.5596, Val_tag_acc=0.9267\n",
      "Epoch 4: Train_cls_acc=0.7371, Train_tag_acc=0.9202, Val_cls_acc=0.6013, Val_tag_acc=0.9244\n",
      "Epoch 5: Train_cls_acc=0.8385, Train_tag_acc=0.9200, Val_cls_acc=0.6409, Val_tag_acc=0.9253\n",
      "Epoch 6: Train_cls_acc=0.8929, Train_tag_acc=0.9199, Val_cls_acc=0.6603, Val_tag_acc=0.9254\n",
      "Epoch 7: Train_cls_acc=0.9240, Train_tag_acc=0.9199, Val_cls_acc=0.6618, Val_tag_acc=0.9161\n",
      "Epoch 8: Train_cls_acc=0.9484, Train_tag_acc=0.9197, Val_cls_acc=0.6656, Val_tag_acc=0.9283\n",
      "Epoch 9: Train_cls_acc=0.9632, Train_tag_acc=0.9197, Val_cls_acc=0.6699, Val_tag_acc=0.9203\n",
      "Epoch 10: Train_cls_acc=0.9721, Train_tag_acc=0.9199, Val_cls_acc=0.6693, Val_tag_acc=0.9238\n",
      "Epoch 11: Train_cls_acc=0.9793, Train_tag_acc=0.9195, Val_cls_acc=0.6681, Val_tag_acc=0.9218\n",
      "Epoch 12: Train_cls_acc=0.9843, Train_tag_acc=0.9195, Val_cls_acc=0.6685, Val_tag_acc=0.9238\n",
      "Epoch 13: Train_cls_acc=0.9877, Train_tag_acc=0.9196, Val_cls_acc=0.6703, Val_tag_acc=0.9216\n",
      "Epoch 14: Train_cls_acc=0.9904, Train_tag_acc=0.9196, Val_cls_acc=0.6772, Val_tag_acc=0.9231\n",
      "Epoch 15: Train_cls_acc=0.9926, Train_tag_acc=0.9197, Val_cls_acc=0.6772, Val_tag_acc=0.9174\n",
      "Epoch 16: Train_cls_acc=0.9942, Train_tag_acc=0.9195, Val_cls_acc=0.6737, Val_tag_acc=0.9212\n",
      "Epoch 17: Train_cls_acc=0.9952, Train_tag_acc=0.9199, Val_cls_acc=0.6756, Val_tag_acc=0.9197\n",
      "Epoch 18: Train_cls_acc=0.9960, Train_tag_acc=0.9196, Val_cls_acc=0.6785, Val_tag_acc=0.9233\n",
      "Epoch 19: Train_cls_acc=0.9965, Train_tag_acc=0.9195, Val_cls_acc=0.6799, Val_tag_acc=0.9210\n",
      "Epoch 20: Train_cls_acc=0.9973, Train_tag_acc=0.9196, Val_cls_acc=0.6754, Val_tag_acc=0.9206\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4732,  Tagging Acc: 0.9137, Overall Acc:0.1958\n",
      "Overall Acc:0.1958, Params: (type_emb_dim: 16, dtype_emb_dim:32)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1692, Train_tag_acc=0.9049, Val_cls_acc=0.2800, Val_tag_acc=0.9236\n",
      "Epoch 2: Train_cls_acc=0.4078, Train_tag_acc=0.9200, Val_cls_acc=0.4667, Val_tag_acc=0.9187\n",
      "Epoch 3: Train_cls_acc=0.6055, Train_tag_acc=0.9201, Val_cls_acc=0.5519, Val_tag_acc=0.9235\n",
      "Epoch 4: Train_cls_acc=0.7570, Train_tag_acc=0.9202, Val_cls_acc=0.6186, Val_tag_acc=0.9254\n",
      "Epoch 5: Train_cls_acc=0.8501, Train_tag_acc=0.9199, Val_cls_acc=0.6462, Val_tag_acc=0.9234\n",
      "Epoch 6: Train_cls_acc=0.9002, Train_tag_acc=0.9198, Val_cls_acc=0.6497, Val_tag_acc=0.9239\n",
      "Epoch 7: Train_cls_acc=0.9298, Train_tag_acc=0.9200, Val_cls_acc=0.6537, Val_tag_acc=0.9199\n",
      "Epoch 8: Train_cls_acc=0.9515, Train_tag_acc=0.9197, Val_cls_acc=0.6516, Val_tag_acc=0.9213\n",
      "Epoch 9: Train_cls_acc=0.9647, Train_tag_acc=0.9196, Val_cls_acc=0.6439, Val_tag_acc=0.9211\n",
      "Epoch 10: Train_cls_acc=0.9742, Train_tag_acc=0.9196, Val_cls_acc=0.6510, Val_tag_acc=0.9168\n",
      "Epoch 11: Train_cls_acc=0.9802, Train_tag_acc=0.9199, Val_cls_acc=0.6495, Val_tag_acc=0.9184\n",
      "Epoch 12: Train_cls_acc=0.9847, Train_tag_acc=0.9194, Val_cls_acc=0.6514, Val_tag_acc=0.9241\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4737,  Tagging Acc: 0.9141, Overall Acc:0.1891\n",
      "Overall Acc:0.1891, Params: (type_emb_dim: 16, dtype_emb_dim:50)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1756, Train_tag_acc=0.9020, Val_cls_acc=0.2827, Val_tag_acc=0.9229\n",
      "Epoch 2: Train_cls_acc=0.4199, Train_tag_acc=0.9197, Val_cls_acc=0.4807, Val_tag_acc=0.9199\n",
      "Epoch 3: Train_cls_acc=0.6177, Train_tag_acc=0.9202, Val_cls_acc=0.5692, Val_tag_acc=0.9231\n",
      "Epoch 4: Train_cls_acc=0.7607, Train_tag_acc=0.9201, Val_cls_acc=0.6199, Val_tag_acc=0.9231\n",
      "Epoch 5: Train_cls_acc=0.8527, Train_tag_acc=0.9198, Val_cls_acc=0.6516, Val_tag_acc=0.9219\n",
      "Epoch 6: Train_cls_acc=0.8997, Train_tag_acc=0.9200, Val_cls_acc=0.6388, Val_tag_acc=0.9157\n",
      "Epoch 7: Train_cls_acc=0.9293, Train_tag_acc=0.9198, Val_cls_acc=0.6624, Val_tag_acc=0.9255\n",
      "Epoch 8: Train_cls_acc=0.9506, Train_tag_acc=0.9195, Val_cls_acc=0.6710, Val_tag_acc=0.9206\n",
      "Epoch 9: Train_cls_acc=0.9640, Train_tag_acc=0.9195, Val_cls_acc=0.6624, Val_tag_acc=0.9157\n",
      "Epoch 10: Train_cls_acc=0.9732, Train_tag_acc=0.9199, Val_cls_acc=0.6610, Val_tag_acc=0.9228\n",
      "Epoch 11: Train_cls_acc=0.9792, Train_tag_acc=0.9196, Val_cls_acc=0.6578, Val_tag_acc=0.9236\n",
      "Epoch 12: Train_cls_acc=0.9838, Train_tag_acc=0.9196, Val_cls_acc=0.6683, Val_tag_acc=0.9202\n",
      "Epoch 13: Train_cls_acc=0.9876, Train_tag_acc=0.9194, Val_cls_acc=0.6585, Val_tag_acc=0.9157\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4710,  Tagging Acc: 0.9157, Overall Acc:0.1864\n",
      "Overall Acc:0.1864, Params: (type_emb_dim: 16, dtype_emb_dim:64)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1521, Train_tag_acc=0.9051, Val_cls_acc=0.2431, Val_tag_acc=0.9196\n",
      "Epoch 2: Train_cls_acc=0.3755, Train_tag_acc=0.9201, Val_cls_acc=0.4432, Val_tag_acc=0.9247\n",
      "Epoch 3: Train_cls_acc=0.5769, Train_tag_acc=0.9202, Val_cls_acc=0.5464, Val_tag_acc=0.9239\n",
      "Epoch 4: Train_cls_acc=0.7305, Train_tag_acc=0.9203, Val_cls_acc=0.6117, Val_tag_acc=0.9235\n",
      "Epoch 5: Train_cls_acc=0.8332, Train_tag_acc=0.9201, Val_cls_acc=0.6434, Val_tag_acc=0.9227\n",
      "Epoch 6: Train_cls_acc=0.8911, Train_tag_acc=0.9201, Val_cls_acc=0.6568, Val_tag_acc=0.9267\n",
      "Epoch 7: Train_cls_acc=0.9246, Train_tag_acc=0.9203, Val_cls_acc=0.6478, Val_tag_acc=0.9258\n",
      "Epoch 8: Train_cls_acc=0.9476, Train_tag_acc=0.9202, Val_cls_acc=0.6549, Val_tag_acc=0.9245\n",
      "Epoch 9: Train_cls_acc=0.9617, Train_tag_acc=0.9196, Val_cls_acc=0.6453, Val_tag_acc=0.9203\n",
      "Epoch 10: Train_cls_acc=0.9707, Train_tag_acc=0.9200, Val_cls_acc=0.6562, Val_tag_acc=0.9190\n",
      "Epoch 11: Train_cls_acc=0.9780, Train_tag_acc=0.9200, Val_cls_acc=0.6626, Val_tag_acc=0.9147\n",
      "Epoch 12: Train_cls_acc=0.9827, Train_tag_acc=0.9199, Val_cls_acc=0.6631, Val_tag_acc=0.9176\n",
      "Epoch 13: Train_cls_acc=0.9864, Train_tag_acc=0.9194, Val_cls_acc=0.6560, Val_tag_acc=0.9250\n",
      "Epoch 14: Train_cls_acc=0.9898, Train_tag_acc=0.9197, Val_cls_acc=0.6645, Val_tag_acc=0.9245\n",
      "Epoch 15: Train_cls_acc=0.9920, Train_tag_acc=0.9195, Val_cls_acc=0.6656, Val_tag_acc=0.9213\n",
      "Epoch 16: Train_cls_acc=0.9934, Train_tag_acc=0.9195, Val_cls_acc=0.6622, Val_tag_acc=0.9184\n",
      "Epoch 17: Train_cls_acc=0.9950, Train_tag_acc=0.9195, Val_cls_acc=0.6622, Val_tag_acc=0.9229\n",
      "Epoch 18: Train_cls_acc=0.9959, Train_tag_acc=0.9198, Val_cls_acc=0.6570, Val_tag_acc=0.9235\n",
      "Epoch 19: Train_cls_acc=0.9966, Train_tag_acc=0.9198, Val_cls_acc=0.6614, Val_tag_acc=0.9174\n",
      "Epoch 20: Train_cls_acc=0.9970, Train_tag_acc=0.9197, Val_cls_acc=0.6643, Val_tag_acc=0.9252\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4630,  Tagging Acc: 0.9131, Overall Acc:0.2166\n",
      "Overall Acc:0.2166, Params: (type_emb_dim: 32, dtype_emb_dim:8)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1632, Train_tag_acc=0.9144, Val_cls_acc=0.2606, Val_tag_acc=0.9238\n",
      "Epoch 2: Train_cls_acc=0.3981, Train_tag_acc=0.9202, Val_cls_acc=0.4701, Val_tag_acc=0.9220\n",
      "Epoch 3: Train_cls_acc=0.5916, Train_tag_acc=0.9201, Val_cls_acc=0.5696, Val_tag_acc=0.9248\n",
      "Epoch 4: Train_cls_acc=0.7467, Train_tag_acc=0.9201, Val_cls_acc=0.6123, Val_tag_acc=0.9215\n",
      "Epoch 5: Train_cls_acc=0.8419, Train_tag_acc=0.9202, Val_cls_acc=0.6293, Val_tag_acc=0.9254\n",
      "Epoch 6: Train_cls_acc=0.8948, Train_tag_acc=0.9203, Val_cls_acc=0.6378, Val_tag_acc=0.9272\n",
      "Epoch 7: Train_cls_acc=0.9262, Train_tag_acc=0.9200, Val_cls_acc=0.6478, Val_tag_acc=0.9236\n",
      "Epoch 8: Train_cls_acc=0.9486, Train_tag_acc=0.9200, Val_cls_acc=0.6578, Val_tag_acc=0.9249\n",
      "Epoch 9: Train_cls_acc=0.9627, Train_tag_acc=0.9198, Val_cls_acc=0.6507, Val_tag_acc=0.9221\n",
      "Epoch 10: Train_cls_acc=0.9720, Train_tag_acc=0.9194, Val_cls_acc=0.6568, Val_tag_acc=0.9212\n",
      "Epoch 11: Train_cls_acc=0.9790, Train_tag_acc=0.9198, Val_cls_acc=0.6520, Val_tag_acc=0.9219\n",
      "Epoch 12: Train_cls_acc=0.9837, Train_tag_acc=0.9197, Val_cls_acc=0.6535, Val_tag_acc=0.9213\n",
      "Epoch 13: Train_cls_acc=0.9874, Train_tag_acc=0.9194, Val_cls_acc=0.6526, Val_tag_acc=0.9253\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4824,  Tagging Acc: 0.9185, Overall Acc:0.2290\n",
      "Overall Acc:0.2290, Params: (type_emb_dim: 32, dtype_emb_dim:16)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1711, Train_tag_acc=0.8995, Val_cls_acc=0.2671, Val_tag_acc=0.9261\n",
      "Epoch 2: Train_cls_acc=0.4019, Train_tag_acc=0.9199, Val_cls_acc=0.4632, Val_tag_acc=0.9182\n",
      "Epoch 3: Train_cls_acc=0.5985, Train_tag_acc=0.9201, Val_cls_acc=0.5502, Val_tag_acc=0.9250\n",
      "Epoch 4: Train_cls_acc=0.7448, Train_tag_acc=0.9201, Val_cls_acc=0.6123, Val_tag_acc=0.9216\n",
      "Epoch 5: Train_cls_acc=0.8431, Train_tag_acc=0.9200, Val_cls_acc=0.6315, Val_tag_acc=0.9167\n",
      "Epoch 6: Train_cls_acc=0.8941, Train_tag_acc=0.9196, Val_cls_acc=0.6580, Val_tag_acc=0.9257\n",
      "Epoch 7: Train_cls_acc=0.9258, Train_tag_acc=0.9197, Val_cls_acc=0.6466, Val_tag_acc=0.9235\n",
      "Epoch 8: Train_cls_acc=0.9480, Train_tag_acc=0.9199, Val_cls_acc=0.6537, Val_tag_acc=0.9218\n",
      "Epoch 9: Train_cls_acc=0.9619, Train_tag_acc=0.9196, Val_cls_acc=0.6553, Val_tag_acc=0.9201\n",
      "Epoch 10: Train_cls_acc=0.9715, Train_tag_acc=0.9197, Val_cls_acc=0.6509, Val_tag_acc=0.9247\n",
      "Epoch 11: Train_cls_acc=0.9783, Train_tag_acc=0.9194, Val_cls_acc=0.6618, Val_tag_acc=0.9163\n",
      "Epoch 12: Train_cls_acc=0.9841, Train_tag_acc=0.9196, Val_cls_acc=0.6386, Val_tag_acc=0.9215\n",
      "Epoch 13: Train_cls_acc=0.9871, Train_tag_acc=0.9198, Val_cls_acc=0.6447, Val_tag_acc=0.9190\n",
      "Epoch 14: Train_cls_acc=0.9905, Train_tag_acc=0.9194, Val_cls_acc=0.6487, Val_tag_acc=0.9252\n",
      "Epoch 15: Train_cls_acc=0.9920, Train_tag_acc=0.9197, Val_cls_acc=0.6472, Val_tag_acc=0.9230\n",
      "Epoch 16: Train_cls_acc=0.9938, Train_tag_acc=0.9196, Val_cls_acc=0.6509, Val_tag_acc=0.9256\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4819,  Tagging Acc: 0.9151, Overall Acc:0.1970\n",
      "Overall Acc:0.1970, Params: (type_emb_dim: 32, dtype_emb_dim:32)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1699, Train_tag_acc=0.9049, Val_cls_acc=0.2693, Val_tag_acc=0.9251\n",
      "Epoch 2: Train_cls_acc=0.4184, Train_tag_acc=0.9200, Val_cls_acc=0.4707, Val_tag_acc=0.9237\n",
      "Epoch 3: Train_cls_acc=0.6191, Train_tag_acc=0.9204, Val_cls_acc=0.5631, Val_tag_acc=0.9222\n",
      "Epoch 4: Train_cls_acc=0.7640, Train_tag_acc=0.9196, Val_cls_acc=0.6101, Val_tag_acc=0.9192\n",
      "Epoch 5: Train_cls_acc=0.8518, Train_tag_acc=0.9199, Val_cls_acc=0.6372, Val_tag_acc=0.9233\n",
      "Epoch 6: Train_cls_acc=0.9006, Train_tag_acc=0.9200, Val_cls_acc=0.6610, Val_tag_acc=0.9184\n",
      "Epoch 7: Train_cls_acc=0.9304, Train_tag_acc=0.9200, Val_cls_acc=0.6503, Val_tag_acc=0.9235\n",
      "Epoch 8: Train_cls_acc=0.9512, Train_tag_acc=0.9198, Val_cls_acc=0.6526, Val_tag_acc=0.9224\n",
      "Epoch 9: Train_cls_acc=0.9648, Train_tag_acc=0.9195, Val_cls_acc=0.6587, Val_tag_acc=0.9213\n",
      "Epoch 10: Train_cls_acc=0.9729, Train_tag_acc=0.9197, Val_cls_acc=0.6558, Val_tag_acc=0.9224\n",
      "Epoch 11: Train_cls_acc=0.9796, Train_tag_acc=0.9193, Val_cls_acc=0.6674, Val_tag_acc=0.9251\n",
      "Epoch 12: Train_cls_acc=0.9844, Train_tag_acc=0.9197, Val_cls_acc=0.6520, Val_tag_acc=0.9207\n",
      "Epoch 13: Train_cls_acc=0.9876, Train_tag_acc=0.9193, Val_cls_acc=0.6622, Val_tag_acc=0.9187\n",
      "Epoch 14: Train_cls_acc=0.9893, Train_tag_acc=0.9190, Val_cls_acc=0.6693, Val_tag_acc=0.9190\n",
      "Epoch 15: Train_cls_acc=0.9922, Train_tag_acc=0.9195, Val_cls_acc=0.6622, Val_tag_acc=0.9250\n",
      "Epoch 16: Train_cls_acc=0.9935, Train_tag_acc=0.9200, Val_cls_acc=0.6772, Val_tag_acc=0.9245\n",
      "Epoch 17: Train_cls_acc=0.9950, Train_tag_acc=0.9193, Val_cls_acc=0.6739, Val_tag_acc=0.9251\n",
      "Epoch 18: Train_cls_acc=0.9959, Train_tag_acc=0.9192, Val_cls_acc=0.6580, Val_tag_acc=0.9227\n",
      "Epoch 19: Train_cls_acc=0.9963, Train_tag_acc=0.9187, Val_cls_acc=0.6624, Val_tag_acc=0.9217\n",
      "Epoch 20: Train_cls_acc=0.9970, Train_tag_acc=0.9194, Val_cls_acc=0.6693, Val_tag_acc=0.9244\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4734,  Tagging Acc: 0.9103, Overall Acc:0.2040\n",
      "Overall Acc:0.2040, Params: (type_emb_dim: 32, dtype_emb_dim:50)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1821, Train_tag_acc=0.8981, Val_cls_acc=0.3017, Val_tag_acc=0.9257\n",
      "Epoch 2: Train_cls_acc=0.4320, Train_tag_acc=0.9201, Val_cls_acc=0.4822, Val_tag_acc=0.9212\n",
      "Epoch 3: Train_cls_acc=0.6267, Train_tag_acc=0.9198, Val_cls_acc=0.5690, Val_tag_acc=0.9246\n",
      "Epoch 4: Train_cls_acc=0.7666, Train_tag_acc=0.9197, Val_cls_acc=0.6192, Val_tag_acc=0.9229\n",
      "Epoch 5: Train_cls_acc=0.8557, Train_tag_acc=0.9200, Val_cls_acc=0.6303, Val_tag_acc=0.9188\n",
      "Epoch 6: Train_cls_acc=0.9021, Train_tag_acc=0.9194, Val_cls_acc=0.6359, Val_tag_acc=0.9238\n",
      "Epoch 7: Train_cls_acc=0.9322, Train_tag_acc=0.9197, Val_cls_acc=0.6437, Val_tag_acc=0.9232\n",
      "Epoch 8: Train_cls_acc=0.9514, Train_tag_acc=0.9198, Val_cls_acc=0.6476, Val_tag_acc=0.9209\n",
      "Epoch 9: Train_cls_acc=0.9642, Train_tag_acc=0.9194, Val_cls_acc=0.6482, Val_tag_acc=0.9247\n",
      "Epoch 10: Train_cls_acc=0.9732, Train_tag_acc=0.9196, Val_cls_acc=0.6499, Val_tag_acc=0.9253\n",
      "Epoch 11: Train_cls_acc=0.9791, Train_tag_acc=0.9193, Val_cls_acc=0.6574, Val_tag_acc=0.9220\n",
      "Epoch 12: Train_cls_acc=0.9843, Train_tag_acc=0.9193, Val_cls_acc=0.6666, Val_tag_acc=0.9260\n",
      "Epoch 13: Train_cls_acc=0.9880, Train_tag_acc=0.9198, Val_cls_acc=0.6599, Val_tag_acc=0.9236\n",
      "Epoch 14: Train_cls_acc=0.9899, Train_tag_acc=0.9195, Val_cls_acc=0.6603, Val_tag_acc=0.9257\n",
      "Epoch 15: Train_cls_acc=0.9924, Train_tag_acc=0.9195, Val_cls_acc=0.6704, Val_tag_acc=0.9215\n",
      "Epoch 16: Train_cls_acc=0.9938, Train_tag_acc=0.9192, Val_cls_acc=0.6655, Val_tag_acc=0.9240\n",
      "Epoch 17: Train_cls_acc=0.9949, Train_tag_acc=0.9195, Val_cls_acc=0.6658, Val_tag_acc=0.9262\n",
      "Epoch 18: Train_cls_acc=0.9961, Train_tag_acc=0.9193, Val_cls_acc=0.6699, Val_tag_acc=0.9217\n",
      "Epoch 19: Train_cls_acc=0.9962, Train_tag_acc=0.9194, Val_cls_acc=0.6678, Val_tag_acc=0.9198\n",
      "Epoch 20: Train_cls_acc=0.9970, Train_tag_acc=0.9195, Val_cls_acc=0.6699, Val_tag_acc=0.9175\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4757,  Tagging Acc: 0.9098, Overall Acc:0.2052\n",
      "Overall Acc:0.2052, Params: (type_emb_dim: 32, dtype_emb_dim:64)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1656, Train_tag_acc=0.9061, Val_cls_acc=0.2656, Val_tag_acc=0.9264\n",
      "Epoch 2: Train_cls_acc=0.4087, Train_tag_acc=0.9200, Val_cls_acc=0.4916, Val_tag_acc=0.9212\n",
      "Epoch 3: Train_cls_acc=0.6027, Train_tag_acc=0.9204, Val_cls_acc=0.5612, Val_tag_acc=0.9217\n",
      "Epoch 4: Train_cls_acc=0.7514, Train_tag_acc=0.9206, Val_cls_acc=0.6119, Val_tag_acc=0.9219\n",
      "Epoch 5: Train_cls_acc=0.8471, Train_tag_acc=0.9197, Val_cls_acc=0.6330, Val_tag_acc=0.9236\n",
      "Epoch 6: Train_cls_acc=0.8979, Train_tag_acc=0.9199, Val_cls_acc=0.6476, Val_tag_acc=0.9236\n",
      "Epoch 7: Train_cls_acc=0.9276, Train_tag_acc=0.9199, Val_cls_acc=0.6637, Val_tag_acc=0.9230\n",
      "Epoch 8: Train_cls_acc=0.9497, Train_tag_acc=0.9198, Val_cls_acc=0.6388, Val_tag_acc=0.9147\n",
      "Epoch 9: Train_cls_acc=0.9627, Train_tag_acc=0.9200, Val_cls_acc=0.6482, Val_tag_acc=0.9179\n",
      "Epoch 10: Train_cls_acc=0.9732, Train_tag_acc=0.9197, Val_cls_acc=0.6486, Val_tag_acc=0.9218\n",
      "Epoch 11: Train_cls_acc=0.9800, Train_tag_acc=0.9197, Val_cls_acc=0.6436, Val_tag_acc=0.9240\n",
      "Epoch 12: Train_cls_acc=0.9848, Train_tag_acc=0.9196, Val_cls_acc=0.6413, Val_tag_acc=0.9172\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4888,  Tagging Acc: 0.9160, Overall Acc:0.2199\n",
      "Overall Acc:0.2199, Params: (type_emb_dim: 50, dtype_emb_dim:8)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1685, Train_tag_acc=0.9117, Val_cls_acc=0.2838, Val_tag_acc=0.9203\n",
      "Epoch 2: Train_cls_acc=0.4162, Train_tag_acc=0.9200, Val_cls_acc=0.4621, Val_tag_acc=0.9261\n",
      "Epoch 3: Train_cls_acc=0.6108, Train_tag_acc=0.9200, Val_cls_acc=0.5614, Val_tag_acc=0.9252\n",
      "Epoch 4: Train_cls_acc=0.7565, Train_tag_acc=0.9203, Val_cls_acc=0.6238, Val_tag_acc=0.9212\n",
      "Epoch 5: Train_cls_acc=0.8517, Train_tag_acc=0.9197, Val_cls_acc=0.6332, Val_tag_acc=0.9210\n",
      "Epoch 6: Train_cls_acc=0.8994, Train_tag_acc=0.9201, Val_cls_acc=0.6395, Val_tag_acc=0.9185\n",
      "Epoch 7: Train_cls_acc=0.9313, Train_tag_acc=0.9200, Val_cls_acc=0.6597, Val_tag_acc=0.9243\n",
      "Epoch 8: Train_cls_acc=0.9515, Train_tag_acc=0.9199, Val_cls_acc=0.6491, Val_tag_acc=0.9180\n",
      "Epoch 9: Train_cls_acc=0.9636, Train_tag_acc=0.9199, Val_cls_acc=0.6562, Val_tag_acc=0.9229\n",
      "Epoch 10: Train_cls_acc=0.9732, Train_tag_acc=0.9199, Val_cls_acc=0.6474, Val_tag_acc=0.9202\n",
      "Epoch 11: Train_cls_acc=0.9803, Train_tag_acc=0.9198, Val_cls_acc=0.6493, Val_tag_acc=0.9170\n",
      "Epoch 12: Train_cls_acc=0.9841, Train_tag_acc=0.9196, Val_cls_acc=0.6437, Val_tag_acc=0.9178\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4854,  Tagging Acc: 0.9169, Overall Acc:0.1960\n",
      "Overall Acc:0.1960, Params: (type_emb_dim: 50, dtype_emb_dim:16)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1803, Train_tag_acc=0.9039, Val_cls_acc=0.3115, Val_tag_acc=0.9270\n",
      "Epoch 2: Train_cls_acc=0.4212, Train_tag_acc=0.9199, Val_cls_acc=0.4832, Val_tag_acc=0.9268\n",
      "Epoch 3: Train_cls_acc=0.6202, Train_tag_acc=0.9198, Val_cls_acc=0.5681, Val_tag_acc=0.9251\n",
      "Epoch 4: Train_cls_acc=0.7638, Train_tag_acc=0.9201, Val_cls_acc=0.6272, Val_tag_acc=0.9227\n",
      "Epoch 5: Train_cls_acc=0.8505, Train_tag_acc=0.9202, Val_cls_acc=0.6499, Val_tag_acc=0.9245\n",
      "Epoch 6: Train_cls_acc=0.9002, Train_tag_acc=0.9196, Val_cls_acc=0.6464, Val_tag_acc=0.9152\n",
      "Epoch 7: Train_cls_acc=0.9294, Train_tag_acc=0.9197, Val_cls_acc=0.6562, Val_tag_acc=0.9258\n",
      "Epoch 8: Train_cls_acc=0.9518, Train_tag_acc=0.9197, Val_cls_acc=0.6589, Val_tag_acc=0.9169\n",
      "Epoch 9: Train_cls_acc=0.9652, Train_tag_acc=0.9196, Val_cls_acc=0.6626, Val_tag_acc=0.9174\n",
      "Epoch 10: Train_cls_acc=0.9735, Train_tag_acc=0.9194, Val_cls_acc=0.6616, Val_tag_acc=0.9229\n",
      "Epoch 11: Train_cls_acc=0.9801, Train_tag_acc=0.9194, Val_cls_acc=0.6606, Val_tag_acc=0.9216\n",
      "Epoch 12: Train_cls_acc=0.9846, Train_tag_acc=0.9198, Val_cls_acc=0.6622, Val_tag_acc=0.9245\n",
      "Epoch 13: Train_cls_acc=0.9877, Train_tag_acc=0.9195, Val_cls_acc=0.6647, Val_tag_acc=0.9229\n",
      "Epoch 14: Train_cls_acc=0.9907, Train_tag_acc=0.9195, Val_cls_acc=0.6557, Val_tag_acc=0.9237\n",
      "Epoch 15: Train_cls_acc=0.9926, Train_tag_acc=0.9198, Val_cls_acc=0.6741, Val_tag_acc=0.9236\n",
      "Epoch 16: Train_cls_acc=0.9941, Train_tag_acc=0.9197, Val_cls_acc=0.6610, Val_tag_acc=0.9234\n",
      "Epoch 17: Train_cls_acc=0.9952, Train_tag_acc=0.9194, Val_cls_acc=0.6570, Val_tag_acc=0.9239\n",
      "Epoch 18: Train_cls_acc=0.9957, Train_tag_acc=0.9194, Val_cls_acc=0.6668, Val_tag_acc=0.9272\n",
      "Epoch 19: Train_cls_acc=0.9964, Train_tag_acc=0.9193, Val_cls_acc=0.6582, Val_tag_acc=0.9252\n",
      "Epoch 20: Train_cls_acc=0.9969, Train_tag_acc=0.9194, Val_cls_acc=0.6678, Val_tag_acc=0.9236\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4759,  Tagging Acc: 0.9151, Overall Acc:0.2007\n",
      "Overall Acc:0.2007, Params: (type_emb_dim: 50, dtype_emb_dim:32)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1804, Train_tag_acc=0.9035, Val_cls_acc=0.2827, Val_tag_acc=0.9251\n",
      "Epoch 2: Train_cls_acc=0.4264, Train_tag_acc=0.9198, Val_cls_acc=0.4738, Val_tag_acc=0.9256\n",
      "Epoch 3: Train_cls_acc=0.6249, Train_tag_acc=0.9199, Val_cls_acc=0.5706, Val_tag_acc=0.9255\n",
      "Epoch 4: Train_cls_acc=0.7690, Train_tag_acc=0.9197, Val_cls_acc=0.6297, Val_tag_acc=0.9256\n",
      "Epoch 5: Train_cls_acc=0.8540, Train_tag_acc=0.9199, Val_cls_acc=0.6326, Val_tag_acc=0.9226\n",
      "Epoch 6: Train_cls_acc=0.9008, Train_tag_acc=0.9197, Val_cls_acc=0.6512, Val_tag_acc=0.9237\n",
      "Epoch 7: Train_cls_acc=0.9306, Train_tag_acc=0.9197, Val_cls_acc=0.6505, Val_tag_acc=0.9185\n",
      "Epoch 8: Train_cls_acc=0.9514, Train_tag_acc=0.9195, Val_cls_acc=0.6547, Val_tag_acc=0.9173\n",
      "Epoch 9: Train_cls_acc=0.9646, Train_tag_acc=0.9195, Val_cls_acc=0.6562, Val_tag_acc=0.9208\n",
      "Epoch 10: Train_cls_acc=0.9729, Train_tag_acc=0.9197, Val_cls_acc=0.6545, Val_tag_acc=0.9253\n",
      "Epoch 11: Train_cls_acc=0.9795, Train_tag_acc=0.9199, Val_cls_acc=0.6514, Val_tag_acc=0.9258\n",
      "Epoch 12: Train_cls_acc=0.9845, Train_tag_acc=0.9194, Val_cls_acc=0.6606, Val_tag_acc=0.9173\n",
      "Epoch 13: Train_cls_acc=0.9878, Train_tag_acc=0.9195, Val_cls_acc=0.6518, Val_tag_acc=0.9178\n",
      "Epoch 14: Train_cls_acc=0.9907, Train_tag_acc=0.9198, Val_cls_acc=0.6641, Val_tag_acc=0.9231\n",
      "Epoch 15: Train_cls_acc=0.9923, Train_tag_acc=0.9192, Val_cls_acc=0.6649, Val_tag_acc=0.9220\n",
      "Epoch 16: Train_cls_acc=0.9944, Train_tag_acc=0.9195, Val_cls_acc=0.6562, Val_tag_acc=0.9258\n",
      "Epoch 17: Train_cls_acc=0.9950, Train_tag_acc=0.9194, Val_cls_acc=0.6501, Val_tag_acc=0.9250\n",
      "Epoch 18: Train_cls_acc=0.9958, Train_tag_acc=0.9194, Val_cls_acc=0.6572, Val_tag_acc=0.9224\n",
      "Epoch 19: Train_cls_acc=0.9965, Train_tag_acc=0.9193, Val_cls_acc=0.6664, Val_tag_acc=0.9215\n",
      "Epoch 20: Train_cls_acc=0.9971, Train_tag_acc=0.9194, Val_cls_acc=0.6718, Val_tag_acc=0.9240\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4856,  Tagging Acc: 0.9170, Overall Acc:0.1888\n",
      "Overall Acc:0.1888, Params: (type_emb_dim: 50, dtype_emb_dim:50)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1915, Train_tag_acc=0.9051, Val_cls_acc=0.3082, Val_tag_acc=0.9249\n",
      "Epoch 2: Train_cls_acc=0.4419, Train_tag_acc=0.9198, Val_cls_acc=0.4722, Val_tag_acc=0.9193\n",
      "Epoch 3: Train_cls_acc=0.6330, Train_tag_acc=0.9199, Val_cls_acc=0.5583, Val_tag_acc=0.9240\n",
      "Epoch 4: Train_cls_acc=0.7730, Train_tag_acc=0.9197, Val_cls_acc=0.6207, Val_tag_acc=0.9235\n",
      "Epoch 5: Train_cls_acc=0.8579, Train_tag_acc=0.9196, Val_cls_acc=0.6299, Val_tag_acc=0.9226\n",
      "Epoch 6: Train_cls_acc=0.9018, Train_tag_acc=0.9197, Val_cls_acc=0.6526, Val_tag_acc=0.9182\n",
      "Epoch 7: Train_cls_acc=0.9313, Train_tag_acc=0.9196, Val_cls_acc=0.6478, Val_tag_acc=0.9225\n",
      "Epoch 8: Train_cls_acc=0.9516, Train_tag_acc=0.9197, Val_cls_acc=0.6566, Val_tag_acc=0.9248\n",
      "Epoch 9: Train_cls_acc=0.9650, Train_tag_acc=0.9196, Val_cls_acc=0.6583, Val_tag_acc=0.9258\n",
      "Epoch 10: Train_cls_acc=0.9731, Train_tag_acc=0.9196, Val_cls_acc=0.6601, Val_tag_acc=0.9203\n",
      "Epoch 11: Train_cls_acc=0.9798, Train_tag_acc=0.9195, Val_cls_acc=0.6693, Val_tag_acc=0.9251\n",
      "Epoch 12: Train_cls_acc=0.9848, Train_tag_acc=0.9192, Val_cls_acc=0.6595, Val_tag_acc=0.9233\n",
      "Epoch 13: Train_cls_acc=0.9880, Train_tag_acc=0.9194, Val_cls_acc=0.6551, Val_tag_acc=0.9216\n",
      "Epoch 14: Train_cls_acc=0.9905, Train_tag_acc=0.9194, Val_cls_acc=0.6693, Val_tag_acc=0.9224\n",
      "Epoch 15: Train_cls_acc=0.9927, Train_tag_acc=0.9195, Val_cls_acc=0.6612, Val_tag_acc=0.9152\n",
      "Epoch 16: Train_cls_acc=0.9939, Train_tag_acc=0.9193, Val_cls_acc=0.6722, Val_tag_acc=0.9206\n",
      "Epoch 17: Train_cls_acc=0.9949, Train_tag_acc=0.9194, Val_cls_acc=0.6553, Val_tag_acc=0.9193\n",
      "Epoch 18: Train_cls_acc=0.9956, Train_tag_acc=0.9194, Val_cls_acc=0.6641, Val_tag_acc=0.9251\n",
      "Epoch 19: Train_cls_acc=0.9962, Train_tag_acc=0.9191, Val_cls_acc=0.6572, Val_tag_acc=0.9250\n",
      "Epoch 20: Train_cls_acc=0.9967, Train_tag_acc=0.9193, Val_cls_acc=0.6639, Val_tag_acc=0.9176\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4950,  Tagging Acc: 0.9135, Overall Acc:0.2141\n",
      "Overall Acc:0.2141, Params: (type_emb_dim: 50, dtype_emb_dim:64)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1737, Train_tag_acc=0.9054, Val_cls_acc=0.2702, Val_tag_acc=0.9192\n",
      "Epoch 2: Train_cls_acc=0.4213, Train_tag_acc=0.9198, Val_cls_acc=0.4717, Val_tag_acc=0.9283\n",
      "Epoch 3: Train_cls_acc=0.6106, Train_tag_acc=0.9199, Val_cls_acc=0.5604, Val_tag_acc=0.9180\n",
      "Epoch 4: Train_cls_acc=0.7601, Train_tag_acc=0.9200, Val_cls_acc=0.6249, Val_tag_acc=0.9249\n",
      "Epoch 5: Train_cls_acc=0.8479, Train_tag_acc=0.9196, Val_cls_acc=0.6340, Val_tag_acc=0.9256\n",
      "Epoch 6: Train_cls_acc=0.8990, Train_tag_acc=0.9198, Val_cls_acc=0.6437, Val_tag_acc=0.9250\n",
      "Epoch 7: Train_cls_acc=0.9295, Train_tag_acc=0.9199, Val_cls_acc=0.6495, Val_tag_acc=0.9234\n",
      "Epoch 8: Train_cls_acc=0.9500, Train_tag_acc=0.9194, Val_cls_acc=0.6510, Val_tag_acc=0.9224\n",
      "Epoch 9: Train_cls_acc=0.9637, Train_tag_acc=0.9199, Val_cls_acc=0.6413, Val_tag_acc=0.9249\n",
      "Epoch 10: Train_cls_acc=0.9727, Train_tag_acc=0.9194, Val_cls_acc=0.6522, Val_tag_acc=0.9194\n",
      "Epoch 11: Train_cls_acc=0.9800, Train_tag_acc=0.9197, Val_cls_acc=0.6591, Val_tag_acc=0.9242\n",
      "Epoch 12: Train_cls_acc=0.9856, Train_tag_acc=0.9196, Val_cls_acc=0.6526, Val_tag_acc=0.9179\n",
      "Epoch 13: Train_cls_acc=0.9881, Train_tag_acc=0.9195, Val_cls_acc=0.6545, Val_tag_acc=0.9197\n",
      "Epoch 14: Train_cls_acc=0.9910, Train_tag_acc=0.9195, Val_cls_acc=0.6558, Val_tag_acc=0.9251\n",
      "Epoch 15: Train_cls_acc=0.9925, Train_tag_acc=0.9192, Val_cls_acc=0.6545, Val_tag_acc=0.9182\n",
      "Epoch 16: Train_cls_acc=0.9940, Train_tag_acc=0.9194, Val_cls_acc=0.6555, Val_tag_acc=0.9237\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4888,  Tagging Acc: 0.9161, Overall Acc:0.2357\n",
      "Overall Acc:0.2357, Params: (type_emb_dim: 64, dtype_emb_dim:8)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1777, Train_tag_acc=0.9063, Val_cls_acc=0.2821, Val_tag_acc=0.9237\n",
      "Epoch 2: Train_cls_acc=0.4245, Train_tag_acc=0.9200, Val_cls_acc=0.4738, Val_tag_acc=0.9187\n",
      "Epoch 3: Train_cls_acc=0.6155, Train_tag_acc=0.9199, Val_cls_acc=0.5692, Val_tag_acc=0.9242\n",
      "Epoch 4: Train_cls_acc=0.7620, Train_tag_acc=0.9199, Val_cls_acc=0.6222, Val_tag_acc=0.9259\n",
      "Epoch 5: Train_cls_acc=0.8534, Train_tag_acc=0.9200, Val_cls_acc=0.6365, Val_tag_acc=0.9216\n",
      "Epoch 6: Train_cls_acc=0.9012, Train_tag_acc=0.9198, Val_cls_acc=0.6411, Val_tag_acc=0.9175\n",
      "Epoch 7: Train_cls_acc=0.9305, Train_tag_acc=0.9199, Val_cls_acc=0.6558, Val_tag_acc=0.9252\n",
      "Epoch 8: Train_cls_acc=0.9506, Train_tag_acc=0.9197, Val_cls_acc=0.6558, Val_tag_acc=0.9184\n",
      "Epoch 9: Train_cls_acc=0.9647, Train_tag_acc=0.9197, Val_cls_acc=0.6624, Val_tag_acc=0.9254\n",
      "Epoch 10: Train_cls_acc=0.9727, Train_tag_acc=0.9197, Val_cls_acc=0.6645, Val_tag_acc=0.9213\n",
      "Epoch 11: Train_cls_acc=0.9799, Train_tag_acc=0.9194, Val_cls_acc=0.6557, Val_tag_acc=0.9258\n",
      "Epoch 12: Train_cls_acc=0.9848, Train_tag_acc=0.9196, Val_cls_acc=0.6608, Val_tag_acc=0.9238\n",
      "Epoch 13: Train_cls_acc=0.9877, Train_tag_acc=0.9195, Val_cls_acc=0.6647, Val_tag_acc=0.9165\n",
      "Epoch 14: Train_cls_acc=0.9896, Train_tag_acc=0.9198, Val_cls_acc=0.6626, Val_tag_acc=0.9242\n",
      "Epoch 15: Train_cls_acc=0.9927, Train_tag_acc=0.9196, Val_cls_acc=0.6679, Val_tag_acc=0.9223\n",
      "Epoch 16: Train_cls_acc=0.9937, Train_tag_acc=0.9194, Val_cls_acc=0.6701, Val_tag_acc=0.9224\n",
      "Epoch 17: Train_cls_acc=0.9953, Train_tag_acc=0.9195, Val_cls_acc=0.6697, Val_tag_acc=0.9213\n",
      "Epoch 18: Train_cls_acc=0.9958, Train_tag_acc=0.9195, Val_cls_acc=0.6703, Val_tag_acc=0.9214\n",
      "Epoch 19: Train_cls_acc=0.9965, Train_tag_acc=0.9193, Val_cls_acc=0.6649, Val_tag_acc=0.9213\n",
      "Epoch 20: Train_cls_acc=0.9971, Train_tag_acc=0.9197, Val_cls_acc=0.6701, Val_tag_acc=0.9241\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4784,  Tagging Acc: 0.9106, Overall Acc:0.1720\n",
      "Overall Acc:0.1720, Params: (type_emb_dim: 64, dtype_emb_dim:16)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1890, Train_tag_acc=0.9040, Val_cls_acc=0.2792, Val_tag_acc=0.9234\n",
      "Epoch 2: Train_cls_acc=0.4333, Train_tag_acc=0.9198, Val_cls_acc=0.4655, Val_tag_acc=0.9211\n",
      "Epoch 3: Train_cls_acc=0.6334, Train_tag_acc=0.9200, Val_cls_acc=0.5765, Val_tag_acc=0.9210\n",
      "Epoch 4: Train_cls_acc=0.7724, Train_tag_acc=0.9203, Val_cls_acc=0.6284, Val_tag_acc=0.9209\n",
      "Epoch 5: Train_cls_acc=0.8571, Train_tag_acc=0.9198, Val_cls_acc=0.6437, Val_tag_acc=0.9194\n",
      "Epoch 6: Train_cls_acc=0.9028, Train_tag_acc=0.9195, Val_cls_acc=0.6489, Val_tag_acc=0.9260\n",
      "Epoch 7: Train_cls_acc=0.9309, Train_tag_acc=0.9198, Val_cls_acc=0.6443, Val_tag_acc=0.9230\n",
      "Epoch 8: Train_cls_acc=0.9529, Train_tag_acc=0.9195, Val_cls_acc=0.6509, Val_tag_acc=0.9242\n",
      "Epoch 9: Train_cls_acc=0.9645, Train_tag_acc=0.9196, Val_cls_acc=0.6589, Val_tag_acc=0.9153\n",
      "Epoch 10: Train_cls_acc=0.9733, Train_tag_acc=0.9194, Val_cls_acc=0.6593, Val_tag_acc=0.9224\n",
      "Epoch 11: Train_cls_acc=0.9799, Train_tag_acc=0.9199, Val_cls_acc=0.6545, Val_tag_acc=0.9184\n",
      "Epoch 12: Train_cls_acc=0.9847, Train_tag_acc=0.9195, Val_cls_acc=0.6608, Val_tag_acc=0.9249\n",
      "Epoch 13: Train_cls_acc=0.9883, Train_tag_acc=0.9198, Val_cls_acc=0.6583, Val_tag_acc=0.9254\n",
      "Epoch 14: Train_cls_acc=0.9904, Train_tag_acc=0.9195, Val_cls_acc=0.6662, Val_tag_acc=0.9234\n",
      "Epoch 15: Train_cls_acc=0.9926, Train_tag_acc=0.9196, Val_cls_acc=0.6681, Val_tag_acc=0.9116\n",
      "Epoch 16: Train_cls_acc=0.9942, Train_tag_acc=0.9196, Val_cls_acc=0.6576, Val_tag_acc=0.9233\n",
      "Epoch 17: Train_cls_acc=0.9955, Train_tag_acc=0.9192, Val_cls_acc=0.6704, Val_tag_acc=0.9263\n",
      "Epoch 18: Train_cls_acc=0.9959, Train_tag_acc=0.9194, Val_cls_acc=0.6580, Val_tag_acc=0.9175\n",
      "Epoch 19: Train_cls_acc=0.9967, Train_tag_acc=0.9194, Val_cls_acc=0.6630, Val_tag_acc=0.9177\n",
      "Epoch 20: Train_cls_acc=0.9970, Train_tag_acc=0.9194, Val_cls_acc=0.6620, Val_tag_acc=0.9261\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4814,  Tagging Acc: 0.9148, Overall Acc:0.1866\n",
      "Overall Acc:0.1866, Params: (type_emb_dim: 64, dtype_emb_dim:32)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1948, Train_tag_acc=0.9091, Val_cls_acc=0.3167, Val_tag_acc=0.9185\n",
      "Epoch 2: Train_cls_acc=0.4484, Train_tag_acc=0.9200, Val_cls_acc=0.4749, Val_tag_acc=0.9155\n",
      "Epoch 3: Train_cls_acc=0.6447, Train_tag_acc=0.9200, Val_cls_acc=0.5788, Val_tag_acc=0.9238\n",
      "Epoch 4: Train_cls_acc=0.7815, Train_tag_acc=0.9198, Val_cls_acc=0.6153, Val_tag_acc=0.9240\n",
      "Epoch 5: Train_cls_acc=0.8609, Train_tag_acc=0.9199, Val_cls_acc=0.6278, Val_tag_acc=0.9235\n",
      "Epoch 6: Train_cls_acc=0.9051, Train_tag_acc=0.9199, Val_cls_acc=0.6447, Val_tag_acc=0.9210\n",
      "Epoch 7: Train_cls_acc=0.9327, Train_tag_acc=0.9196, Val_cls_acc=0.6489, Val_tag_acc=0.9193\n",
      "Epoch 8: Train_cls_acc=0.9526, Train_tag_acc=0.9195, Val_cls_acc=0.6476, Val_tag_acc=0.9220\n",
      "Epoch 9: Train_cls_acc=0.9646, Train_tag_acc=0.9196, Val_cls_acc=0.6549, Val_tag_acc=0.9238\n",
      "Epoch 10: Train_cls_acc=0.9737, Train_tag_acc=0.9194, Val_cls_acc=0.6591, Val_tag_acc=0.9228\n",
      "Epoch 11: Train_cls_acc=0.9791, Train_tag_acc=0.9198, Val_cls_acc=0.6530, Val_tag_acc=0.9196\n",
      "Epoch 12: Train_cls_acc=0.9843, Train_tag_acc=0.9194, Val_cls_acc=0.6534, Val_tag_acc=0.9235\n",
      "Epoch 13: Train_cls_acc=0.9878, Train_tag_acc=0.9199, Val_cls_acc=0.6522, Val_tag_acc=0.9224\n",
      "Epoch 14: Train_cls_acc=0.9902, Train_tag_acc=0.9192, Val_cls_acc=0.6639, Val_tag_acc=0.9201\n",
      "Epoch 15: Train_cls_acc=0.9926, Train_tag_acc=0.9192, Val_cls_acc=0.6605, Val_tag_acc=0.9245\n",
      "Epoch 16: Train_cls_acc=0.9941, Train_tag_acc=0.9191, Val_cls_acc=0.6593, Val_tag_acc=0.9188\n",
      "Epoch 17: Train_cls_acc=0.9945, Train_tag_acc=0.9193, Val_cls_acc=0.6585, Val_tag_acc=0.9148\n",
      "Epoch 18: Train_cls_acc=0.9957, Train_tag_acc=0.9195, Val_cls_acc=0.6691, Val_tag_acc=0.9258\n",
      "Epoch 19: Train_cls_acc=0.9962, Train_tag_acc=0.9193, Val_cls_acc=0.6639, Val_tag_acc=0.9240\n",
      "Epoch 20: Train_cls_acc=0.9969, Train_tag_acc=0.9195, Val_cls_acc=0.6683, Val_tag_acc=0.9241\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4789,  Tagging Acc: 0.9166, Overall Acc:0.1873\n",
      "Overall Acc:0.1873, Params: (type_emb_dim: 64, dtype_emb_dim:50)\n",
      "Initialize linear model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.1925, Train_tag_acc=0.9090, Val_cls_acc=0.2838, Val_tag_acc=0.9248\n",
      "Epoch 2: Train_cls_acc=0.4528, Train_tag_acc=0.9197, Val_cls_acc=0.4897, Val_tag_acc=0.9184\n",
      "Epoch 3: Train_cls_acc=0.6474, Train_tag_acc=0.9200, Val_cls_acc=0.5856, Val_tag_acc=0.9244\n",
      "Epoch 4: Train_cls_acc=0.7822, Train_tag_acc=0.9199, Val_cls_acc=0.6226, Val_tag_acc=0.9227\n",
      "Epoch 5: Train_cls_acc=0.8614, Train_tag_acc=0.9199, Val_cls_acc=0.6378, Val_tag_acc=0.9243\n",
      "Epoch 6: Train_cls_acc=0.9050, Train_tag_acc=0.9197, Val_cls_acc=0.6582, Val_tag_acc=0.9222\n",
      "Epoch 7: Train_cls_acc=0.9323, Train_tag_acc=0.9194, Val_cls_acc=0.6570, Val_tag_acc=0.9237\n",
      "Epoch 8: Train_cls_acc=0.9516, Train_tag_acc=0.9195, Val_cls_acc=0.6574, Val_tag_acc=0.9210\n",
      "Epoch 9: Train_cls_acc=0.9630, Train_tag_acc=0.9192, Val_cls_acc=0.6653, Val_tag_acc=0.9205\n",
      "Epoch 10: Train_cls_acc=0.9727, Train_tag_acc=0.9196, Val_cls_acc=0.6593, Val_tag_acc=0.9259\n",
      "Epoch 11: Train_cls_acc=0.9790, Train_tag_acc=0.9193, Val_cls_acc=0.6612, Val_tag_acc=0.9219\n",
      "Epoch 12: Train_cls_acc=0.9842, Train_tag_acc=0.9193, Val_cls_acc=0.6564, Val_tag_acc=0.9263\n",
      "Epoch 13: Train_cls_acc=0.9875, Train_tag_acc=0.9193, Val_cls_acc=0.6555, Val_tag_acc=0.9177\n",
      "Epoch 14: Train_cls_acc=0.9902, Train_tag_acc=0.9193, Val_cls_acc=0.6655, Val_tag_acc=0.9255\n",
      "Epoch 15: Train_cls_acc=0.9922, Train_tag_acc=0.9191, Val_cls_acc=0.6693, Val_tag_acc=0.9214\n",
      "Epoch 16: Train_cls_acc=0.9940, Train_tag_acc=0.9193, Val_cls_acc=0.6587, Val_tag_acc=0.9242\n",
      "Epoch 17: Train_cls_acc=0.9947, Train_tag_acc=0.9196, Val_cls_acc=0.6580, Val_tag_acc=0.9174\n",
      "Epoch 18: Train_cls_acc=0.9958, Train_tag_acc=0.9188, Val_cls_acc=0.6591, Val_tag_acc=0.9238\n",
      "Epoch 19: Train_cls_acc=0.9963, Train_tag_acc=0.9195, Val_cls_acc=0.6775, Val_tag_acc=0.9204\n",
      "Epoch 20: Train_cls_acc=0.9969, Train_tag_acc=0.9189, Val_cls_acc=0.6770, Val_tag_acc=0.9201\n",
      "===============Testing Model=================\n",
      "Test set linear —  Classification Acc: 0.4893,  Tagging Acc: 0.9167, Overall Acc:0.1908\n",
      "Overall Acc:0.1908, Params: (type_emb_dim: 64, dtype_emb_dim:64)\n",
      "Best accuracy of linear - Acc: 0.23573200992555832, params: (type_emb_dim: 64, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.2869, Train_tag_acc=0.9125, Val_cls_acc=0.4880, Val_tag_acc=0.9219\n",
      "Epoch 2: Train_cls_acc=0.7099, Train_tag_acc=0.9202, Val_cls_acc=0.5923, Val_tag_acc=0.9238\n",
      "Epoch 3: Train_cls_acc=0.8905, Train_tag_acc=0.9200, Val_cls_acc=0.5955, Val_tag_acc=0.9208\n",
      "Epoch 4: Train_cls_acc=0.9453, Train_tag_acc=0.9203, Val_cls_acc=0.6384, Val_tag_acc=0.9204\n",
      "Epoch 5: Train_cls_acc=0.9681, Train_tag_acc=0.9203, Val_cls_acc=0.6209, Val_tag_acc=0.9257\n",
      "Epoch 6: Train_cls_acc=0.9793, Train_tag_acc=0.9204, Val_cls_acc=0.6338, Val_tag_acc=0.9250\n",
      "Epoch 7: Train_cls_acc=0.9858, Train_tag_acc=0.9203, Val_cls_acc=0.6382, Val_tag_acc=0.9204\n",
      "Epoch 8: Train_cls_acc=0.9905, Train_tag_acc=0.9204, Val_cls_acc=0.6238, Val_tag_acc=0.9176\n",
      "Epoch 9: Train_cls_acc=0.9929, Train_tag_acc=0.9203, Val_cls_acc=0.6466, Val_tag_acc=0.9239\n",
      "Epoch 10: Train_cls_acc=0.9950, Train_tag_acc=0.9205, Val_cls_acc=0.6355, Val_tag_acc=0.9225\n",
      "Epoch 11: Train_cls_acc=0.9963, Train_tag_acc=0.9204, Val_cls_acc=0.6528, Val_tag_acc=0.9225\n",
      "Epoch 12: Train_cls_acc=0.9972, Train_tag_acc=0.9207, Val_cls_acc=0.6576, Val_tag_acc=0.9183\n",
      "Epoch 13: Train_cls_acc=0.9981, Train_tag_acc=0.9205, Val_cls_acc=0.6522, Val_tag_acc=0.9251\n",
      "Epoch 14: Train_cls_acc=0.9984, Train_tag_acc=0.9205, Val_cls_acc=0.6585, Val_tag_acc=0.9227\n",
      "Epoch 15: Train_cls_acc=0.9986, Train_tag_acc=0.9207, Val_cls_acc=0.6441, Val_tag_acc=0.9230\n",
      "Epoch 16: Train_cls_acc=0.9993, Train_tag_acc=0.9209, Val_cls_acc=0.6583, Val_tag_acc=0.9212\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9206, Val_cls_acc=0.6583, Val_tag_acc=0.9207\n",
      "Epoch 18: Train_cls_acc=0.9991, Train_tag_acc=0.9206, Val_cls_acc=0.6580, Val_tag_acc=0.9242\n",
      "Epoch 19: Train_cls_acc=0.9995, Train_tag_acc=0.9208, Val_cls_acc=0.6535, Val_tag_acc=0.9238\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4404,  Tagging Acc: 0.9123, Overall Acc:0.1392\n",
      "Overall Acc:0.1392, Params: (type_emb_dim: 8, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.2944, Train_tag_acc=0.9121, Val_cls_acc=0.4882, Val_tag_acc=0.9180\n",
      "Epoch 2: Train_cls_acc=0.7131, Train_tag_acc=0.9200, Val_cls_acc=0.5859, Val_tag_acc=0.9205\n",
      "Epoch 3: Train_cls_acc=0.8914, Train_tag_acc=0.9200, Val_cls_acc=0.6130, Val_tag_acc=0.9218\n",
      "Epoch 4: Train_cls_acc=0.9470, Train_tag_acc=0.9200, Val_cls_acc=0.6151, Val_tag_acc=0.9199\n",
      "Epoch 5: Train_cls_acc=0.9684, Train_tag_acc=0.9202, Val_cls_acc=0.6297, Val_tag_acc=0.9245\n",
      "Epoch 6: Train_cls_acc=0.9798, Train_tag_acc=0.9204, Val_cls_acc=0.6313, Val_tag_acc=0.9173\n",
      "Epoch 7: Train_cls_acc=0.9866, Train_tag_acc=0.9206, Val_cls_acc=0.6428, Val_tag_acc=0.9197\n",
      "Epoch 8: Train_cls_acc=0.9906, Train_tag_acc=0.9204, Val_cls_acc=0.6365, Val_tag_acc=0.9171\n",
      "Epoch 9: Train_cls_acc=0.9934, Train_tag_acc=0.9207, Val_cls_acc=0.6324, Val_tag_acc=0.9251\n",
      "Epoch 10: Train_cls_acc=0.9953, Train_tag_acc=0.9205, Val_cls_acc=0.6418, Val_tag_acc=0.9151\n",
      "Epoch 11: Train_cls_acc=0.9967, Train_tag_acc=0.9207, Val_cls_acc=0.6411, Val_tag_acc=0.9243\n",
      "Epoch 12: Train_cls_acc=0.9970, Train_tag_acc=0.9205, Val_cls_acc=0.6436, Val_tag_acc=0.9221\n",
      "Epoch 13: Train_cls_acc=0.9981, Train_tag_acc=0.9206, Val_cls_acc=0.6520, Val_tag_acc=0.9244\n",
      "Epoch 14: Train_cls_acc=0.9987, Train_tag_acc=0.9207, Val_cls_acc=0.6470, Val_tag_acc=0.9208\n",
      "Epoch 15: Train_cls_acc=0.9988, Train_tag_acc=0.9206, Val_cls_acc=0.6591, Val_tag_acc=0.9239\n",
      "Epoch 16: Train_cls_acc=0.9991, Train_tag_acc=0.9209, Val_cls_acc=0.6578, Val_tag_acc=0.9230\n",
      "Epoch 17: Train_cls_acc=0.9994, Train_tag_acc=0.9205, Val_cls_acc=0.6510, Val_tag_acc=0.9241\n",
      "Epoch 18: Train_cls_acc=0.9993, Train_tag_acc=0.9208, Val_cls_acc=0.6499, Val_tag_acc=0.9268\n",
      "Epoch 19: Train_cls_acc=0.9996, Train_tag_acc=0.9209, Val_cls_acc=0.6524, Val_tag_acc=0.9245\n",
      "Epoch 20: Train_cls_acc=0.9997, Train_tag_acc=0.9207, Val_cls_acc=0.6491, Val_tag_acc=0.9240\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4278,  Tagging Acc: 0.9101, Overall Acc:0.1189\n",
      "Overall Acc:0.1189, Params: (type_emb_dim: 8, dtype_emb_dim:16)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3099, Train_tag_acc=0.9089, Val_cls_acc=0.5064, Val_tag_acc=0.9217\n",
      "Epoch 2: Train_cls_acc=0.7280, Train_tag_acc=0.9197, Val_cls_acc=0.5690, Val_tag_acc=0.9235\n",
      "Epoch 3: Train_cls_acc=0.8911, Train_tag_acc=0.9199, Val_cls_acc=0.6011, Val_tag_acc=0.9213\n",
      "Epoch 4: Train_cls_acc=0.9463, Train_tag_acc=0.9202, Val_cls_acc=0.6270, Val_tag_acc=0.9170\n",
      "Epoch 5: Train_cls_acc=0.9684, Train_tag_acc=0.9206, Val_cls_acc=0.6311, Val_tag_acc=0.9175\n",
      "Epoch 6: Train_cls_acc=0.9790, Train_tag_acc=0.9204, Val_cls_acc=0.6418, Val_tag_acc=0.9226\n",
      "Epoch 7: Train_cls_acc=0.9863, Train_tag_acc=0.9202, Val_cls_acc=0.6372, Val_tag_acc=0.9230\n",
      "Epoch 8: Train_cls_acc=0.9906, Train_tag_acc=0.9205, Val_cls_acc=0.6080, Val_tag_acc=0.9209\n",
      "Epoch 9: Train_cls_acc=0.9933, Train_tag_acc=0.9206, Val_cls_acc=0.6470, Val_tag_acc=0.9240\n",
      "Epoch 10: Train_cls_acc=0.9947, Train_tag_acc=0.9206, Val_cls_acc=0.6491, Val_tag_acc=0.9235\n",
      "Epoch 11: Train_cls_acc=0.9962, Train_tag_acc=0.9204, Val_cls_acc=0.6570, Val_tag_acc=0.9258\n",
      "Epoch 12: Train_cls_acc=0.9974, Train_tag_acc=0.9207, Val_cls_acc=0.6376, Val_tag_acc=0.9257\n",
      "Epoch 13: Train_cls_acc=0.9979, Train_tag_acc=0.9207, Val_cls_acc=0.6472, Val_tag_acc=0.9245\n",
      "Epoch 14: Train_cls_acc=0.9984, Train_tag_acc=0.9208, Val_cls_acc=0.6595, Val_tag_acc=0.9257\n",
      "Epoch 15: Train_cls_acc=0.9987, Train_tag_acc=0.9207, Val_cls_acc=0.6530, Val_tag_acc=0.9244\n",
      "Epoch 16: Train_cls_acc=0.9990, Train_tag_acc=0.9207, Val_cls_acc=0.6710, Val_tag_acc=0.9275\n",
      "Epoch 17: Train_cls_acc=0.9988, Train_tag_acc=0.9207, Val_cls_acc=0.6545, Val_tag_acc=0.9258\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9208, Val_cls_acc=0.6382, Val_tag_acc=0.9256\n",
      "Epoch 19: Train_cls_acc=0.9992, Train_tag_acc=0.9208, Val_cls_acc=0.6626, Val_tag_acc=0.9226\n",
      "Epoch 20: Train_cls_acc=0.9993, Train_tag_acc=0.9209, Val_cls_acc=0.6486, Val_tag_acc=0.9250\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4186,  Tagging Acc: 0.9127, Overall Acc:0.1382\n",
      "Overall Acc:0.1382, Params: (type_emb_dim: 8, dtype_emb_dim:32)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3177, Train_tag_acc=0.9136, Val_cls_acc=0.4911, Val_tag_acc=0.9163\n",
      "Epoch 2: Train_cls_acc=0.7265, Train_tag_acc=0.9196, Val_cls_acc=0.5742, Val_tag_acc=0.9233\n",
      "Epoch 3: Train_cls_acc=0.8874, Train_tag_acc=0.9201, Val_cls_acc=0.6338, Val_tag_acc=0.9152\n",
      "Epoch 4: Train_cls_acc=0.9426, Train_tag_acc=0.9203, Val_cls_acc=0.6315, Val_tag_acc=0.9239\n",
      "Epoch 5: Train_cls_acc=0.9658, Train_tag_acc=0.9205, Val_cls_acc=0.6418, Val_tag_acc=0.9232\n",
      "Epoch 6: Train_cls_acc=0.9774, Train_tag_acc=0.9203, Val_cls_acc=0.6486, Val_tag_acc=0.9235\n",
      "Epoch 7: Train_cls_acc=0.9854, Train_tag_acc=0.9204, Val_cls_acc=0.6199, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9895, Train_tag_acc=0.9204, Val_cls_acc=0.6416, Val_tag_acc=0.9230\n",
      "Epoch 9: Train_cls_acc=0.9927, Train_tag_acc=0.9205, Val_cls_acc=0.6098, Val_tag_acc=0.9162\n",
      "Epoch 10: Train_cls_acc=0.9944, Train_tag_acc=0.9206, Val_cls_acc=0.6286, Val_tag_acc=0.9238\n",
      "Epoch 11: Train_cls_acc=0.9960, Train_tag_acc=0.9207, Val_cls_acc=0.6403, Val_tag_acc=0.9252\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4449,  Tagging Acc: 0.9108, Overall Acc:0.1667\n",
      "Overall Acc:0.1667, Params: (type_emb_dim: 8, dtype_emb_dim:50)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3321, Train_tag_acc=0.9133, Val_cls_acc=0.4523, Val_tag_acc=0.9222\n",
      "Epoch 2: Train_cls_acc=0.7250, Train_tag_acc=0.9196, Val_cls_acc=0.5679, Val_tag_acc=0.9156\n",
      "Epoch 3: Train_cls_acc=0.8854, Train_tag_acc=0.9201, Val_cls_acc=0.6203, Val_tag_acc=0.9174\n",
      "Epoch 4: Train_cls_acc=0.9414, Train_tag_acc=0.9202, Val_cls_acc=0.6242, Val_tag_acc=0.9245\n",
      "Epoch 5: Train_cls_acc=0.9642, Train_tag_acc=0.9201, Val_cls_acc=0.6207, Val_tag_acc=0.9212\n",
      "Epoch 6: Train_cls_acc=0.9755, Train_tag_acc=0.9204, Val_cls_acc=0.6340, Val_tag_acc=0.9262\n",
      "Epoch 7: Train_cls_acc=0.9836, Train_tag_acc=0.9204, Val_cls_acc=0.6268, Val_tag_acc=0.9247\n",
      "Epoch 8: Train_cls_acc=0.9890, Train_tag_acc=0.9204, Val_cls_acc=0.6441, Val_tag_acc=0.9214\n",
      "Epoch 9: Train_cls_acc=0.9917, Train_tag_acc=0.9205, Val_cls_acc=0.6543, Val_tag_acc=0.9185\n",
      "Epoch 10: Train_cls_acc=0.9938, Train_tag_acc=0.9206, Val_cls_acc=0.6553, Val_tag_acc=0.9240\n",
      "Epoch 11: Train_cls_acc=0.9950, Train_tag_acc=0.9209, Val_cls_acc=0.6555, Val_tag_acc=0.9232\n",
      "Epoch 12: Train_cls_acc=0.9966, Train_tag_acc=0.9208, Val_cls_acc=0.6338, Val_tag_acc=0.9241\n",
      "Epoch 13: Train_cls_acc=0.9975, Train_tag_acc=0.9209, Val_cls_acc=0.6605, Val_tag_acc=0.9235\n",
      "Epoch 14: Train_cls_acc=0.9983, Train_tag_acc=0.9209, Val_cls_acc=0.6589, Val_tag_acc=0.9253\n",
      "Epoch 15: Train_cls_acc=0.9985, Train_tag_acc=0.9207, Val_cls_acc=0.6464, Val_tag_acc=0.9254\n",
      "Epoch 16: Train_cls_acc=0.9989, Train_tag_acc=0.9209, Val_cls_acc=0.6541, Val_tag_acc=0.9219\n",
      "Epoch 17: Train_cls_acc=0.9992, Train_tag_acc=0.9209, Val_cls_acc=0.6530, Val_tag_acc=0.9156\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9207, Val_cls_acc=0.6662, Val_tag_acc=0.9219\n",
      "Epoch 19: Train_cls_acc=0.9991, Train_tag_acc=0.9208, Val_cls_acc=0.6545, Val_tag_acc=0.9222\n",
      "Epoch 20: Train_cls_acc=0.9993, Train_tag_acc=0.9209, Val_cls_acc=0.6503, Val_tag_acc=0.9255\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4449,  Tagging Acc: 0.9126, Overall Acc:0.1437\n",
      "Overall Acc:0.1437, Params: (type_emb_dim: 8, dtype_emb_dim:64)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.2920, Train_tag_acc=0.9126, Val_cls_acc=0.4966, Val_tag_acc=0.9168\n",
      "Epoch 2: Train_cls_acc=0.7118, Train_tag_acc=0.9197, Val_cls_acc=0.5767, Val_tag_acc=0.9245\n",
      "Epoch 3: Train_cls_acc=0.8957, Train_tag_acc=0.9201, Val_cls_acc=0.5957, Val_tag_acc=0.9236\n",
      "Epoch 4: Train_cls_acc=0.9503, Train_tag_acc=0.9200, Val_cls_acc=0.6176, Val_tag_acc=0.9239\n",
      "Epoch 5: Train_cls_acc=0.9704, Train_tag_acc=0.9201, Val_cls_acc=0.6267, Val_tag_acc=0.9228\n",
      "Epoch 6: Train_cls_acc=0.9815, Train_tag_acc=0.9203, Val_cls_acc=0.6365, Val_tag_acc=0.9210\n",
      "Epoch 7: Train_cls_acc=0.9869, Train_tag_acc=0.9205, Val_cls_acc=0.6572, Val_tag_acc=0.9216\n",
      "Epoch 8: Train_cls_acc=0.9912, Train_tag_acc=0.9203, Val_cls_acc=0.6528, Val_tag_acc=0.9251\n",
      "Epoch 9: Train_cls_acc=0.9933, Train_tag_acc=0.9207, Val_cls_acc=0.6537, Val_tag_acc=0.9209\n",
      "Epoch 10: Train_cls_acc=0.9962, Train_tag_acc=0.9204, Val_cls_acc=0.6428, Val_tag_acc=0.9285\n",
      "Epoch 11: Train_cls_acc=0.9964, Train_tag_acc=0.9205, Val_cls_acc=0.6520, Val_tag_acc=0.9259\n",
      "Epoch 12: Train_cls_acc=0.9975, Train_tag_acc=0.9205, Val_cls_acc=0.6534, Val_tag_acc=0.9215\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4318,  Tagging Acc: 0.9130, Overall Acc:0.1335\n",
      "Overall Acc:0.1335, Params: (type_emb_dim: 16, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.2996, Train_tag_acc=0.9133, Val_cls_acc=0.4945, Val_tag_acc=0.9225\n",
      "Epoch 2: Train_cls_acc=0.7300, Train_tag_acc=0.9200, Val_cls_acc=0.5971, Val_tag_acc=0.9257\n",
      "Epoch 3: Train_cls_acc=0.8997, Train_tag_acc=0.9199, Val_cls_acc=0.6489, Val_tag_acc=0.9240\n",
      "Epoch 4: Train_cls_acc=0.9478, Train_tag_acc=0.9204, Val_cls_acc=0.6136, Val_tag_acc=0.9255\n",
      "Epoch 5: Train_cls_acc=0.9687, Train_tag_acc=0.9203, Val_cls_acc=0.6393, Val_tag_acc=0.9127\n",
      "Epoch 6: Train_cls_acc=0.9808, Train_tag_acc=0.9202, Val_cls_acc=0.6428, Val_tag_acc=0.9229\n",
      "Epoch 7: Train_cls_acc=0.9868, Train_tag_acc=0.9203, Val_cls_acc=0.6353, Val_tag_acc=0.9244\n",
      "Epoch 8: Train_cls_acc=0.9913, Train_tag_acc=0.9203, Val_cls_acc=0.6366, Val_tag_acc=0.9240\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4218,  Tagging Acc: 0.9099, Overall Acc:0.1166\n",
      "Overall Acc:0.1166, Params: (type_emb_dim: 16, dtype_emb_dim:16)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3095, Train_tag_acc=0.9144, Val_cls_acc=0.5051, Val_tag_acc=0.9200\n",
      "Epoch 2: Train_cls_acc=0.7422, Train_tag_acc=0.9200, Val_cls_acc=0.5783, Val_tag_acc=0.9236\n",
      "Epoch 3: Train_cls_acc=0.8981, Train_tag_acc=0.9201, Val_cls_acc=0.6290, Val_tag_acc=0.9274\n",
      "Epoch 4: Train_cls_acc=0.9494, Train_tag_acc=0.9206, Val_cls_acc=0.6453, Val_tag_acc=0.9206\n",
      "Epoch 5: Train_cls_acc=0.9690, Train_tag_acc=0.9203, Val_cls_acc=0.6399, Val_tag_acc=0.9194\n",
      "Epoch 6: Train_cls_acc=0.9797, Train_tag_acc=0.9202, Val_cls_acc=0.6430, Val_tag_acc=0.9220\n",
      "Epoch 7: Train_cls_acc=0.9869, Train_tag_acc=0.9205, Val_cls_acc=0.6443, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9912, Train_tag_acc=0.9205, Val_cls_acc=0.6272, Val_tag_acc=0.9239\n",
      "Epoch 9: Train_cls_acc=0.9934, Train_tag_acc=0.9205, Val_cls_acc=0.6361, Val_tag_acc=0.9240\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4479,  Tagging Acc: 0.9136, Overall Acc:0.1598\n",
      "Overall Acc:0.1598, Params: (type_emb_dim: 16, dtype_emb_dim:32)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3350, Train_tag_acc=0.9122, Val_cls_acc=0.4934, Val_tag_acc=0.9239\n",
      "Epoch 2: Train_cls_acc=0.7462, Train_tag_acc=0.9200, Val_cls_acc=0.5527, Val_tag_acc=0.9224\n",
      "Epoch 3: Train_cls_acc=0.8931, Train_tag_acc=0.9200, Val_cls_acc=0.5932, Val_tag_acc=0.9227\n",
      "Epoch 4: Train_cls_acc=0.9442, Train_tag_acc=0.9203, Val_cls_acc=0.6099, Val_tag_acc=0.9226\n",
      "Epoch 5: Train_cls_acc=0.9670, Train_tag_acc=0.9204, Val_cls_acc=0.5854, Val_tag_acc=0.9227\n",
      "Epoch 6: Train_cls_acc=0.9780, Train_tag_acc=0.9203, Val_cls_acc=0.6161, Val_tag_acc=0.9268\n",
      "Epoch 7: Train_cls_acc=0.9860, Train_tag_acc=0.9204, Val_cls_acc=0.6155, Val_tag_acc=0.9252\n",
      "Epoch 8: Train_cls_acc=0.9899, Train_tag_acc=0.9204, Val_cls_acc=0.6236, Val_tag_acc=0.9243\n",
      "Epoch 9: Train_cls_acc=0.9927, Train_tag_acc=0.9205, Val_cls_acc=0.6261, Val_tag_acc=0.9235\n",
      "Epoch 10: Train_cls_acc=0.9942, Train_tag_acc=0.9207, Val_cls_acc=0.6324, Val_tag_acc=0.9244\n",
      "Epoch 11: Train_cls_acc=0.9960, Train_tag_acc=0.9204, Val_cls_acc=0.6449, Val_tag_acc=0.9249\n",
      "Epoch 12: Train_cls_acc=0.9967, Train_tag_acc=0.9204, Val_cls_acc=0.6361, Val_tag_acc=0.9242\n",
      "Epoch 13: Train_cls_acc=0.9978, Train_tag_acc=0.9206, Val_cls_acc=0.6487, Val_tag_acc=0.9257\n",
      "Epoch 14: Train_cls_acc=0.9982, Train_tag_acc=0.9208, Val_cls_acc=0.6453, Val_tag_acc=0.9247\n",
      "Epoch 15: Train_cls_acc=0.9989, Train_tag_acc=0.9207, Val_cls_acc=0.6612, Val_tag_acc=0.9195\n",
      "Epoch 16: Train_cls_acc=0.9989, Train_tag_acc=0.9208, Val_cls_acc=0.6451, Val_tag_acc=0.9253\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9209, Val_cls_acc=0.6568, Val_tag_acc=0.9140\n",
      "Epoch 18: Train_cls_acc=0.9993, Train_tag_acc=0.9208, Val_cls_acc=0.6591, Val_tag_acc=0.9253\n",
      "Epoch 19: Train_cls_acc=0.9994, Train_tag_acc=0.9206, Val_cls_acc=0.6509, Val_tag_acc=0.9242\n",
      "Epoch 20: Train_cls_acc=0.9994, Train_tag_acc=0.9207, Val_cls_acc=0.6620, Val_tag_acc=0.9217\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4422,  Tagging Acc: 0.9185, Overall Acc:0.1801\n",
      "Overall Acc:0.1801, Params: (type_emb_dim: 16, dtype_emb_dim:50)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3341, Train_tag_acc=0.9119, Val_cls_acc=0.4999, Val_tag_acc=0.9231\n",
      "Epoch 2: Train_cls_acc=0.7470, Train_tag_acc=0.9198, Val_cls_acc=0.5848, Val_tag_acc=0.9155\n",
      "Epoch 3: Train_cls_acc=0.8938, Train_tag_acc=0.9200, Val_cls_acc=0.6107, Val_tag_acc=0.9233\n",
      "Epoch 4: Train_cls_acc=0.9460, Train_tag_acc=0.9203, Val_cls_acc=0.6280, Val_tag_acc=0.9227\n",
      "Epoch 5: Train_cls_acc=0.9682, Train_tag_acc=0.9205, Val_cls_acc=0.6386, Val_tag_acc=0.9215\n",
      "Epoch 6: Train_cls_acc=0.9787, Train_tag_acc=0.9205, Val_cls_acc=0.6413, Val_tag_acc=0.9205\n",
      "Epoch 7: Train_cls_acc=0.9853, Train_tag_acc=0.9204, Val_cls_acc=0.6374, Val_tag_acc=0.9249\n",
      "Epoch 8: Train_cls_acc=0.9903, Train_tag_acc=0.9208, Val_cls_acc=0.6399, Val_tag_acc=0.9227\n",
      "Epoch 9: Train_cls_acc=0.9929, Train_tag_acc=0.9204, Val_cls_acc=0.6464, Val_tag_acc=0.9254\n",
      "Epoch 10: Train_cls_acc=0.9941, Train_tag_acc=0.9204, Val_cls_acc=0.6551, Val_tag_acc=0.9195\n",
      "Epoch 11: Train_cls_acc=0.9958, Train_tag_acc=0.9206, Val_cls_acc=0.6578, Val_tag_acc=0.9213\n",
      "Epoch 12: Train_cls_acc=0.9974, Train_tag_acc=0.9207, Val_cls_acc=0.6570, Val_tag_acc=0.9192\n",
      "Epoch 13: Train_cls_acc=0.9977, Train_tag_acc=0.9206, Val_cls_acc=0.6710, Val_tag_acc=0.9254\n",
      "Epoch 14: Train_cls_acc=0.9983, Train_tag_acc=0.9208, Val_cls_acc=0.6601, Val_tag_acc=0.9242\n",
      "Epoch 15: Train_cls_acc=0.9983, Train_tag_acc=0.9209, Val_cls_acc=0.6645, Val_tag_acc=0.9260\n",
      "Epoch 16: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6670, Val_tag_acc=0.9213\n",
      "Epoch 17: Train_cls_acc=0.9987, Train_tag_acc=0.9206, Val_cls_acc=0.6587, Val_tag_acc=0.9170\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9207, Val_cls_acc=0.6585, Val_tag_acc=0.9257\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4206,  Tagging Acc: 0.9121, Overall Acc:0.1556\n",
      "Overall Acc:0.1556, Params: (type_emb_dim: 16, dtype_emb_dim:64)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3059, Train_tag_acc=0.9134, Val_cls_acc=0.4853, Val_tag_acc=0.9175\n",
      "Epoch 2: Train_cls_acc=0.7290, Train_tag_acc=0.9197, Val_cls_acc=0.5919, Val_tag_acc=0.9203\n",
      "Epoch 3: Train_cls_acc=0.8924, Train_tag_acc=0.9200, Val_cls_acc=0.6242, Val_tag_acc=0.9234\n",
      "Epoch 4: Train_cls_acc=0.9454, Train_tag_acc=0.9205, Val_cls_acc=0.6493, Val_tag_acc=0.9235\n",
      "Epoch 5: Train_cls_acc=0.9670, Train_tag_acc=0.9205, Val_cls_acc=0.6403, Val_tag_acc=0.9224\n",
      "Epoch 6: Train_cls_acc=0.9794, Train_tag_acc=0.9203, Val_cls_acc=0.6572, Val_tag_acc=0.9187\n",
      "Epoch 7: Train_cls_acc=0.9861, Train_tag_acc=0.9204, Val_cls_acc=0.6564, Val_tag_acc=0.9238\n",
      "Epoch 8: Train_cls_acc=0.9900, Train_tag_acc=0.9205, Val_cls_acc=0.6653, Val_tag_acc=0.9244\n",
      "Epoch 9: Train_cls_acc=0.9928, Train_tag_acc=0.9204, Val_cls_acc=0.6639, Val_tag_acc=0.9164\n",
      "Epoch 10: Train_cls_acc=0.9950, Train_tag_acc=0.9206, Val_cls_acc=0.6733, Val_tag_acc=0.9247\n",
      "Epoch 11: Train_cls_acc=0.9959, Train_tag_acc=0.9206, Val_cls_acc=0.6726, Val_tag_acc=0.9250\n",
      "Epoch 12: Train_cls_acc=0.9968, Train_tag_acc=0.9204, Val_cls_acc=0.6645, Val_tag_acc=0.9229\n",
      "Epoch 13: Train_cls_acc=0.9983, Train_tag_acc=0.9205, Val_cls_acc=0.6722, Val_tag_acc=0.9233\n",
      "Epoch 14: Train_cls_acc=0.9980, Train_tag_acc=0.9206, Val_cls_acc=0.6816, Val_tag_acc=0.9268\n",
      "Epoch 15: Train_cls_acc=0.9990, Train_tag_acc=0.9207, Val_cls_acc=0.6703, Val_tag_acc=0.9249\n",
      "Epoch 16: Train_cls_acc=0.9989, Train_tag_acc=0.9206, Val_cls_acc=0.6710, Val_tag_acc=0.9240\n",
      "Epoch 17: Train_cls_acc=0.9992, Train_tag_acc=0.9207, Val_cls_acc=0.6751, Val_tag_acc=0.9222\n",
      "Epoch 18: Train_cls_acc=0.9994, Train_tag_acc=0.9208, Val_cls_acc=0.6672, Val_tag_acc=0.9161\n",
      "Epoch 19: Train_cls_acc=0.9993, Train_tag_acc=0.9207, Val_cls_acc=0.6679, Val_tag_acc=0.9208\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4315,  Tagging Acc: 0.9157, Overall Acc:0.1685\n",
      "Overall Acc:0.1685, Params: (type_emb_dim: 32, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3174, Train_tag_acc=0.9154, Val_cls_acc=0.4953, Val_tag_acc=0.9208\n",
      "Epoch 2: Train_cls_acc=0.7390, Train_tag_acc=0.9198, Val_cls_acc=0.5673, Val_tag_acc=0.9252\n",
      "Epoch 3: Train_cls_acc=0.8938, Train_tag_acc=0.9200, Val_cls_acc=0.6176, Val_tag_acc=0.9148\n",
      "Epoch 4: Train_cls_acc=0.9464, Train_tag_acc=0.9203, Val_cls_acc=0.6180, Val_tag_acc=0.9239\n",
      "Epoch 5: Train_cls_acc=0.9687, Train_tag_acc=0.9201, Val_cls_acc=0.6389, Val_tag_acc=0.9201\n",
      "Epoch 6: Train_cls_acc=0.9790, Train_tag_acc=0.9204, Val_cls_acc=0.6470, Val_tag_acc=0.9200\n",
      "Epoch 7: Train_cls_acc=0.9865, Train_tag_acc=0.9204, Val_cls_acc=0.6434, Val_tag_acc=0.9218\n",
      "Epoch 8: Train_cls_acc=0.9904, Train_tag_acc=0.9206, Val_cls_acc=0.6601, Val_tag_acc=0.9241\n",
      "Epoch 9: Train_cls_acc=0.9925, Train_tag_acc=0.9206, Val_cls_acc=0.6651, Val_tag_acc=0.9173\n",
      "Epoch 10: Train_cls_acc=0.9946, Train_tag_acc=0.9205, Val_cls_acc=0.6532, Val_tag_acc=0.9239\n",
      "Epoch 11: Train_cls_acc=0.9957, Train_tag_acc=0.9206, Val_cls_acc=0.6491, Val_tag_acc=0.9241\n",
      "Epoch 12: Train_cls_acc=0.9971, Train_tag_acc=0.9205, Val_cls_acc=0.6363, Val_tag_acc=0.9220\n",
      "Epoch 13: Train_cls_acc=0.9977, Train_tag_acc=0.9207, Val_cls_acc=0.6608, Val_tag_acc=0.9223\n",
      "Epoch 14: Train_cls_acc=0.9982, Train_tag_acc=0.9208, Val_cls_acc=0.6606, Val_tag_acc=0.9241\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4479,  Tagging Acc: 0.9142, Overall Acc:0.1365\n",
      "Overall Acc:0.1365, Params: (type_emb_dim: 32, dtype_emb_dim:16)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3277, Train_tag_acc=0.9164, Val_cls_acc=0.4795, Val_tag_acc=0.9234\n",
      "Epoch 2: Train_cls_acc=0.7491, Train_tag_acc=0.9196, Val_cls_acc=0.5566, Val_tag_acc=0.9233\n",
      "Epoch 3: Train_cls_acc=0.8980, Train_tag_acc=0.9201, Val_cls_acc=0.6270, Val_tag_acc=0.9164\n",
      "Epoch 4: Train_cls_acc=0.9448, Train_tag_acc=0.9202, Val_cls_acc=0.6172, Val_tag_acc=0.9197\n",
      "Epoch 5: Train_cls_acc=0.9660, Train_tag_acc=0.9203, Val_cls_acc=0.6242, Val_tag_acc=0.9220\n",
      "Epoch 6: Train_cls_acc=0.9775, Train_tag_acc=0.9202, Val_cls_acc=0.6472, Val_tag_acc=0.9257\n",
      "Epoch 7: Train_cls_acc=0.9859, Train_tag_acc=0.9204, Val_cls_acc=0.6282, Val_tag_acc=0.9187\n",
      "Epoch 8: Train_cls_acc=0.9895, Train_tag_acc=0.9204, Val_cls_acc=0.6576, Val_tag_acc=0.9188\n",
      "Epoch 9: Train_cls_acc=0.9929, Train_tag_acc=0.9206, Val_cls_acc=0.6712, Val_tag_acc=0.9243\n",
      "Epoch 10: Train_cls_acc=0.9949, Train_tag_acc=0.9206, Val_cls_acc=0.6639, Val_tag_acc=0.9231\n",
      "Epoch 11: Train_cls_acc=0.9957, Train_tag_acc=0.9206, Val_cls_acc=0.6666, Val_tag_acc=0.9232\n",
      "Epoch 12: Train_cls_acc=0.9969, Train_tag_acc=0.9210, Val_cls_acc=0.6622, Val_tag_acc=0.9245\n",
      "Epoch 13: Train_cls_acc=0.9979, Train_tag_acc=0.9207, Val_cls_acc=0.6664, Val_tag_acc=0.9212\n",
      "Epoch 14: Train_cls_acc=0.9985, Train_tag_acc=0.9208, Val_cls_acc=0.6718, Val_tag_acc=0.9256\n",
      "Epoch 15: Train_cls_acc=0.9990, Train_tag_acc=0.9207, Val_cls_acc=0.6720, Val_tag_acc=0.9243\n",
      "Epoch 16: Train_cls_acc=0.9988, Train_tag_acc=0.9208, Val_cls_acc=0.6781, Val_tag_acc=0.9230\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6891, Val_tag_acc=0.9206\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9208, Val_cls_acc=0.6718, Val_tag_acc=0.9229\n",
      "Epoch 19: Train_cls_acc=0.9995, Train_tag_acc=0.9208, Val_cls_acc=0.6764, Val_tag_acc=0.9225\n",
      "Epoch 20: Train_cls_acc=0.9993, Train_tag_acc=0.9208, Val_cls_acc=0.6760, Val_tag_acc=0.9208\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4313,  Tagging Acc: 0.9161, Overall Acc:0.1578\n",
      "Overall Acc:0.1578, Params: (type_emb_dim: 32, dtype_emb_dim:32)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3376, Train_tag_acc=0.9133, Val_cls_acc=0.4915, Val_tag_acc=0.9223\n",
      "Epoch 2: Train_cls_acc=0.7464, Train_tag_acc=0.9196, Val_cls_acc=0.5944, Val_tag_acc=0.9202\n",
      "Epoch 3: Train_cls_acc=0.8932, Train_tag_acc=0.9201, Val_cls_acc=0.5927, Val_tag_acc=0.9206\n",
      "Epoch 4: Train_cls_acc=0.9447, Train_tag_acc=0.9205, Val_cls_acc=0.6190, Val_tag_acc=0.9240\n",
      "Epoch 5: Train_cls_acc=0.9662, Train_tag_acc=0.9202, Val_cls_acc=0.6288, Val_tag_acc=0.9162\n",
      "Epoch 6: Train_cls_acc=0.9774, Train_tag_acc=0.9205, Val_cls_acc=0.6343, Val_tag_acc=0.9256\n",
      "Epoch 7: Train_cls_acc=0.9841, Train_tag_acc=0.9206, Val_cls_acc=0.6434, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9891, Train_tag_acc=0.9205, Val_cls_acc=0.6230, Val_tag_acc=0.9210\n",
      "Epoch 9: Train_cls_acc=0.9917, Train_tag_acc=0.9207, Val_cls_acc=0.6445, Val_tag_acc=0.9215\n",
      "Epoch 10: Train_cls_acc=0.9938, Train_tag_acc=0.9205, Val_cls_acc=0.6551, Val_tag_acc=0.9223\n",
      "Epoch 11: Train_cls_acc=0.9959, Train_tag_acc=0.9206, Val_cls_acc=0.6606, Val_tag_acc=0.9233\n",
      "Epoch 12: Train_cls_acc=0.9972, Train_tag_acc=0.9205, Val_cls_acc=0.6601, Val_tag_acc=0.9201\n",
      "Epoch 13: Train_cls_acc=0.9975, Train_tag_acc=0.9204, Val_cls_acc=0.6631, Val_tag_acc=0.9257\n",
      "Epoch 14: Train_cls_acc=0.9982, Train_tag_acc=0.9207, Val_cls_acc=0.6568, Val_tag_acc=0.9253\n",
      "Epoch 15: Train_cls_acc=0.9985, Train_tag_acc=0.9205, Val_cls_acc=0.6666, Val_tag_acc=0.9227\n",
      "Epoch 16: Train_cls_acc=0.9989, Train_tag_acc=0.9208, Val_cls_acc=0.6631, Val_tag_acc=0.9220\n",
      "Epoch 17: Train_cls_acc=0.9988, Train_tag_acc=0.9209, Val_cls_acc=0.6656, Val_tag_acc=0.9228\n",
      "Epoch 18: Train_cls_acc=0.9994, Train_tag_acc=0.9207, Val_cls_acc=0.6639, Val_tag_acc=0.9233\n",
      "Epoch 19: Train_cls_acc=0.9994, Train_tag_acc=0.9207, Val_cls_acc=0.6685, Val_tag_acc=0.9230\n",
      "Epoch 20: Train_cls_acc=0.9994, Train_tag_acc=0.9208, Val_cls_acc=0.6681, Val_tag_acc=0.9200\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4313,  Tagging Acc: 0.9160, Overall Acc:0.1660\n",
      "Overall Acc:0.1660, Params: (type_emb_dim: 32, dtype_emb_dim:50)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3617, Train_tag_acc=0.9130, Val_cls_acc=0.5041, Val_tag_acc=0.9257\n",
      "Epoch 2: Train_cls_acc=0.7600, Train_tag_acc=0.9199, Val_cls_acc=0.5758, Val_tag_acc=0.9254\n",
      "Epoch 3: Train_cls_acc=0.8951, Train_tag_acc=0.9201, Val_cls_acc=0.6101, Val_tag_acc=0.9217\n",
      "Epoch 4: Train_cls_acc=0.9418, Train_tag_acc=0.9204, Val_cls_acc=0.6341, Val_tag_acc=0.9196\n",
      "Epoch 5: Train_cls_acc=0.9653, Train_tag_acc=0.9205, Val_cls_acc=0.6268, Val_tag_acc=0.9235\n",
      "Epoch 6: Train_cls_acc=0.9754, Train_tag_acc=0.9205, Val_cls_acc=0.6328, Val_tag_acc=0.9218\n",
      "Epoch 7: Train_cls_acc=0.9841, Train_tag_acc=0.9205, Val_cls_acc=0.6330, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9883, Train_tag_acc=0.9205, Val_cls_acc=0.6436, Val_tag_acc=0.9240\n",
      "Epoch 9: Train_cls_acc=0.9918, Train_tag_acc=0.9203, Val_cls_acc=0.6445, Val_tag_acc=0.9252\n",
      "Epoch 10: Train_cls_acc=0.9938, Train_tag_acc=0.9207, Val_cls_acc=0.6326, Val_tag_acc=0.9251\n",
      "Epoch 11: Train_cls_acc=0.9955, Train_tag_acc=0.9206, Val_cls_acc=0.6428, Val_tag_acc=0.9223\n",
      "Epoch 12: Train_cls_acc=0.9967, Train_tag_acc=0.9205, Val_cls_acc=0.6461, Val_tag_acc=0.9252\n",
      "Epoch 13: Train_cls_acc=0.9977, Train_tag_acc=0.9207, Val_cls_acc=0.6355, Val_tag_acc=0.9224\n",
      "Epoch 14: Train_cls_acc=0.9981, Train_tag_acc=0.9206, Val_cls_acc=0.6576, Val_tag_acc=0.9244\n",
      "Epoch 15: Train_cls_acc=0.9982, Train_tag_acc=0.9204, Val_cls_acc=0.6512, Val_tag_acc=0.9257\n",
      "Epoch 16: Train_cls_acc=0.9990, Train_tag_acc=0.9207, Val_cls_acc=0.6391, Val_tag_acc=0.9253\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6480, Val_tag_acc=0.9254\n",
      "Epoch 18: Train_cls_acc=0.9994, Train_tag_acc=0.9208, Val_cls_acc=0.6541, Val_tag_acc=0.9252\n",
      "Epoch 19: Train_cls_acc=0.9992, Train_tag_acc=0.9208, Val_cls_acc=0.6393, Val_tag_acc=0.9221\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4199,  Tagging Acc: 0.9097, Overall Acc:0.1628\n",
      "Overall Acc:0.1628, Params: (type_emb_dim: 32, dtype_emb_dim:64)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3136, Train_tag_acc=0.9136, Val_cls_acc=0.5057, Val_tag_acc=0.9155\n",
      "Epoch 2: Train_cls_acc=0.7331, Train_tag_acc=0.9198, Val_cls_acc=0.5927, Val_tag_acc=0.9220\n",
      "Epoch 3: Train_cls_acc=0.8965, Train_tag_acc=0.9201, Val_cls_acc=0.6278, Val_tag_acc=0.9206\n",
      "Epoch 4: Train_cls_acc=0.9477, Train_tag_acc=0.9203, Val_cls_acc=0.6357, Val_tag_acc=0.9248\n",
      "Epoch 5: Train_cls_acc=0.9686, Train_tag_acc=0.9206, Val_cls_acc=0.6432, Val_tag_acc=0.9239\n",
      "Epoch 6: Train_cls_acc=0.9796, Train_tag_acc=0.9205, Val_cls_acc=0.6441, Val_tag_acc=0.9256\n",
      "Epoch 7: Train_cls_acc=0.9861, Train_tag_acc=0.9205, Val_cls_acc=0.6436, Val_tag_acc=0.9230\n",
      "Epoch 8: Train_cls_acc=0.9909, Train_tag_acc=0.9205, Val_cls_acc=0.6553, Val_tag_acc=0.9155\n",
      "Epoch 9: Train_cls_acc=0.9927, Train_tag_acc=0.9203, Val_cls_acc=0.6557, Val_tag_acc=0.9177\n",
      "Epoch 10: Train_cls_acc=0.9947, Train_tag_acc=0.9206, Val_cls_acc=0.6443, Val_tag_acc=0.9242\n",
      "Epoch 11: Train_cls_acc=0.9962, Train_tag_acc=0.9207, Val_cls_acc=0.6505, Val_tag_acc=0.9222\n",
      "Epoch 12: Train_cls_acc=0.9973, Train_tag_acc=0.9207, Val_cls_acc=0.6357, Val_tag_acc=0.9256\n",
      "Epoch 13: Train_cls_acc=0.9981, Train_tag_acc=0.9207, Val_cls_acc=0.6551, Val_tag_acc=0.9266\n",
      "Epoch 14: Train_cls_acc=0.9988, Train_tag_acc=0.9207, Val_cls_acc=0.6622, Val_tag_acc=0.9238\n",
      "Epoch 15: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6522, Val_tag_acc=0.9208\n",
      "Epoch 16: Train_cls_acc=0.9991, Train_tag_acc=0.9209, Val_cls_acc=0.6693, Val_tag_acc=0.9226\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9207, Val_cls_acc=0.6612, Val_tag_acc=0.9206\n",
      "Epoch 18: Train_cls_acc=0.9995, Train_tag_acc=0.9207, Val_cls_acc=0.6708, Val_tag_acc=0.9220\n",
      "Epoch 19: Train_cls_acc=0.9992, Train_tag_acc=0.9207, Val_cls_acc=0.6560, Val_tag_acc=0.9256\n",
      "Epoch 20: Train_cls_acc=0.9995, Train_tag_acc=0.9208, Val_cls_acc=0.6606, Val_tag_acc=0.9250\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4335,  Tagging Acc: 0.9096, Overall Acc:0.1275\n",
      "Overall Acc:0.1275, Params: (type_emb_dim: 50, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3464, Train_tag_acc=0.9146, Val_cls_acc=0.5206, Val_tag_acc=0.9199\n",
      "Epoch 2: Train_cls_acc=0.7600, Train_tag_acc=0.9195, Val_cls_acc=0.6021, Val_tag_acc=0.9238\n",
      "Epoch 3: Train_cls_acc=0.9001, Train_tag_acc=0.9200, Val_cls_acc=0.6232, Val_tag_acc=0.9217\n",
      "Epoch 4: Train_cls_acc=0.9454, Train_tag_acc=0.9203, Val_cls_acc=0.6284, Val_tag_acc=0.9238\n",
      "Epoch 5: Train_cls_acc=0.9671, Train_tag_acc=0.9202, Val_cls_acc=0.6282, Val_tag_acc=0.9213\n",
      "Epoch 6: Train_cls_acc=0.9769, Train_tag_acc=0.9204, Val_cls_acc=0.6307, Val_tag_acc=0.9149\n",
      "Epoch 7: Train_cls_acc=0.9840, Train_tag_acc=0.9205, Val_cls_acc=0.6316, Val_tag_acc=0.9239\n",
      "Epoch 8: Train_cls_acc=0.9900, Train_tag_acc=0.9205, Val_cls_acc=0.6535, Val_tag_acc=0.9231\n",
      "Epoch 9: Train_cls_acc=0.9924, Train_tag_acc=0.9207, Val_cls_acc=0.6516, Val_tag_acc=0.9285\n",
      "Epoch 10: Train_cls_acc=0.9947, Train_tag_acc=0.9206, Val_cls_acc=0.6578, Val_tag_acc=0.9227\n",
      "Epoch 11: Train_cls_acc=0.9962, Train_tag_acc=0.9204, Val_cls_acc=0.6582, Val_tag_acc=0.9252\n",
      "Epoch 12: Train_cls_acc=0.9977, Train_tag_acc=0.9207, Val_cls_acc=0.6535, Val_tag_acc=0.9238\n",
      "Epoch 13: Train_cls_acc=0.9976, Train_tag_acc=0.9207, Val_cls_acc=0.6476, Val_tag_acc=0.9252\n",
      "Epoch 14: Train_cls_acc=0.9985, Train_tag_acc=0.9207, Val_cls_acc=0.6474, Val_tag_acc=0.9238\n",
      "Epoch 15: Train_cls_acc=0.9993, Train_tag_acc=0.9206, Val_cls_acc=0.6603, Val_tag_acc=0.9251\n",
      "Epoch 16: Train_cls_acc=0.9990, Train_tag_acc=0.9207, Val_cls_acc=0.6388, Val_tag_acc=0.9252\n",
      "Epoch 17: Train_cls_acc=0.9989, Train_tag_acc=0.9207, Val_cls_acc=0.6505, Val_tag_acc=0.9242\n",
      "Epoch 18: Train_cls_acc=0.9995, Train_tag_acc=0.9207, Val_cls_acc=0.6464, Val_tag_acc=0.9188\n",
      "Epoch 19: Train_cls_acc=0.9993, Train_tag_acc=0.9208, Val_cls_acc=0.6476, Val_tag_acc=0.9223\n",
      "Epoch 20: Train_cls_acc=0.9996, Train_tag_acc=0.9207, Val_cls_acc=0.6384, Val_tag_acc=0.9247\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4186,  Tagging Acc: 0.9120, Overall Acc:0.1102\n",
      "Overall Acc:0.1102, Params: (type_emb_dim: 50, dtype_emb_dim:16)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3369, Train_tag_acc=0.9143, Val_cls_acc=0.4797, Val_tag_acc=0.9233\n",
      "Epoch 2: Train_cls_acc=0.7413, Train_tag_acc=0.9196, Val_cls_acc=0.5712, Val_tag_acc=0.9155\n",
      "Epoch 3: Train_cls_acc=0.8911, Train_tag_acc=0.9201, Val_cls_acc=0.6023, Val_tag_acc=0.9247\n",
      "Epoch 4: Train_cls_acc=0.9422, Train_tag_acc=0.9201, Val_cls_acc=0.6190, Val_tag_acc=0.9230\n",
      "Epoch 5: Train_cls_acc=0.9634, Train_tag_acc=0.9201, Val_cls_acc=0.6061, Val_tag_acc=0.9278\n",
      "Epoch 6: Train_cls_acc=0.9760, Train_tag_acc=0.9206, Val_cls_acc=0.6272, Val_tag_acc=0.9241\n",
      "Epoch 7: Train_cls_acc=0.9831, Train_tag_acc=0.9205, Val_cls_acc=0.6437, Val_tag_acc=0.9252\n",
      "Epoch 8: Train_cls_acc=0.9891, Train_tag_acc=0.9205, Val_cls_acc=0.6165, Val_tag_acc=0.9253\n",
      "Epoch 9: Train_cls_acc=0.9919, Train_tag_acc=0.9205, Val_cls_acc=0.6624, Val_tag_acc=0.9244\n",
      "Epoch 10: Train_cls_acc=0.9940, Train_tag_acc=0.9206, Val_cls_acc=0.6606, Val_tag_acc=0.9243\n",
      "Epoch 11: Train_cls_acc=0.9957, Train_tag_acc=0.9205, Val_cls_acc=0.6505, Val_tag_acc=0.9224\n",
      "Epoch 12: Train_cls_acc=0.9961, Train_tag_acc=0.9207, Val_cls_acc=0.6566, Val_tag_acc=0.9235\n",
      "Epoch 13: Train_cls_acc=0.9975, Train_tag_acc=0.9206, Val_cls_acc=0.6591, Val_tag_acc=0.9217\n",
      "Epoch 14: Train_cls_acc=0.9979, Train_tag_acc=0.9207, Val_cls_acc=0.6537, Val_tag_acc=0.9256\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4342,  Tagging Acc: 0.9123, Overall Acc:0.1571\n",
      "Overall Acc:0.1571, Params: (type_emb_dim: 50, dtype_emb_dim:32)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3381, Train_tag_acc=0.9138, Val_cls_acc=0.4970, Val_tag_acc=0.9223\n",
      "Epoch 2: Train_cls_acc=0.7434, Train_tag_acc=0.9197, Val_cls_acc=0.5923, Val_tag_acc=0.9242\n",
      "Epoch 3: Train_cls_acc=0.8938, Train_tag_acc=0.9204, Val_cls_acc=0.6278, Val_tag_acc=0.9222\n",
      "Epoch 4: Train_cls_acc=0.9461, Train_tag_acc=0.9205, Val_cls_acc=0.6378, Val_tag_acc=0.9237\n",
      "Epoch 5: Train_cls_acc=0.9672, Train_tag_acc=0.9202, Val_cls_acc=0.6411, Val_tag_acc=0.9236\n",
      "Epoch 6: Train_cls_acc=0.9788, Train_tag_acc=0.9203, Val_cls_acc=0.6324, Val_tag_acc=0.9238\n",
      "Epoch 7: Train_cls_acc=0.9847, Train_tag_acc=0.9203, Val_cls_acc=0.6445, Val_tag_acc=0.9236\n",
      "Epoch 8: Train_cls_acc=0.9900, Train_tag_acc=0.9206, Val_cls_acc=0.6562, Val_tag_acc=0.9241\n",
      "Epoch 9: Train_cls_acc=0.9920, Train_tag_acc=0.9207, Val_cls_acc=0.6641, Val_tag_acc=0.9240\n",
      "Epoch 10: Train_cls_acc=0.9942, Train_tag_acc=0.9207, Val_cls_acc=0.6612, Val_tag_acc=0.9263\n",
      "Epoch 11: Train_cls_acc=0.9959, Train_tag_acc=0.9205, Val_cls_acc=0.6618, Val_tag_acc=0.9161\n",
      "Epoch 12: Train_cls_acc=0.9966, Train_tag_acc=0.9208, Val_cls_acc=0.6516, Val_tag_acc=0.9239\n",
      "Epoch 13: Train_cls_acc=0.9976, Train_tag_acc=0.9208, Val_cls_acc=0.6743, Val_tag_acc=0.9264\n",
      "Epoch 14: Train_cls_acc=0.9985, Train_tag_acc=0.9206, Val_cls_acc=0.6672, Val_tag_acc=0.9223\n",
      "Epoch 15: Train_cls_acc=0.9986, Train_tag_acc=0.9208, Val_cls_acc=0.6760, Val_tag_acc=0.9253\n",
      "Epoch 16: Train_cls_acc=0.9987, Train_tag_acc=0.9206, Val_cls_acc=0.6727, Val_tag_acc=0.9270\n",
      "Epoch 17: Train_cls_acc=0.9991, Train_tag_acc=0.9208, Val_cls_acc=0.6818, Val_tag_acc=0.9242\n",
      "Epoch 18: Train_cls_acc=0.9996, Train_tag_acc=0.9207, Val_cls_acc=0.6787, Val_tag_acc=0.9253\n",
      "Epoch 19: Train_cls_acc=0.9991, Train_tag_acc=0.9209, Val_cls_acc=0.6691, Val_tag_acc=0.9254\n",
      "Epoch 20: Train_cls_acc=0.9996, Train_tag_acc=0.9208, Val_cls_acc=0.6818, Val_tag_acc=0.9254\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4610,  Tagging Acc: 0.9129, Overall Acc:0.1685\n",
      "Overall Acc:0.1685, Params: (type_emb_dim: 50, dtype_emb_dim:50)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3495, Train_tag_acc=0.9139, Val_cls_acc=0.4901, Val_tag_acc=0.9205\n",
      "Epoch 2: Train_cls_acc=0.7510, Train_tag_acc=0.9198, Val_cls_acc=0.6063, Val_tag_acc=0.9247\n",
      "Epoch 3: Train_cls_acc=0.8962, Train_tag_acc=0.9200, Val_cls_acc=0.6253, Val_tag_acc=0.9216\n",
      "Epoch 4: Train_cls_acc=0.9428, Train_tag_acc=0.9204, Val_cls_acc=0.6336, Val_tag_acc=0.9229\n",
      "Epoch 5: Train_cls_acc=0.9666, Train_tag_acc=0.9203, Val_cls_acc=0.6322, Val_tag_acc=0.9185\n",
      "Epoch 6: Train_cls_acc=0.9779, Train_tag_acc=0.9203, Val_cls_acc=0.6430, Val_tag_acc=0.9206\n",
      "Epoch 7: Train_cls_acc=0.9860, Train_tag_acc=0.9202, Val_cls_acc=0.6397, Val_tag_acc=0.9242\n",
      "Epoch 8: Train_cls_acc=0.9898, Train_tag_acc=0.9205, Val_cls_acc=0.6445, Val_tag_acc=0.9240\n",
      "Epoch 9: Train_cls_acc=0.9930, Train_tag_acc=0.9210, Val_cls_acc=0.6520, Val_tag_acc=0.9239\n",
      "Epoch 10: Train_cls_acc=0.9940, Train_tag_acc=0.9207, Val_cls_acc=0.6351, Val_tag_acc=0.9237\n",
      "Epoch 11: Train_cls_acc=0.9962, Train_tag_acc=0.9205, Val_cls_acc=0.6520, Val_tag_acc=0.9209\n",
      "Epoch 12: Train_cls_acc=0.9972, Train_tag_acc=0.9206, Val_cls_acc=0.6345, Val_tag_acc=0.9218\n",
      "Epoch 13: Train_cls_acc=0.9980, Train_tag_acc=0.9207, Val_cls_acc=0.6484, Val_tag_acc=0.9243\n",
      "Epoch 14: Train_cls_acc=0.9985, Train_tag_acc=0.9207, Val_cls_acc=0.6405, Val_tag_acc=0.9257\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4442,  Tagging Acc: 0.9104, Overall Acc:0.1568\n",
      "Overall Acc:0.1568, Params: (type_emb_dim: 50, dtype_emb_dim:64)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3242, Train_tag_acc=0.9143, Val_cls_acc=0.4905, Val_tag_acc=0.9227\n",
      "Epoch 2: Train_cls_acc=0.7235, Train_tag_acc=0.9198, Val_cls_acc=0.5769, Val_tag_acc=0.9258\n",
      "Epoch 3: Train_cls_acc=0.8896, Train_tag_acc=0.9201, Val_cls_acc=0.5809, Val_tag_acc=0.9217\n",
      "Epoch 4: Train_cls_acc=0.9445, Train_tag_acc=0.9201, Val_cls_acc=0.6443, Val_tag_acc=0.9208\n",
      "Epoch 5: Train_cls_acc=0.9670, Train_tag_acc=0.9203, Val_cls_acc=0.6307, Val_tag_acc=0.9244\n",
      "Epoch 6: Train_cls_acc=0.9780, Train_tag_acc=0.9204, Val_cls_acc=0.6238, Val_tag_acc=0.9182\n",
      "Epoch 7: Train_cls_acc=0.9851, Train_tag_acc=0.9204, Val_cls_acc=0.6462, Val_tag_acc=0.9243\n",
      "Epoch 8: Train_cls_acc=0.9898, Train_tag_acc=0.9204, Val_cls_acc=0.6374, Val_tag_acc=0.9185\n",
      "Epoch 9: Train_cls_acc=0.9926, Train_tag_acc=0.9205, Val_cls_acc=0.6341, Val_tag_acc=0.9243\n",
      "Epoch 10: Train_cls_acc=0.9941, Train_tag_acc=0.9207, Val_cls_acc=0.6630, Val_tag_acc=0.9191\n",
      "Epoch 11: Train_cls_acc=0.9952, Train_tag_acc=0.9207, Val_cls_acc=0.6610, Val_tag_acc=0.9251\n",
      "Epoch 12: Train_cls_acc=0.9969, Train_tag_acc=0.9207, Val_cls_acc=0.6560, Val_tag_acc=0.9253\n",
      "Epoch 13: Train_cls_acc=0.9973, Train_tag_acc=0.9205, Val_cls_acc=0.6708, Val_tag_acc=0.9256\n",
      "Epoch 14: Train_cls_acc=0.9984, Train_tag_acc=0.9206, Val_cls_acc=0.6526, Val_tag_acc=0.9253\n",
      "Epoch 15: Train_cls_acc=0.9986, Train_tag_acc=0.9210, Val_cls_acc=0.6501, Val_tag_acc=0.9258\n",
      "Epoch 16: Train_cls_acc=0.9991, Train_tag_acc=0.9208, Val_cls_acc=0.6407, Val_tag_acc=0.9253\n",
      "Epoch 17: Train_cls_acc=0.9992, Train_tag_acc=0.9209, Val_cls_acc=0.6437, Val_tag_acc=0.9208\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9207, Val_cls_acc=0.6616, Val_tag_acc=0.9252\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4496,  Tagging Acc: 0.9105, Overall Acc:0.1660\n",
      "Overall Acc:0.1660, Params: (type_emb_dim: 64, dtype_emb_dim:8)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3403, Train_tag_acc=0.9134, Val_cls_acc=0.5116, Val_tag_acc=0.9157\n",
      "Epoch 2: Train_cls_acc=0.7527, Train_tag_acc=0.9200, Val_cls_acc=0.6078, Val_tag_acc=0.9257\n",
      "Epoch 3: Train_cls_acc=0.8956, Train_tag_acc=0.9198, Val_cls_acc=0.6146, Val_tag_acc=0.9251\n",
      "Epoch 4: Train_cls_acc=0.9463, Train_tag_acc=0.9207, Val_cls_acc=0.6199, Val_tag_acc=0.9241\n",
      "Epoch 5: Train_cls_acc=0.9673, Train_tag_acc=0.9204, Val_cls_acc=0.6247, Val_tag_acc=0.9249\n",
      "Epoch 6: Train_cls_acc=0.9785, Train_tag_acc=0.9203, Val_cls_acc=0.6484, Val_tag_acc=0.9230\n",
      "Epoch 7: Train_cls_acc=0.9858, Train_tag_acc=0.9204, Val_cls_acc=0.6320, Val_tag_acc=0.9219\n",
      "Epoch 8: Train_cls_acc=0.9895, Train_tag_acc=0.9205, Val_cls_acc=0.6297, Val_tag_acc=0.9221\n",
      "Epoch 9: Train_cls_acc=0.9923, Train_tag_acc=0.9205, Val_cls_acc=0.6551, Val_tag_acc=0.9280\n",
      "Epoch 10: Train_cls_acc=0.9945, Train_tag_acc=0.9206, Val_cls_acc=0.6426, Val_tag_acc=0.9231\n",
      "Epoch 11: Train_cls_acc=0.9958, Train_tag_acc=0.9206, Val_cls_acc=0.6491, Val_tag_acc=0.9253\n",
      "Epoch 12: Train_cls_acc=0.9970, Train_tag_acc=0.9207, Val_cls_acc=0.6593, Val_tag_acc=0.9252\n",
      "Epoch 13: Train_cls_acc=0.9978, Train_tag_acc=0.9206, Val_cls_acc=0.6528, Val_tag_acc=0.9175\n",
      "Epoch 14: Train_cls_acc=0.9983, Train_tag_acc=0.9206, Val_cls_acc=0.6660, Val_tag_acc=0.9226\n",
      "Epoch 15: Train_cls_acc=0.9988, Train_tag_acc=0.9206, Val_cls_acc=0.6666, Val_tag_acc=0.9256\n",
      "Epoch 16: Train_cls_acc=0.9988, Train_tag_acc=0.9208, Val_cls_acc=0.6628, Val_tag_acc=0.9208\n",
      "Epoch 17: Train_cls_acc=0.9992, Train_tag_acc=0.9211, Val_cls_acc=0.6676, Val_tag_acc=0.9244\n",
      "Epoch 18: Train_cls_acc=0.9994, Train_tag_acc=0.9208, Val_cls_acc=0.6639, Val_tag_acc=0.9252\n",
      "Epoch 19: Train_cls_acc=0.9993, Train_tag_acc=0.9207, Val_cls_acc=0.6647, Val_tag_acc=0.9242\n",
      "Epoch 20: Train_cls_acc=0.9994, Train_tag_acc=0.9209, Val_cls_acc=0.6489, Val_tag_acc=0.9239\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4414,  Tagging Acc: 0.9155, Overall Acc:0.1526\n",
      "Overall Acc:0.1526, Params: (type_emb_dim: 64, dtype_emb_dim:16)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3572, Train_tag_acc=0.9140, Val_cls_acc=0.4986, Val_tag_acc=0.9210\n",
      "Epoch 2: Train_cls_acc=0.7549, Train_tag_acc=0.9199, Val_cls_acc=0.6078, Val_tag_acc=0.9229\n",
      "Epoch 3: Train_cls_acc=0.8958, Train_tag_acc=0.9202, Val_cls_acc=0.6301, Val_tag_acc=0.9204\n",
      "Epoch 4: Train_cls_acc=0.9442, Train_tag_acc=0.9203, Val_cls_acc=0.6232, Val_tag_acc=0.9232\n",
      "Epoch 5: Train_cls_acc=0.9666, Train_tag_acc=0.9202, Val_cls_acc=0.6437, Val_tag_acc=0.9224\n",
      "Epoch 6: Train_cls_acc=0.9782, Train_tag_acc=0.9205, Val_cls_acc=0.6547, Val_tag_acc=0.9238\n",
      "Epoch 7: Train_cls_acc=0.9843, Train_tag_acc=0.9205, Val_cls_acc=0.6551, Val_tag_acc=0.9244\n",
      "Epoch 8: Train_cls_acc=0.9884, Train_tag_acc=0.9205, Val_cls_acc=0.6499, Val_tag_acc=0.9240\n",
      "Epoch 9: Train_cls_acc=0.9916, Train_tag_acc=0.9206, Val_cls_acc=0.6505, Val_tag_acc=0.9268\n",
      "Epoch 10: Train_cls_acc=0.9939, Train_tag_acc=0.9206, Val_cls_acc=0.6461, Val_tag_acc=0.9241\n",
      "Epoch 11: Train_cls_acc=0.9953, Train_tag_acc=0.9207, Val_cls_acc=0.6493, Val_tag_acc=0.9238\n",
      "Epoch 12: Train_cls_acc=0.9965, Train_tag_acc=0.9205, Val_cls_acc=0.6605, Val_tag_acc=0.9251\n",
      "Epoch 13: Train_cls_acc=0.9974, Train_tag_acc=0.9210, Val_cls_acc=0.6484, Val_tag_acc=0.9252\n",
      "Epoch 14: Train_cls_acc=0.9981, Train_tag_acc=0.9209, Val_cls_acc=0.6522, Val_tag_acc=0.9251\n",
      "Epoch 15: Train_cls_acc=0.9986, Train_tag_acc=0.9208, Val_cls_acc=0.6541, Val_tag_acc=0.9205\n",
      "Epoch 16: Train_cls_acc=0.9985, Train_tag_acc=0.9208, Val_cls_acc=0.6466, Val_tag_acc=0.9251\n",
      "Epoch 17: Train_cls_acc=0.9994, Train_tag_acc=0.9209, Val_cls_acc=0.6524, Val_tag_acc=0.9256\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4400,  Tagging Acc: 0.9150, Overall Acc:0.1246\n",
      "Overall Acc:0.1246, Params: (type_emb_dim: 64, dtype_emb_dim:32)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3543, Train_tag_acc=0.9142, Val_cls_acc=0.5085, Val_tag_acc=0.9192\n",
      "Epoch 2: Train_cls_acc=0.7491, Train_tag_acc=0.9196, Val_cls_acc=0.5844, Val_tag_acc=0.9244\n",
      "Epoch 3: Train_cls_acc=0.8933, Train_tag_acc=0.9200, Val_cls_acc=0.6259, Val_tag_acc=0.9183\n",
      "Epoch 4: Train_cls_acc=0.9439, Train_tag_acc=0.9202, Val_cls_acc=0.6510, Val_tag_acc=0.9236\n",
      "Epoch 5: Train_cls_acc=0.9662, Train_tag_acc=0.9203, Val_cls_acc=0.6330, Val_tag_acc=0.9235\n",
      "Epoch 6: Train_cls_acc=0.9780, Train_tag_acc=0.9206, Val_cls_acc=0.6499, Val_tag_acc=0.9201\n",
      "Epoch 7: Train_cls_acc=0.9855, Train_tag_acc=0.9205, Val_cls_acc=0.6466, Val_tag_acc=0.9234\n",
      "Epoch 8: Train_cls_acc=0.9902, Train_tag_acc=0.9208, Val_cls_acc=0.6643, Val_tag_acc=0.9155\n",
      "Epoch 9: Train_cls_acc=0.9921, Train_tag_acc=0.9208, Val_cls_acc=0.6570, Val_tag_acc=0.9251\n",
      "Epoch 10: Train_cls_acc=0.9947, Train_tag_acc=0.9205, Val_cls_acc=0.6564, Val_tag_acc=0.9251\n",
      "Epoch 11: Train_cls_acc=0.9959, Train_tag_acc=0.9207, Val_cls_acc=0.6601, Val_tag_acc=0.9241\n",
      "Epoch 12: Train_cls_acc=0.9969, Train_tag_acc=0.9206, Val_cls_acc=0.6620, Val_tag_acc=0.9253\n",
      "Epoch 13: Train_cls_acc=0.9978, Train_tag_acc=0.9206, Val_cls_acc=0.6710, Val_tag_acc=0.9250\n",
      "Epoch 14: Train_cls_acc=0.9986, Train_tag_acc=0.9207, Val_cls_acc=0.6712, Val_tag_acc=0.9249\n",
      "Epoch 15: Train_cls_acc=0.9984, Train_tag_acc=0.9206, Val_cls_acc=0.6553, Val_tag_acc=0.9253\n",
      "Epoch 16: Train_cls_acc=0.9993, Train_tag_acc=0.9210, Val_cls_acc=0.6637, Val_tag_acc=0.9179\n",
      "Epoch 17: Train_cls_acc=0.9988, Train_tag_acc=0.9208, Val_cls_acc=0.6670, Val_tag_acc=0.9265\n",
      "Epoch 18: Train_cls_acc=0.9992, Train_tag_acc=0.9209, Val_cls_acc=0.6818, Val_tag_acc=0.9252\n",
      "Epoch 19: Train_cls_acc=0.9991, Train_tag_acc=0.9210, Val_cls_acc=0.6716, Val_tag_acc=0.9254\n",
      "Epoch 20: Train_cls_acc=0.9996, Train_tag_acc=0.9207, Val_cls_acc=0.6779, Val_tag_acc=0.9219\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4409,  Tagging Acc: 0.9102, Overall Acc:0.1739\n",
      "Overall Acc:0.1739, Params: (type_emb_dim: 64, dtype_emb_dim:50)\n",
      "Initialize feedforward model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.3452, Train_tag_acc=0.9157, Val_cls_acc=0.5178, Val_tag_acc=0.9230\n",
      "Epoch 2: Train_cls_acc=0.7534, Train_tag_acc=0.9199, Val_cls_acc=0.5940, Val_tag_acc=0.9236\n",
      "Epoch 3: Train_cls_acc=0.8941, Train_tag_acc=0.9201, Val_cls_acc=0.6126, Val_tag_acc=0.9246\n",
      "Epoch 4: Train_cls_acc=0.9458, Train_tag_acc=0.9198, Val_cls_acc=0.6159, Val_tag_acc=0.9244\n",
      "Epoch 5: Train_cls_acc=0.9675, Train_tag_acc=0.9204, Val_cls_acc=0.6240, Val_tag_acc=0.9180\n",
      "Epoch 6: Train_cls_acc=0.9773, Train_tag_acc=0.9204, Val_cls_acc=0.6190, Val_tag_acc=0.9174\n",
      "Epoch 7: Train_cls_acc=0.9855, Train_tag_acc=0.9205, Val_cls_acc=0.6443, Val_tag_acc=0.9235\n",
      "Epoch 8: Train_cls_acc=0.9893, Train_tag_acc=0.9205, Val_cls_acc=0.6263, Val_tag_acc=0.9243\n",
      "Epoch 9: Train_cls_acc=0.9914, Train_tag_acc=0.9206, Val_cls_acc=0.6493, Val_tag_acc=0.9257\n",
      "Epoch 10: Train_cls_acc=0.9940, Train_tag_acc=0.9208, Val_cls_acc=0.6489, Val_tag_acc=0.9178\n",
      "Epoch 11: Train_cls_acc=0.9956, Train_tag_acc=0.9207, Val_cls_acc=0.6570, Val_tag_acc=0.9238\n",
      "Epoch 12: Train_cls_acc=0.9967, Train_tag_acc=0.9207, Val_cls_acc=0.6292, Val_tag_acc=0.9186\n",
      "Epoch 13: Train_cls_acc=0.9978, Train_tag_acc=0.9207, Val_cls_acc=0.6453, Val_tag_acc=0.9242\n",
      "Epoch 14: Train_cls_acc=0.9980, Train_tag_acc=0.9206, Val_cls_acc=0.6449, Val_tag_acc=0.9253\n",
      "Epoch 15: Train_cls_acc=0.9985, Train_tag_acc=0.9208, Val_cls_acc=0.6382, Val_tag_acc=0.9238\n",
      "Epoch 16: Train_cls_acc=0.9990, Train_tag_acc=0.9206, Val_cls_acc=0.6497, Val_tag_acc=0.9204\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set feedforward —  Classification Acc: 0.4414,  Tagging Acc: 0.9190, Overall Acc:0.1720\n",
      "Overall Acc:0.1720, Params: (type_emb_dim: 64, dtype_emb_dim:64)\n",
      "Best accuracy of feedforward - Acc: 0.18014888337468982, params: (type_emb_dim: 16, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4297, Train_tag_acc=0.9399, Val_cls_acc=0.4976, Val_tag_acc=0.9510\n",
      "Epoch 2: Train_cls_acc=0.8786, Train_tag_acc=0.9747, Val_cls_acc=0.6023, Val_tag_acc=0.9596\n",
      "Epoch 3: Train_cls_acc=0.9655, Train_tag_acc=0.9869, Val_cls_acc=0.6307, Val_tag_acc=0.9658\n",
      "Epoch 4: Train_cls_acc=0.9839, Train_tag_acc=0.9921, Val_cls_acc=0.6307, Val_tag_acc=0.9668\n",
      "Epoch 5: Train_cls_acc=0.9914, Train_tag_acc=0.9959, Val_cls_acc=0.6560, Val_tag_acc=0.9678\n",
      "Epoch 6: Train_cls_acc=0.9934, Train_tag_acc=0.9975, Val_cls_acc=0.6666, Val_tag_acc=0.9666\n",
      "Epoch 7: Train_cls_acc=0.9952, Train_tag_acc=0.9985, Val_cls_acc=0.6370, Val_tag_acc=0.9683\n",
      "Epoch 8: Train_cls_acc=0.9958, Train_tag_acc=0.9988, Val_cls_acc=0.6660, Val_tag_acc=0.9701\n",
      "Epoch 9: Train_cls_acc=0.9966, Train_tag_acc=0.9992, Val_cls_acc=0.6451, Val_tag_acc=0.9683\n",
      "Epoch 10: Train_cls_acc=0.9992, Train_tag_acc=0.9999, Val_cls_acc=0.6466, Val_tag_acc=0.9698\n",
      "Epoch 11: Train_cls_acc=0.9958, Train_tag_acc=0.9990, Val_cls_acc=0.6430, Val_tag_acc=0.9703\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3965,  Tagging Acc: 0.9722, Overall Acc:0.2469\n",
      "Overall Acc:0.2469, Params: (type_emb_dim: 8, dtype_emb_dim:8)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4440, Train_tag_acc=0.9411, Val_cls_acc=0.4780, Val_tag_acc=0.9549\n",
      "Epoch 2: Train_cls_acc=0.8851, Train_tag_acc=0.9763, Val_cls_acc=0.5859, Val_tag_acc=0.9666\n",
      "Epoch 3: Train_cls_acc=0.9658, Train_tag_acc=0.9867, Val_cls_acc=0.6051, Val_tag_acc=0.9719\n",
      "Epoch 4: Train_cls_acc=0.9851, Train_tag_acc=0.9926, Val_cls_acc=0.6013, Val_tag_acc=0.9696\n",
      "Epoch 5: Train_cls_acc=0.9904, Train_tag_acc=0.9957, Val_cls_acc=0.6388, Val_tag_acc=0.9712\n",
      "Epoch 6: Train_cls_acc=0.9937, Train_tag_acc=0.9978, Val_cls_acc=0.6332, Val_tag_acc=0.9714\n",
      "Epoch 7: Train_cls_acc=0.9940, Train_tag_acc=0.9980, Val_cls_acc=0.6614, Val_tag_acc=0.9709\n",
      "Epoch 8: Train_cls_acc=0.9973, Train_tag_acc=0.9993, Val_cls_acc=0.6353, Val_tag_acc=0.9702\n",
      "Epoch 9: Train_cls_acc=0.9969, Train_tag_acc=0.9992, Val_cls_acc=0.6334, Val_tag_acc=0.9695\n",
      "Epoch 10: Train_cls_acc=0.9975, Train_tag_acc=0.9993, Val_cls_acc=0.6341, Val_tag_acc=0.9714\n",
      "Epoch 11: Train_cls_acc=0.9991, Train_tag_acc=0.9999, Val_cls_acc=0.6497, Val_tag_acc=0.9727\n",
      "Epoch 12: Train_cls_acc=0.9965, Train_tag_acc=0.9990, Val_cls_acc=0.6372, Val_tag_acc=0.9718\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3824,  Tagging Acc: 0.9752, Overall Acc:0.2323\n",
      "Overall Acc:0.2323, Params: (type_emb_dim: 8, dtype_emb_dim:16)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4449, Train_tag_acc=0.9454, Val_cls_acc=0.4698, Val_tag_acc=0.9522\n",
      "Epoch 2: Train_cls_acc=0.8756, Train_tag_acc=0.9765, Val_cls_acc=0.5917, Val_tag_acc=0.9648\n",
      "Epoch 3: Train_cls_acc=0.9663, Train_tag_acc=0.9872, Val_cls_acc=0.5879, Val_tag_acc=0.9679\n",
      "Epoch 4: Train_cls_acc=0.9839, Train_tag_acc=0.9926, Val_cls_acc=0.6315, Val_tag_acc=0.9739\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9954, Val_cls_acc=0.6184, Val_tag_acc=0.9741\n",
      "Epoch 6: Train_cls_acc=0.9932, Train_tag_acc=0.9978, Val_cls_acc=0.6407, Val_tag_acc=0.9767\n",
      "Epoch 7: Train_cls_acc=0.9941, Train_tag_acc=0.9984, Val_cls_acc=0.6411, Val_tag_acc=0.9769\n",
      "Epoch 8: Train_cls_acc=0.9969, Train_tag_acc=0.9993, Val_cls_acc=0.6499, Val_tag_acc=0.9744\n",
      "Epoch 9: Train_cls_acc=0.9966, Train_tag_acc=0.9991, Val_cls_acc=0.6220, Val_tag_acc=0.9758\n",
      "Epoch 10: Train_cls_acc=0.9980, Train_tag_acc=0.9996, Val_cls_acc=0.6355, Val_tag_acc=0.9750\n",
      "Epoch 11: Train_cls_acc=0.9971, Train_tag_acc=0.9993, Val_cls_acc=0.6201, Val_tag_acc=0.9749\n",
      "Epoch 12: Train_cls_acc=0.9982, Train_tag_acc=0.9995, Val_cls_acc=0.6626, Val_tag_acc=0.9761\n",
      "Epoch 13: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6679, Val_tag_acc=0.9758\n",
      "Epoch 14: Train_cls_acc=0.9967, Train_tag_acc=0.9992, Val_cls_acc=0.6437, Val_tag_acc=0.9747\n",
      "Epoch 15: Train_cls_acc=0.9996, Train_tag_acc=0.9999, Val_cls_acc=0.6549, Val_tag_acc=0.9770\n",
      "Epoch 16: Train_cls_acc=0.9994, Train_tag_acc=0.9998, Val_cls_acc=0.6610, Val_tag_acc=0.9760\n",
      "Epoch 17: Train_cls_acc=0.9984, Train_tag_acc=0.9996, Val_cls_acc=0.6420, Val_tag_acc=0.9764\n",
      "Epoch 18: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6699, Val_tag_acc=0.9761\n",
      "Epoch 19: Train_cls_acc=0.9989, Train_tag_acc=0.9996, Val_cls_acc=0.6752, Val_tag_acc=0.9754\n",
      "Epoch 20: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6710, Val_tag_acc=0.9758\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4233,  Tagging Acc: 0.9731, Overall Acc:0.2707\n",
      "Overall Acc:0.2707, Params: (type_emb_dim: 8, dtype_emb_dim:32)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4560, Train_tag_acc=0.9483, Val_cls_acc=0.5412, Val_tag_acc=0.9622\n",
      "Epoch 2: Train_cls_acc=0.8916, Train_tag_acc=0.9791, Val_cls_acc=0.6138, Val_tag_acc=0.9672\n",
      "Epoch 3: Train_cls_acc=0.9685, Train_tag_acc=0.9885, Val_cls_acc=0.6334, Val_tag_acc=0.9694\n",
      "Epoch 4: Train_cls_acc=0.9832, Train_tag_acc=0.9928, Val_cls_acc=0.5940, Val_tag_acc=0.9706\n",
      "Epoch 5: Train_cls_acc=0.9904, Train_tag_acc=0.9958, Val_cls_acc=0.6374, Val_tag_acc=0.9721\n",
      "Epoch 6: Train_cls_acc=0.9941, Train_tag_acc=0.9976, Val_cls_acc=0.6315, Val_tag_acc=0.9745\n",
      "Epoch 7: Train_cls_acc=0.9944, Train_tag_acc=0.9982, Val_cls_acc=0.6376, Val_tag_acc=0.9734\n",
      "Epoch 8: Train_cls_acc=0.9983, Train_tag_acc=0.9996, Val_cls_acc=0.6197, Val_tag_acc=0.9733\n",
      "Epoch 9: Train_cls_acc=0.9958, Train_tag_acc=0.9984, Val_cls_acc=0.6447, Val_tag_acc=0.9731\n",
      "Epoch 10: Train_cls_acc=0.9994, Train_tag_acc=0.9999, Val_cls_acc=0.6443, Val_tag_acc=0.9744\n",
      "Epoch 11: Train_cls_acc=0.9968, Train_tag_acc=0.9990, Val_cls_acc=0.6493, Val_tag_acc=0.9746\n",
      "Epoch 12: Train_cls_acc=0.9996, Train_tag_acc=0.9999, Val_cls_acc=0.6497, Val_tag_acc=0.9737\n",
      "Epoch 13: Train_cls_acc=0.9985, Train_tag_acc=0.9994, Val_cls_acc=0.6499, Val_tag_acc=0.9725\n",
      "Epoch 14: Train_cls_acc=0.9996, Train_tag_acc=0.9998, Val_cls_acc=0.6631, Val_tag_acc=0.9728\n",
      "Epoch 15: Train_cls_acc=0.9981, Train_tag_acc=0.9993, Val_cls_acc=0.6422, Val_tag_acc=0.9714\n",
      "Epoch 16: Train_cls_acc=0.9998, Train_tag_acc=0.9999, Val_cls_acc=0.6436, Val_tag_acc=0.9721\n",
      "Epoch 17: Train_cls_acc=1.0000, Train_tag_acc=0.9999, Val_cls_acc=0.6368, Val_tag_acc=0.9734\n",
      "Epoch 18: Train_cls_acc=0.9980, Train_tag_acc=0.9994, Val_cls_acc=0.6407, Val_tag_acc=0.9726\n",
      "Epoch 19: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6443, Val_tag_acc=0.9715\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4129,  Tagging Acc: 0.9778, Overall Acc:0.2797\n",
      "Overall Acc:0.2797, Params: (type_emb_dim: 8, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4650, Train_tag_acc=0.9464, Val_cls_acc=0.5427, Val_tag_acc=0.9594\n",
      "Epoch 2: Train_cls_acc=0.8837, Train_tag_acc=0.9784, Val_cls_acc=0.5583, Val_tag_acc=0.9616\n",
      "Epoch 3: Train_cls_acc=0.9683, Train_tag_acc=0.9879, Val_cls_acc=0.6032, Val_tag_acc=0.9689\n",
      "Epoch 4: Train_cls_acc=0.9843, Train_tag_acc=0.9923, Val_cls_acc=0.5790, Val_tag_acc=0.9709\n",
      "Epoch 5: Train_cls_acc=0.9888, Train_tag_acc=0.9950, Val_cls_acc=0.6142, Val_tag_acc=0.9706\n",
      "Epoch 6: Train_cls_acc=0.9924, Train_tag_acc=0.9970, Val_cls_acc=0.5769, Val_tag_acc=0.9695\n",
      "Epoch 7: Train_cls_acc=0.9957, Train_tag_acc=0.9986, Val_cls_acc=0.6399, Val_tag_acc=0.9727\n",
      "Epoch 8: Train_cls_acc=0.9958, Train_tag_acc=0.9988, Val_cls_acc=0.6405, Val_tag_acc=0.9686\n",
      "Epoch 9: Train_cls_acc=0.9968, Train_tag_acc=0.9991, Val_cls_acc=0.6486, Val_tag_acc=0.9734\n",
      "Epoch 10: Train_cls_acc=0.9989, Train_tag_acc=0.9997, Val_cls_acc=0.6593, Val_tag_acc=0.9748\n",
      "Epoch 11: Train_cls_acc=0.9969, Train_tag_acc=0.9991, Val_cls_acc=0.6486, Val_tag_acc=0.9740\n",
      "Epoch 12: Train_cls_acc=0.9993, Train_tag_acc=0.9999, Val_cls_acc=0.6270, Val_tag_acc=0.9744\n",
      "Epoch 13: Train_cls_acc=0.9981, Train_tag_acc=0.9991, Val_cls_acc=0.6562, Val_tag_acc=0.9741\n",
      "Epoch 14: Train_cls_acc=0.9994, Train_tag_acc=0.9997, Val_cls_acc=0.6370, Val_tag_acc=0.9757\n",
      "Epoch 15: Train_cls_acc=0.9984, Train_tag_acc=0.9995, Val_cls_acc=0.6507, Val_tag_acc=0.9748\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4149,  Tagging Acc: 0.9712, Overall Acc:0.2454\n",
      "Overall Acc:0.2454, Params: (type_emb_dim: 8, dtype_emb_dim:64)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4346, Train_tag_acc=0.9432, Val_cls_acc=0.5214, Val_tag_acc=0.9572\n",
      "Epoch 2: Train_cls_acc=0.8869, Train_tag_acc=0.9769, Val_cls_acc=0.6142, Val_tag_acc=0.9681\n",
      "Epoch 3: Train_cls_acc=0.9697, Train_tag_acc=0.9869, Val_cls_acc=0.5500, Val_tag_acc=0.9660\n",
      "Epoch 4: Train_cls_acc=0.9864, Train_tag_acc=0.9925, Val_cls_acc=0.5969, Val_tag_acc=0.9684\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9954, Val_cls_acc=0.6334, Val_tag_acc=0.9701\n",
      "Epoch 6: Train_cls_acc=0.9947, Train_tag_acc=0.9977, Val_cls_acc=0.6174, Val_tag_acc=0.9704\n",
      "Epoch 7: Train_cls_acc=0.9946, Train_tag_acc=0.9983, Val_cls_acc=0.6562, Val_tag_acc=0.9729\n",
      "Epoch 8: Train_cls_acc=0.9981, Train_tag_acc=0.9994, Val_cls_acc=0.6512, Val_tag_acc=0.9718\n",
      "Epoch 9: Train_cls_acc=0.9953, Train_tag_acc=0.9987, Val_cls_acc=0.6480, Val_tag_acc=0.9697\n",
      "Epoch 10: Train_cls_acc=0.9994, Train_tag_acc=1.0000, Val_cls_acc=0.6368, Val_tag_acc=0.9723\n",
      "Epoch 11: Train_cls_acc=0.9975, Train_tag_acc=0.9990, Val_cls_acc=0.6209, Val_tag_acc=0.9705\n",
      "Epoch 12: Train_cls_acc=0.9993, Train_tag_acc=0.9998, Val_cls_acc=0.6512, Val_tag_acc=0.9715\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3797,  Tagging Acc: 0.9731, Overall Acc:0.2380\n",
      "Overall Acc:0.2380, Params: (type_emb_dim: 16, dtype_emb_dim:8)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4544, Train_tag_acc=0.9448, Val_cls_acc=0.5168, Val_tag_acc=0.9586\n",
      "Epoch 2: Train_cls_acc=0.8792, Train_tag_acc=0.9756, Val_cls_acc=0.6128, Val_tag_acc=0.9622\n",
      "Epoch 3: Train_cls_acc=0.9668, Train_tag_acc=0.9863, Val_cls_acc=0.6361, Val_tag_acc=0.9679\n",
      "Epoch 4: Train_cls_acc=0.9801, Train_tag_acc=0.9912, Val_cls_acc=0.6138, Val_tag_acc=0.9664\n",
      "Epoch 5: Train_cls_acc=0.9898, Train_tag_acc=0.9955, Val_cls_acc=0.6468, Val_tag_acc=0.9702\n",
      "Epoch 6: Train_cls_acc=0.9900, Train_tag_acc=0.9966, Val_cls_acc=0.6330, Val_tag_acc=0.9726\n",
      "Epoch 7: Train_cls_acc=0.9957, Train_tag_acc=0.9985, Val_cls_acc=0.6123, Val_tag_acc=0.9707\n",
      "Epoch 8: Train_cls_acc=0.9964, Train_tag_acc=0.9989, Val_cls_acc=0.6489, Val_tag_acc=0.9750\n",
      "Epoch 9: Train_cls_acc=0.9980, Train_tag_acc=0.9995, Val_cls_acc=0.6359, Val_tag_acc=0.9733\n",
      "Epoch 10: Train_cls_acc=0.9964, Train_tag_acc=0.9988, Val_cls_acc=0.6409, Val_tag_acc=0.9730\n",
      "Epoch 11: Train_cls_acc=0.9990, Train_tag_acc=0.9997, Val_cls_acc=0.6395, Val_tag_acc=0.9744\n",
      "Epoch 12: Train_cls_acc=0.9957, Train_tag_acc=0.9990, Val_cls_acc=0.6672, Val_tag_acc=0.9755\n",
      "Epoch 13: Train_cls_acc=0.9995, Train_tag_acc=0.9999, Val_cls_acc=0.6703, Val_tag_acc=0.9751\n",
      "Epoch 14: Train_cls_acc=0.9994, Train_tag_acc=0.9999, Val_cls_acc=0.6261, Val_tag_acc=0.9709\n",
      "Epoch 15: Train_cls_acc=0.9972, Train_tag_acc=0.9991, Val_cls_acc=0.6391, Val_tag_acc=0.9769\n",
      "Epoch 16: Train_cls_acc=1.0000, Train_tag_acc=1.0000, Val_cls_acc=0.6336, Val_tag_acc=0.9770\n",
      "Epoch 17: Train_cls_acc=0.9985, Train_tag_acc=0.9992, Val_cls_acc=0.6268, Val_tag_acc=0.9752\n",
      "Epoch 18: Train_cls_acc=0.9994, Train_tag_acc=0.9999, Val_cls_acc=0.6520, Val_tag_acc=0.9742\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4194,  Tagging Acc: 0.9742, Overall Acc:0.2675\n",
      "Overall Acc:0.2675, Params: (type_emb_dim: 16, dtype_emb_dim:16)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4639, Train_tag_acc=0.9458, Val_cls_acc=0.5575, Val_tag_acc=0.9524\n",
      "Epoch 2: Train_cls_acc=0.8938, Train_tag_acc=0.9764, Val_cls_acc=0.6224, Val_tag_acc=0.9611\n",
      "Epoch 3: Train_cls_acc=0.9710, Train_tag_acc=0.9871, Val_cls_acc=0.5911, Val_tag_acc=0.9624\n",
      "Epoch 4: Train_cls_acc=0.9853, Train_tag_acc=0.9925, Val_cls_acc=0.6359, Val_tag_acc=0.9680\n",
      "Epoch 5: Train_cls_acc=0.9906, Train_tag_acc=0.9957, Val_cls_acc=0.6510, Val_tag_acc=0.9678\n",
      "Epoch 6: Train_cls_acc=0.9927, Train_tag_acc=0.9971, Val_cls_acc=0.6597, Val_tag_acc=0.9694\n",
      "Epoch 7: Train_cls_acc=0.9948, Train_tag_acc=0.9984, Val_cls_acc=0.6585, Val_tag_acc=0.9687\n",
      "Epoch 8: Train_cls_acc=0.9958, Train_tag_acc=0.9988, Val_cls_acc=0.6618, Val_tag_acc=0.9696\n",
      "Epoch 9: Train_cls_acc=0.9979, Train_tag_acc=0.9993, Val_cls_acc=0.6388, Val_tag_acc=0.9691\n",
      "Epoch 10: Train_cls_acc=0.9971, Train_tag_acc=0.9988, Val_cls_acc=0.6770, Val_tag_acc=0.9718\n",
      "Epoch 11: Train_cls_acc=0.9995, Train_tag_acc=1.0000, Val_cls_acc=0.6641, Val_tag_acc=0.9704\n",
      "Epoch 12: Train_cls_acc=0.9968, Train_tag_acc=0.9986, Val_cls_acc=0.6368, Val_tag_acc=0.9718\n",
      "Epoch 13: Train_cls_acc=0.9998, Train_tag_acc=1.0000, Val_cls_acc=0.6526, Val_tag_acc=0.9720\n",
      "Epoch 14: Train_cls_acc=0.9988, Train_tag_acc=0.9996, Val_cls_acc=0.6666, Val_tag_acc=0.9708\n",
      "Epoch 15: Train_cls_acc=0.9999, Train_tag_acc=0.9999, Val_cls_acc=0.6562, Val_tag_acc=0.9715\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3866,  Tagging Acc: 0.9700, Overall Acc:0.2481\n",
      "Overall Acc:0.2481, Params: (type_emb_dim: 16, dtype_emb_dim:32)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4697, Train_tag_acc=0.9456, Val_cls_acc=0.5053, Val_tag_acc=0.9578\n",
      "Epoch 2: Train_cls_acc=0.8914, Train_tag_acc=0.9770, Val_cls_acc=0.5485, Val_tag_acc=0.9646\n",
      "Epoch 3: Train_cls_acc=0.9688, Train_tag_acc=0.9874, Val_cls_acc=0.5996, Val_tag_acc=0.9692\n",
      "Epoch 4: Train_cls_acc=0.9826, Train_tag_acc=0.9924, Val_cls_acc=0.5982, Val_tag_acc=0.9693\n",
      "Epoch 5: Train_cls_acc=0.9881, Train_tag_acc=0.9951, Val_cls_acc=0.6146, Val_tag_acc=0.9684\n",
      "Epoch 6: Train_cls_acc=0.9949, Train_tag_acc=0.9977, Val_cls_acc=0.6042, Val_tag_acc=0.9703\n",
      "Epoch 7: Train_cls_acc=0.9937, Train_tag_acc=0.9979, Val_cls_acc=0.6436, Val_tag_acc=0.9717\n",
      "Epoch 8: Train_cls_acc=0.9980, Train_tag_acc=0.9995, Val_cls_acc=0.6272, Val_tag_acc=0.9704\n",
      "Epoch 9: Train_cls_acc=0.9942, Train_tag_acc=0.9983, Val_cls_acc=0.6144, Val_tag_acc=0.9706\n",
      "Epoch 10: Train_cls_acc=0.9973, Train_tag_acc=0.9994, Val_cls_acc=0.6211, Val_tag_acc=0.9732\n",
      "Epoch 11: Train_cls_acc=0.9994, Train_tag_acc=0.9998, Val_cls_acc=0.6411, Val_tag_acc=0.9738\n",
      "Epoch 12: Train_cls_acc=0.9973, Train_tag_acc=0.9992, Val_cls_acc=0.6157, Val_tag_acc=0.9737\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3747,  Tagging Acc: 0.9733, Overall Acc:0.2107\n",
      "Overall Acc:0.2107, Params: (type_emb_dim: 16, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4734, Train_tag_acc=0.9473, Val_cls_acc=0.4651, Val_tag_acc=0.9586\n",
      "Epoch 2: Train_cls_acc=0.8872, Train_tag_acc=0.9776, Val_cls_acc=0.5637, Val_tag_acc=0.9651\n",
      "Epoch 3: Train_cls_acc=0.9638, Train_tag_acc=0.9871, Val_cls_acc=0.5775, Val_tag_acc=0.9686\n",
      "Epoch 4: Train_cls_acc=0.9818, Train_tag_acc=0.9919, Val_cls_acc=0.6051, Val_tag_acc=0.9701\n",
      "Epoch 5: Train_cls_acc=0.9903, Train_tag_acc=0.9956, Val_cls_acc=0.5882, Val_tag_acc=0.9676\n",
      "Epoch 6: Train_cls_acc=0.9940, Train_tag_acc=0.9979, Val_cls_acc=0.5882, Val_tag_acc=0.9710\n",
      "Epoch 7: Train_cls_acc=0.9945, Train_tag_acc=0.9981, Val_cls_acc=0.6042, Val_tag_acc=0.9688\n",
      "Epoch 8: Train_cls_acc=0.9970, Train_tag_acc=0.9991, Val_cls_acc=0.6138, Val_tag_acc=0.9729\n",
      "Epoch 9: Train_cls_acc=0.9967, Train_tag_acc=0.9989, Val_cls_acc=0.6487, Val_tag_acc=0.9728\n",
      "Epoch 10: Train_cls_acc=0.9992, Train_tag_acc=0.9998, Val_cls_acc=0.6372, Val_tag_acc=0.9734\n",
      "Epoch 11: Train_cls_acc=0.9977, Train_tag_acc=0.9992, Val_cls_acc=0.6338, Val_tag_acc=0.9682\n",
      "Epoch 12: Train_cls_acc=0.9975, Train_tag_acc=0.9992, Val_cls_acc=0.6426, Val_tag_acc=0.9740\n",
      "Epoch 13: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6368, Val_tag_acc=0.9745\n",
      "Epoch 14: Train_cls_acc=0.9979, Train_tag_acc=0.9992, Val_cls_acc=0.6263, Val_tag_acc=0.9726\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3722,  Tagging Acc: 0.9749, Overall Acc:0.2186\n",
      "Overall Acc:0.2186, Params: (type_emb_dim: 16, dtype_emb_dim:64)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4717, Train_tag_acc=0.9465, Val_cls_acc=0.5051, Val_tag_acc=0.9574\n",
      "Epoch 2: Train_cls_acc=0.8921, Train_tag_acc=0.9772, Val_cls_acc=0.5581, Val_tag_acc=0.9658\n",
      "Epoch 3: Train_cls_acc=0.9635, Train_tag_acc=0.9867, Val_cls_acc=0.5717, Val_tag_acc=0.9662\n",
      "Epoch 4: Train_cls_acc=0.9831, Train_tag_acc=0.9923, Val_cls_acc=0.5938, Val_tag_acc=0.9675\n",
      "Epoch 5: Train_cls_acc=0.9891, Train_tag_acc=0.9952, Val_cls_acc=0.6096, Val_tag_acc=0.9693\n",
      "Epoch 6: Train_cls_acc=0.9930, Train_tag_acc=0.9972, Val_cls_acc=0.6061, Val_tag_acc=0.9730\n",
      "Epoch 7: Train_cls_acc=0.9952, Train_tag_acc=0.9986, Val_cls_acc=0.6069, Val_tag_acc=0.9692\n",
      "Epoch 8: Train_cls_acc=0.9955, Train_tag_acc=0.9986, Val_cls_acc=0.6215, Val_tag_acc=0.9699\n",
      "Epoch 9: Train_cls_acc=0.9977, Train_tag_acc=0.9994, Val_cls_acc=0.6301, Val_tag_acc=0.9721\n",
      "Epoch 10: Train_cls_acc=0.9959, Train_tag_acc=0.9991, Val_cls_acc=0.6069, Val_tag_acc=0.9665\n",
      "Epoch 11: Train_cls_acc=0.9977, Train_tag_acc=0.9993, Val_cls_acc=0.6315, Val_tag_acc=0.9692\n",
      "Epoch 12: Train_cls_acc=0.9994, Train_tag_acc=1.0000, Val_cls_acc=0.6411, Val_tag_acc=0.9715\n",
      "Epoch 13: Train_cls_acc=0.9974, Train_tag_acc=0.9991, Val_cls_acc=0.6213, Val_tag_acc=0.9684\n",
      "Epoch 14: Train_cls_acc=0.9986, Train_tag_acc=0.9996, Val_cls_acc=0.6303, Val_tag_acc=0.9710\n",
      "Epoch 15: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6539, Val_tag_acc=0.9726\n",
      "Epoch 16: Train_cls_acc=1.0000, Train_tag_acc=1.0000, Val_cls_acc=0.6503, Val_tag_acc=0.9718\n",
      "Epoch 17: Train_cls_acc=0.9970, Train_tag_acc=0.9990, Val_cls_acc=0.6470, Val_tag_acc=0.9735\n",
      "Epoch 18: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6315, Val_tag_acc=0.9742\n",
      "Epoch 19: Train_cls_acc=1.0000, Train_tag_acc=1.0000, Val_cls_acc=0.6528, Val_tag_acc=0.9747\n",
      "Epoch 20: Train_cls_acc=0.9978, Train_tag_acc=0.9992, Val_cls_acc=0.6288, Val_tag_acc=0.9719\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3928,  Tagging Acc: 0.9706, Overall Acc:0.2412\n",
      "Overall Acc:0.2412, Params: (type_emb_dim: 32, dtype_emb_dim:8)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4669, Train_tag_acc=0.9470, Val_cls_acc=0.5003, Val_tag_acc=0.9546\n",
      "Epoch 2: Train_cls_acc=0.8960, Train_tag_acc=0.9771, Val_cls_acc=0.5911, Val_tag_acc=0.9672\n",
      "Epoch 3: Train_cls_acc=0.9699, Train_tag_acc=0.9873, Val_cls_acc=0.6311, Val_tag_acc=0.9671\n",
      "Epoch 4: Train_cls_acc=0.9849, Train_tag_acc=0.9925, Val_cls_acc=0.6341, Val_tag_acc=0.9667\n",
      "Epoch 5: Train_cls_acc=0.9908, Train_tag_acc=0.9959, Val_cls_acc=0.6355, Val_tag_acc=0.9693\n",
      "Epoch 6: Train_cls_acc=0.9936, Train_tag_acc=0.9974, Val_cls_acc=0.6455, Val_tag_acc=0.9703\n",
      "Epoch 7: Train_cls_acc=0.9966, Train_tag_acc=0.9989, Val_cls_acc=0.6388, Val_tag_acc=0.9721\n",
      "Epoch 8: Train_cls_acc=0.9967, Train_tag_acc=0.9989, Val_cls_acc=0.6293, Val_tag_acc=0.9708\n",
      "Epoch 9: Train_cls_acc=0.9975, Train_tag_acc=0.9992, Val_cls_acc=0.6674, Val_tag_acc=0.9707\n",
      "Epoch 10: Train_cls_acc=0.9989, Train_tag_acc=0.9997, Val_cls_acc=0.6572, Val_tag_acc=0.9708\n",
      "Epoch 11: Train_cls_acc=0.9974, Train_tag_acc=0.9993, Val_cls_acc=0.6378, Val_tag_acc=0.9736\n",
      "Epoch 12: Train_cls_acc=0.9994, Train_tag_acc=0.9999, Val_cls_acc=0.6393, Val_tag_acc=0.9712\n",
      "Epoch 13: Train_cls_acc=0.9991, Train_tag_acc=0.9995, Val_cls_acc=0.6347, Val_tag_acc=0.9712\n",
      "Epoch 14: Train_cls_acc=0.9987, Train_tag_acc=0.9997, Val_cls_acc=0.6466, Val_tag_acc=0.9732\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4072,  Tagging Acc: 0.9707, Overall Acc:0.2506\n",
      "Overall Acc:0.2506, Params: (type_emb_dim: 32, dtype_emb_dim:16)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4656, Train_tag_acc=0.9465, Val_cls_acc=0.5068, Val_tag_acc=0.9601\n",
      "Epoch 2: Train_cls_acc=0.8966, Train_tag_acc=0.9784, Val_cls_acc=0.5669, Val_tag_acc=0.9663\n",
      "Epoch 3: Train_cls_acc=0.9690, Train_tag_acc=0.9883, Val_cls_acc=0.5973, Val_tag_acc=0.9698\n",
      "Epoch 4: Train_cls_acc=0.9829, Train_tag_acc=0.9929, Val_cls_acc=0.6007, Val_tag_acc=0.9695\n",
      "Epoch 5: Train_cls_acc=0.9907, Train_tag_acc=0.9959, Val_cls_acc=0.6307, Val_tag_acc=0.9712\n",
      "Epoch 6: Train_cls_acc=0.9937, Train_tag_acc=0.9978, Val_cls_acc=0.6005, Val_tag_acc=0.9705\n",
      "Epoch 7: Train_cls_acc=0.9935, Train_tag_acc=0.9979, Val_cls_acc=0.6067, Val_tag_acc=0.9732\n",
      "Epoch 8: Train_cls_acc=0.9977, Train_tag_acc=0.9992, Val_cls_acc=0.6399, Val_tag_acc=0.9739\n",
      "Epoch 9: Train_cls_acc=0.9987, Train_tag_acc=0.9997, Val_cls_acc=0.6313, Val_tag_acc=0.9739\n",
      "Epoch 10: Train_cls_acc=0.9965, Train_tag_acc=0.9987, Val_cls_acc=0.6232, Val_tag_acc=0.9689\n",
      "Epoch 11: Train_cls_acc=0.9990, Train_tag_acc=0.9998, Val_cls_acc=0.6295, Val_tag_acc=0.9714\n",
      "Epoch 12: Train_cls_acc=0.9998, Train_tag_acc=1.0000, Val_cls_acc=0.6307, Val_tag_acc=0.9716\n",
      "Epoch 13: Train_cls_acc=0.9955, Train_tag_acc=0.9985, Val_cls_acc=0.6048, Val_tag_acc=0.9704\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4042,  Tagging Acc: 0.9745, Overall Acc:0.2670\n",
      "Overall Acc:0.2670, Params: (type_emb_dim: 32, dtype_emb_dim:32)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4808, Train_tag_acc=0.9485, Val_cls_acc=0.4876, Val_tag_acc=0.9552\n",
      "Epoch 2: Train_cls_acc=0.8927, Train_tag_acc=0.9784, Val_cls_acc=0.5719, Val_tag_acc=0.9662\n",
      "Epoch 3: Train_cls_acc=0.9680, Train_tag_acc=0.9880, Val_cls_acc=0.6270, Val_tag_acc=0.9735\n",
      "Epoch 4: Train_cls_acc=0.9834, Train_tag_acc=0.9927, Val_cls_acc=0.6101, Val_tag_acc=0.9698\n",
      "Epoch 5: Train_cls_acc=0.9894, Train_tag_acc=0.9955, Val_cls_acc=0.6413, Val_tag_acc=0.9747\n",
      "Epoch 6: Train_cls_acc=0.9942, Train_tag_acc=0.9977, Val_cls_acc=0.6365, Val_tag_acc=0.9702\n",
      "Epoch 7: Train_cls_acc=0.9936, Train_tag_acc=0.9974, Val_cls_acc=0.6455, Val_tag_acc=0.9737\n",
      "Epoch 8: Train_cls_acc=0.9980, Train_tag_acc=0.9993, Val_cls_acc=0.6353, Val_tag_acc=0.9699\n",
      "Epoch 9: Train_cls_acc=0.9972, Train_tag_acc=0.9989, Val_cls_acc=0.6397, Val_tag_acc=0.9744\n",
      "Epoch 10: Train_cls_acc=0.9974, Train_tag_acc=0.9993, Val_cls_acc=0.6286, Val_tag_acc=0.9732\n",
      "Epoch 11: Train_cls_acc=0.9982, Train_tag_acc=0.9992, Val_cls_acc=0.6455, Val_tag_acc=0.9736\n",
      "Epoch 12: Train_cls_acc=0.9997, Train_tag_acc=0.9999, Val_cls_acc=0.6472, Val_tag_acc=0.9755\n",
      "Epoch 13: Train_cls_acc=0.9977, Train_tag_acc=0.9991, Val_cls_acc=0.6007, Val_tag_acc=0.9740\n",
      "Epoch 14: Train_cls_acc=0.9983, Train_tag_acc=0.9995, Val_cls_acc=0.6578, Val_tag_acc=0.9753\n",
      "Epoch 15: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6566, Val_tag_acc=0.9763\n",
      "Epoch 16: Train_cls_acc=0.9983, Train_tag_acc=0.9992, Val_cls_acc=0.6219, Val_tag_acc=0.9737\n",
      "Epoch 17: Train_cls_acc=0.9998, Train_tag_acc=0.9999, Val_cls_acc=0.6547, Val_tag_acc=0.9776\n",
      "Epoch 18: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6564, Val_tag_acc=0.9772\n",
      "Epoch 19: Train_cls_acc=0.9977, Train_tag_acc=0.9991, Val_cls_acc=0.6420, Val_tag_acc=0.9759\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3720,  Tagging Acc: 0.9731, Overall Acc:0.2288\n",
      "Overall Acc:0.2288, Params: (type_emb_dim: 32, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4771, Train_tag_acc=0.9491, Val_cls_acc=0.5041, Val_tag_acc=0.9567\n",
      "Epoch 2: Train_cls_acc=0.8825, Train_tag_acc=0.9763, Val_cls_acc=0.5592, Val_tag_acc=0.9652\n",
      "Epoch 3: Train_cls_acc=0.9623, Train_tag_acc=0.9863, Val_cls_acc=0.6155, Val_tag_acc=0.9694\n",
      "Epoch 4: Train_cls_acc=0.9823, Train_tag_acc=0.9919, Val_cls_acc=0.6370, Val_tag_acc=0.9723\n",
      "Epoch 5: Train_cls_acc=0.9882, Train_tag_acc=0.9949, Val_cls_acc=0.6388, Val_tag_acc=0.9742\n",
      "Epoch 6: Train_cls_acc=0.9913, Train_tag_acc=0.9968, Val_cls_acc=0.6395, Val_tag_acc=0.9710\n",
      "Epoch 7: Train_cls_acc=0.9940, Train_tag_acc=0.9981, Val_cls_acc=0.6541, Val_tag_acc=0.9726\n",
      "Epoch 8: Train_cls_acc=0.9971, Train_tag_acc=0.9992, Val_cls_acc=0.6568, Val_tag_acc=0.9743\n",
      "Epoch 9: Train_cls_acc=0.9973, Train_tag_acc=0.9993, Val_cls_acc=0.6499, Val_tag_acc=0.9733\n",
      "Epoch 10: Train_cls_acc=0.9963, Train_tag_acc=0.9992, Val_cls_acc=0.6743, Val_tag_acc=0.9763\n",
      "Epoch 11: Train_cls_acc=0.9979, Train_tag_acc=0.9995, Val_cls_acc=0.6578, Val_tag_acc=0.9742\n",
      "Epoch 12: Train_cls_acc=0.9985, Train_tag_acc=0.9997, Val_cls_acc=0.6643, Val_tag_acc=0.9766\n",
      "Epoch 13: Train_cls_acc=0.9996, Train_tag_acc=0.9999, Val_cls_acc=0.6718, Val_tag_acc=0.9746\n",
      "Epoch 14: Train_cls_acc=0.9980, Train_tag_acc=0.9992, Val_cls_acc=0.6505, Val_tag_acc=0.9747\n",
      "Epoch 15: Train_cls_acc=0.9988, Train_tag_acc=0.9997, Val_cls_acc=0.6635, Val_tag_acc=0.9748\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3762,  Tagging Acc: 0.9749, Overall Acc:0.2328\n",
      "Overall Acc:0.2328, Params: (type_emb_dim: 32, dtype_emb_dim:64)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4728, Train_tag_acc=0.9484, Val_cls_acc=0.5279, Val_tag_acc=0.9586\n",
      "Epoch 2: Train_cls_acc=0.8832, Train_tag_acc=0.9769, Val_cls_acc=0.5692, Val_tag_acc=0.9665\n",
      "Epoch 3: Train_cls_acc=0.9647, Train_tag_acc=0.9861, Val_cls_acc=0.5967, Val_tag_acc=0.9682\n",
      "Epoch 4: Train_cls_acc=0.9826, Train_tag_acc=0.9915, Val_cls_acc=0.6224, Val_tag_acc=0.9697\n",
      "Epoch 5: Train_cls_acc=0.9893, Train_tag_acc=0.9946, Val_cls_acc=0.6403, Val_tag_acc=0.9709\n",
      "Epoch 6: Train_cls_acc=0.9938, Train_tag_acc=0.9972, Val_cls_acc=0.6088, Val_tag_acc=0.9703\n",
      "Epoch 7: Train_cls_acc=0.9956, Train_tag_acc=0.9984, Val_cls_acc=0.6238, Val_tag_acc=0.9727\n",
      "Epoch 8: Train_cls_acc=0.9959, Train_tag_acc=0.9984, Val_cls_acc=0.6489, Val_tag_acc=0.9720\n",
      "Epoch 9: Train_cls_acc=0.9986, Train_tag_acc=0.9995, Val_cls_acc=0.6587, Val_tag_acc=0.9714\n",
      "Epoch 10: Train_cls_acc=0.9953, Train_tag_acc=0.9983, Val_cls_acc=0.6461, Val_tag_acc=0.9745\n",
      "Epoch 11: Train_cls_acc=0.9992, Train_tag_acc=0.9999, Val_cls_acc=0.6453, Val_tag_acc=0.9739\n",
      "Epoch 12: Train_cls_acc=0.9973, Train_tag_acc=0.9991, Val_cls_acc=0.6606, Val_tag_acc=0.9764\n",
      "Epoch 13: Train_cls_acc=0.9996, Train_tag_acc=1.0000, Val_cls_acc=0.6610, Val_tag_acc=0.9757\n",
      "Epoch 14: Train_cls_acc=0.9993, Train_tag_acc=0.9996, Val_cls_acc=0.6374, Val_tag_acc=0.9699\n",
      "Epoch 15: Train_cls_acc=0.9975, Train_tag_acc=0.9991, Val_cls_acc=0.6399, Val_tag_acc=0.9725\n",
      "Epoch 16: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6535, Val_tag_acc=0.9725\n",
      "Epoch 17: Train_cls_acc=0.9983, Train_tag_acc=0.9992, Val_cls_acc=0.6174, Val_tag_acc=0.9742\n",
      "Epoch 18: Train_cls_acc=1.0000, Train_tag_acc=1.0000, Val_cls_acc=0.6366, Val_tag_acc=0.9726\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3876,  Tagging Acc: 0.9731, Overall Acc:0.2561\n",
      "Overall Acc:0.2561, Params: (type_emb_dim: 50, dtype_emb_dim:8)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4818, Train_tag_acc=0.9489, Val_cls_acc=0.5842, Val_tag_acc=0.9534\n",
      "Epoch 2: Train_cls_acc=0.8922, Train_tag_acc=0.9781, Val_cls_acc=0.6048, Val_tag_acc=0.9598\n",
      "Epoch 3: Train_cls_acc=0.9684, Train_tag_acc=0.9876, Val_cls_acc=0.6232, Val_tag_acc=0.9643\n",
      "Epoch 4: Train_cls_acc=0.9820, Train_tag_acc=0.9921, Val_cls_acc=0.6053, Val_tag_acc=0.9686\n",
      "Epoch 5: Train_cls_acc=0.9893, Train_tag_acc=0.9954, Val_cls_acc=0.6351, Val_tag_acc=0.9687\n",
      "Epoch 6: Train_cls_acc=0.9927, Train_tag_acc=0.9973, Val_cls_acc=0.6453, Val_tag_acc=0.9706\n",
      "Epoch 7: Train_cls_acc=0.9948, Train_tag_acc=0.9984, Val_cls_acc=0.6297, Val_tag_acc=0.9698\n",
      "Epoch 8: Train_cls_acc=0.9963, Train_tag_acc=0.9990, Val_cls_acc=0.6437, Val_tag_acc=0.9733\n",
      "Epoch 9: Train_cls_acc=0.9980, Train_tag_acc=0.9995, Val_cls_acc=0.6439, Val_tag_acc=0.9727\n",
      "Epoch 10: Train_cls_acc=0.9968, Train_tag_acc=0.9990, Val_cls_acc=0.6384, Val_tag_acc=0.9730\n",
      "Epoch 11: Train_cls_acc=0.9989, Train_tag_acc=0.9999, Val_cls_acc=0.6422, Val_tag_acc=0.9733\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3737,  Tagging Acc: 0.9716, Overall Acc:0.2295\n",
      "Overall Acc:0.2295, Params: (type_emb_dim: 50, dtype_emb_dim:16)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4788, Train_tag_acc=0.9494, Val_cls_acc=0.5181, Val_tag_acc=0.9590\n",
      "Epoch 2: Train_cls_acc=0.8905, Train_tag_acc=0.9790, Val_cls_acc=0.5516, Val_tag_acc=0.9593\n",
      "Epoch 3: Train_cls_acc=0.9651, Train_tag_acc=0.9880, Val_cls_acc=0.6318, Val_tag_acc=0.9675\n",
      "Epoch 4: Train_cls_acc=0.9837, Train_tag_acc=0.9931, Val_cls_acc=0.6103, Val_tag_acc=0.9697\n",
      "Epoch 5: Train_cls_acc=0.9894, Train_tag_acc=0.9958, Val_cls_acc=0.6203, Val_tag_acc=0.9707\n",
      "Epoch 6: Train_cls_acc=0.9937, Train_tag_acc=0.9980, Val_cls_acc=0.6393, Val_tag_acc=0.9734\n",
      "Epoch 7: Train_cls_acc=0.9949, Train_tag_acc=0.9985, Val_cls_acc=0.6192, Val_tag_acc=0.9723\n",
      "Epoch 8: Train_cls_acc=0.9958, Train_tag_acc=0.9990, Val_cls_acc=0.6497, Val_tag_acc=0.9734\n",
      "Epoch 9: Train_cls_acc=0.9966, Train_tag_acc=0.9990, Val_cls_acc=0.6545, Val_tag_acc=0.9759\n",
      "Epoch 10: Train_cls_acc=0.9977, Train_tag_acc=0.9995, Val_cls_acc=0.6507, Val_tag_acc=0.9736\n",
      "Epoch 11: Train_cls_acc=0.9983, Train_tag_acc=0.9996, Val_cls_acc=0.6432, Val_tag_acc=0.9741\n",
      "Epoch 12: Train_cls_acc=0.9989, Train_tag_acc=0.9998, Val_cls_acc=0.6292, Val_tag_acc=0.9718\n",
      "Epoch 13: Train_cls_acc=0.9985, Train_tag_acc=0.9993, Val_cls_acc=0.6378, Val_tag_acc=0.9734\n",
      "Epoch 14: Train_cls_acc=0.9992, Train_tag_acc=0.9999, Val_cls_acc=0.6405, Val_tag_acc=0.9731\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4062,  Tagging Acc: 0.9723, Overall Acc:0.2538\n",
      "Overall Acc:0.2538, Params: (type_emb_dim: 50, dtype_emb_dim:32)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4804, Train_tag_acc=0.9506, Val_cls_acc=0.5011, Val_tag_acc=0.9623\n",
      "Epoch 2: Train_cls_acc=0.8966, Train_tag_acc=0.9786, Val_cls_acc=0.5568, Val_tag_acc=0.9652\n",
      "Epoch 3: Train_cls_acc=0.9691, Train_tag_acc=0.9879, Val_cls_acc=0.5464, Val_tag_acc=0.9696\n",
      "Epoch 4: Train_cls_acc=0.9816, Train_tag_acc=0.9927, Val_cls_acc=0.5362, Val_tag_acc=0.9613\n",
      "Epoch 5: Train_cls_acc=0.9875, Train_tag_acc=0.9941, Val_cls_acc=0.5936, Val_tag_acc=0.9708\n",
      "Epoch 6: Train_cls_acc=0.9922, Train_tag_acc=0.9971, Val_cls_acc=0.6370, Val_tag_acc=0.9716\n",
      "Epoch 7: Train_cls_acc=0.9947, Train_tag_acc=0.9985, Val_cls_acc=0.6282, Val_tag_acc=0.9726\n",
      "Epoch 8: Train_cls_acc=0.9967, Train_tag_acc=0.9991, Val_cls_acc=0.6053, Val_tag_acc=0.9734\n",
      "Epoch 9: Train_cls_acc=0.9972, Train_tag_acc=0.9993, Val_cls_acc=0.6320, Val_tag_acc=0.9717\n",
      "Epoch 10: Train_cls_acc=0.9971, Train_tag_acc=0.9989, Val_cls_acc=0.6436, Val_tag_acc=0.9739\n",
      "Epoch 11: Train_cls_acc=0.9997, Train_tag_acc=0.9999, Val_cls_acc=0.6365, Val_tag_acc=0.9736\n",
      "Epoch 12: Train_cls_acc=0.9976, Train_tag_acc=0.9992, Val_cls_acc=0.6249, Val_tag_acc=0.9717\n",
      "Epoch 13: Train_cls_acc=0.9991, Train_tag_acc=0.9997, Val_cls_acc=0.5963, Val_tag_acc=0.9717\n",
      "Epoch 14: Train_cls_acc=0.9997, Train_tag_acc=1.0000, Val_cls_acc=0.6190, Val_tag_acc=0.9749\n",
      "Epoch 15: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6186, Val_tag_acc=0.9758\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3797,  Tagging Acc: 0.9729, Overall Acc:0.2300\n",
      "Overall Acc:0.2300, Params: (type_emb_dim: 50, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4699, Train_tag_acc=0.9496, Val_cls_acc=0.5247, Val_tag_acc=0.9577\n",
      "Epoch 2: Train_cls_acc=0.8885, Train_tag_acc=0.9784, Val_cls_acc=0.5304, Val_tag_acc=0.9622\n",
      "Epoch 3: Train_cls_acc=0.9692, Train_tag_acc=0.9878, Val_cls_acc=0.5857, Val_tag_acc=0.9640\n",
      "Epoch 4: Train_cls_acc=0.9848, Train_tag_acc=0.9925, Val_cls_acc=0.6274, Val_tag_acc=0.9671\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9952, Val_cls_acc=0.6386, Val_tag_acc=0.9666\n",
      "Epoch 6: Train_cls_acc=0.9927, Train_tag_acc=0.9971, Val_cls_acc=0.6432, Val_tag_acc=0.9675\n",
      "Epoch 7: Train_cls_acc=0.9952, Train_tag_acc=0.9985, Val_cls_acc=0.6188, Val_tag_acc=0.9690\n",
      "Epoch 8: Train_cls_acc=0.9972, Train_tag_acc=0.9993, Val_cls_acc=0.6459, Val_tag_acc=0.9680\n",
      "Epoch 9: Train_cls_acc=0.9980, Train_tag_acc=0.9994, Val_cls_acc=0.6658, Val_tag_acc=0.9672\n",
      "Epoch 10: Train_cls_acc=0.9971, Train_tag_acc=0.9992, Val_cls_acc=0.6330, Val_tag_acc=0.9678\n",
      "Epoch 11: Train_cls_acc=0.9987, Train_tag_acc=0.9997, Val_cls_acc=0.6424, Val_tag_acc=0.9689\n",
      "Epoch 12: Train_cls_acc=0.9979, Train_tag_acc=0.9994, Val_cls_acc=0.6322, Val_tag_acc=0.9697\n",
      "Epoch 13: Train_cls_acc=0.9998, Train_tag_acc=1.0000, Val_cls_acc=0.6624, Val_tag_acc=0.9697\n",
      "Epoch 14: Train_cls_acc=0.9976, Train_tag_acc=0.9990, Val_cls_acc=0.6685, Val_tag_acc=0.9702\n",
      "Epoch 15: Train_cls_acc=0.9998, Train_tag_acc=0.9999, Val_cls_acc=0.6645, Val_tag_acc=0.9710\n",
      "Epoch 16: Train_cls_acc=0.9997, Train_tag_acc=0.9998, Val_cls_acc=0.6862, Val_tag_acc=0.9713\n",
      "Epoch 17: Train_cls_acc=0.9978, Train_tag_acc=0.9992, Val_cls_acc=0.6343, Val_tag_acc=0.9709\n",
      "Epoch 18: Train_cls_acc=0.9999, Train_tag_acc=1.0000, Val_cls_acc=0.6672, Val_tag_acc=0.9704\n",
      "Epoch 19: Train_cls_acc=0.9998, Train_tag_acc=0.9999, Val_cls_acc=0.6612, Val_tag_acc=0.9719\n",
      "Epoch 20: Train_cls_acc=1.0000, Train_tag_acc=1.0000, Val_cls_acc=0.6509, Val_tag_acc=0.9738\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3809,  Tagging Acc: 0.9764, Overall Acc:0.2417\n",
      "Overall Acc:0.2417, Params: (type_emb_dim: 50, dtype_emb_dim:64)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4822, Train_tag_acc=0.9477, Val_cls_acc=0.5573, Val_tag_acc=0.9597\n",
      "Epoch 2: Train_cls_acc=0.8961, Train_tag_acc=0.9778, Val_cls_acc=0.6082, Val_tag_acc=0.9621\n",
      "Epoch 3: Train_cls_acc=0.9682, Train_tag_acc=0.9873, Val_cls_acc=0.6411, Val_tag_acc=0.9685\n",
      "Epoch 4: Train_cls_acc=0.9834, Train_tag_acc=0.9924, Val_cls_acc=0.6247, Val_tag_acc=0.9695\n",
      "Epoch 5: Train_cls_acc=0.9880, Train_tag_acc=0.9954, Val_cls_acc=0.6384, Val_tag_acc=0.9694\n",
      "Epoch 6: Train_cls_acc=0.9920, Train_tag_acc=0.9967, Val_cls_acc=0.6437, Val_tag_acc=0.9732\n",
      "Epoch 7: Train_cls_acc=0.9952, Train_tag_acc=0.9983, Val_cls_acc=0.6518, Val_tag_acc=0.9741\n",
      "Epoch 8: Train_cls_acc=0.9975, Train_tag_acc=0.9990, Val_cls_acc=0.6580, Val_tag_acc=0.9752\n",
      "Epoch 9: Train_cls_acc=0.9977, Train_tag_acc=0.9995, Val_cls_acc=0.5929, Val_tag_acc=0.9707\n",
      "Epoch 10: Train_cls_acc=0.9968, Train_tag_acc=0.9987, Val_cls_acc=0.6703, Val_tag_acc=0.9735\n",
      "Epoch 11: Train_cls_acc=0.9982, Train_tag_acc=0.9995, Val_cls_acc=0.6507, Val_tag_acc=0.9754\n",
      "Epoch 12: Train_cls_acc=0.9994, Train_tag_acc=0.9998, Val_cls_acc=0.6649, Val_tag_acc=0.9756\n",
      "Epoch 13: Train_cls_acc=0.9984, Train_tag_acc=0.9994, Val_cls_acc=0.6516, Val_tag_acc=0.9730\n",
      "Epoch 14: Train_cls_acc=0.9998, Train_tag_acc=0.9999, Val_cls_acc=0.6599, Val_tag_acc=0.9730\n",
      "Epoch 15: Train_cls_acc=0.9976, Train_tag_acc=0.9991, Val_cls_acc=0.6534, Val_tag_acc=0.9739\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4047,  Tagging Acc: 0.9759, Overall Acc:0.2581\n",
      "Overall Acc:0.2581, Params: (type_emb_dim: 64, dtype_emb_dim:8)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4670, Train_tag_acc=0.9484, Val_cls_acc=0.5180, Val_tag_acc=0.9582\n",
      "Epoch 2: Train_cls_acc=0.8910, Train_tag_acc=0.9774, Val_cls_acc=0.5360, Val_tag_acc=0.9649\n",
      "Epoch 3: Train_cls_acc=0.9544, Train_tag_acc=0.9842, Val_cls_acc=0.5859, Val_tag_acc=0.9716\n",
      "Epoch 4: Train_cls_acc=0.9823, Train_tag_acc=0.9908, Val_cls_acc=0.5850, Val_tag_acc=0.9711\n",
      "Epoch 5: Train_cls_acc=0.9884, Train_tag_acc=0.9941, Val_cls_acc=0.6067, Val_tag_acc=0.9701\n",
      "Epoch 6: Train_cls_acc=0.9928, Train_tag_acc=0.9964, Val_cls_acc=0.6282, Val_tag_acc=0.9711\n",
      "Epoch 7: Train_cls_acc=0.9931, Train_tag_acc=0.9971, Val_cls_acc=0.6147, Val_tag_acc=0.9747\n",
      "Epoch 8: Train_cls_acc=0.9950, Train_tag_acc=0.9978, Val_cls_acc=0.6155, Val_tag_acc=0.9727\n",
      "Epoch 9: Train_cls_acc=0.9979, Train_tag_acc=0.9993, Val_cls_acc=0.6253, Val_tag_acc=0.9735\n",
      "Epoch 10: Train_cls_acc=0.9967, Train_tag_acc=0.9988, Val_cls_acc=0.5982, Val_tag_acc=0.9734\n",
      "Epoch 11: Train_cls_acc=0.9987, Train_tag_acc=0.9996, Val_cls_acc=0.6245, Val_tag_acc=0.9765\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3697,  Tagging Acc: 0.9718, Overall Acc:0.2144\n",
      "Overall Acc:0.2144, Params: (type_emb_dim: 64, dtype_emb_dim:16)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4831, Train_tag_acc=0.9492, Val_cls_acc=0.5014, Val_tag_acc=0.9564\n",
      "Epoch 2: Train_cls_acc=0.8912, Train_tag_acc=0.9768, Val_cls_acc=0.5794, Val_tag_acc=0.9639\n",
      "Epoch 3: Train_cls_acc=0.9657, Train_tag_acc=0.9870, Val_cls_acc=0.6290, Val_tag_acc=0.9655\n",
      "Epoch 4: Train_cls_acc=0.9830, Train_tag_acc=0.9918, Val_cls_acc=0.6023, Val_tag_acc=0.9672\n",
      "Epoch 5: Train_cls_acc=0.9896, Train_tag_acc=0.9955, Val_cls_acc=0.6226, Val_tag_acc=0.9683\n",
      "Epoch 6: Train_cls_acc=0.9933, Train_tag_acc=0.9973, Val_cls_acc=0.6011, Val_tag_acc=0.9708\n",
      "Epoch 7: Train_cls_acc=0.9959, Train_tag_acc=0.9985, Val_cls_acc=0.6443, Val_tag_acc=0.9724\n",
      "Epoch 8: Train_cls_acc=0.9972, Train_tag_acc=0.9992, Val_cls_acc=0.6457, Val_tag_acc=0.9712\n",
      "Epoch 9: Train_cls_acc=0.9972, Train_tag_acc=0.9992, Val_cls_acc=0.6213, Val_tag_acc=0.9692\n",
      "Epoch 10: Train_cls_acc=0.9987, Train_tag_acc=0.9998, Val_cls_acc=0.5946, Val_tag_acc=0.9704\n",
      "Epoch 11: Train_cls_acc=0.9963, Train_tag_acc=0.9989, Val_cls_acc=0.6023, Val_tag_acc=0.9723\n",
      "Epoch 12: Train_cls_acc=0.9995, Train_tag_acc=1.0000, Val_cls_acc=0.6315, Val_tag_acc=0.9755\n",
      "Epoch 13: Train_cls_acc=0.9996, Train_tag_acc=0.9999, Val_cls_acc=0.6199, Val_tag_acc=0.9694\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3988,  Tagging Acc: 0.9711, Overall Acc:0.2464\n",
      "Overall Acc:0.2464, Params: (type_emb_dim: 64, dtype_emb_dim:32)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.5054, Train_tag_acc=0.9515, Val_cls_acc=0.5191, Val_tag_acc=0.9634\n",
      "Epoch 2: Train_cls_acc=0.8983, Train_tag_acc=0.9797, Val_cls_acc=0.5819, Val_tag_acc=0.9654\n",
      "Epoch 3: Train_cls_acc=0.9645, Train_tag_acc=0.9880, Val_cls_acc=0.6203, Val_tag_acc=0.9685\n",
      "Epoch 4: Train_cls_acc=0.9832, Train_tag_acc=0.9929, Val_cls_acc=0.6397, Val_tag_acc=0.9727\n",
      "Epoch 5: Train_cls_acc=0.9883, Train_tag_acc=0.9954, Val_cls_acc=0.6474, Val_tag_acc=0.9728\n",
      "Epoch 6: Train_cls_acc=0.9919, Train_tag_acc=0.9976, Val_cls_acc=0.6486, Val_tag_acc=0.9723\n",
      "Epoch 7: Train_cls_acc=0.9944, Train_tag_acc=0.9986, Val_cls_acc=0.6457, Val_tag_acc=0.9731\n",
      "Epoch 8: Train_cls_acc=0.9956, Train_tag_acc=0.9991, Val_cls_acc=0.6253, Val_tag_acc=0.9722\n",
      "Epoch 9: Train_cls_acc=0.9965, Train_tag_acc=0.9992, Val_cls_acc=0.6455, Val_tag_acc=0.9761\n",
      "Epoch 10: Train_cls_acc=0.9982, Train_tag_acc=0.9994, Val_cls_acc=0.6603, Val_tag_acc=0.9748\n",
      "Epoch 11: Train_cls_acc=0.9978, Train_tag_acc=0.9994, Val_cls_acc=0.6564, Val_tag_acc=0.9726\n",
      "Epoch 12: Train_cls_acc=0.9988, Train_tag_acc=0.9997, Val_cls_acc=0.6578, Val_tag_acc=0.9743\n",
      "Epoch 13: Train_cls_acc=0.9997, Train_tag_acc=0.9999, Val_cls_acc=0.6881, Val_tag_acc=0.9727\n",
      "Epoch 14: Train_cls_acc=0.9993, Train_tag_acc=0.9996, Val_cls_acc=0.6795, Val_tag_acc=0.9748\n",
      "Epoch 15: Train_cls_acc=0.9986, Train_tag_acc=0.9996, Val_cls_acc=0.6676, Val_tag_acc=0.9748\n",
      "Epoch 16: Train_cls_acc=0.9993, Train_tag_acc=0.9997, Val_cls_acc=0.6618, Val_tag_acc=0.9727\n",
      "Epoch 17: Train_cls_acc=0.9998, Train_tag_acc=1.0000, Val_cls_acc=0.6751, Val_tag_acc=0.9751\n",
      "Epoch 18: Train_cls_acc=0.9991, Train_tag_acc=0.9996, Val_cls_acc=0.6783, Val_tag_acc=0.9730\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.4228,  Tagging Acc: 0.9767, Overall Acc:0.2717\n",
      "Overall Acc:0.2717, Params: (type_emb_dim: 64, dtype_emb_dim:50)\n",
      "Initialize lstm model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.4847, Train_tag_acc=0.9516, Val_cls_acc=0.5210, Val_tag_acc=0.9587\n",
      "Epoch 2: Train_cls_acc=0.8966, Train_tag_acc=0.9800, Val_cls_acc=0.5790, Val_tag_acc=0.9687\n",
      "Epoch 3: Train_cls_acc=0.9668, Train_tag_acc=0.9882, Val_cls_acc=0.5802, Val_tag_acc=0.9706\n",
      "Epoch 4: Train_cls_acc=0.9834, Train_tag_acc=0.9928, Val_cls_acc=0.5990, Val_tag_acc=0.9743\n",
      "Epoch 5: Train_cls_acc=0.9903, Train_tag_acc=0.9956, Val_cls_acc=0.6046, Val_tag_acc=0.9713\n",
      "Epoch 6: Train_cls_acc=0.9928, Train_tag_acc=0.9972, Val_cls_acc=0.5994, Val_tag_acc=0.9766\n",
      "Epoch 7: Train_cls_acc=0.9953, Train_tag_acc=0.9983, Val_cls_acc=0.6268, Val_tag_acc=0.9712\n",
      "Epoch 8: Train_cls_acc=0.9968, Train_tag_acc=0.9990, Val_cls_acc=0.6307, Val_tag_acc=0.9742\n",
      "Epoch 9: Train_cls_acc=0.9974, Train_tag_acc=0.9992, Val_cls_acc=0.6090, Val_tag_acc=0.9746\n",
      "Epoch 10: Train_cls_acc=0.9978, Train_tag_acc=0.9994, Val_cls_acc=0.6288, Val_tag_acc=0.9745\n",
      "Epoch 11: Train_cls_acc=0.9974, Train_tag_acc=0.9992, Val_cls_acc=0.5842, Val_tag_acc=0.9705\n",
      "Epoch 12: Train_cls_acc=0.9992, Train_tag_acc=0.9998, Val_cls_acc=0.6307, Val_tag_acc=0.9752\n",
      "Epoch 13: Train_cls_acc=0.9996, Train_tag_acc=1.0000, Val_cls_acc=0.6109, Val_tag_acc=0.9754\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set lstm —  Classification Acc: 0.3625,  Tagging Acc: 0.9768, Overall Acc:0.2290\n",
      "Overall Acc:0.2290, Params: (type_emb_dim: 64, dtype_emb_dim:64)\n",
      "Best accuracy of lstm - Acc: 0.27965260545905707, params: (type_emb_dim: 8, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "embed_dim must be divisible by num_heads",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim1 \u001b[38;5;129;01min\u001b[39;00m test_type_emb_dim:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dim2 \u001b[38;5;129;01min\u001b[39;00m test_dtype_emb_dim:\n\u001b[1;32m---> 14\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mClassificationModels\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtype_vocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdtype_vocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtype_emb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_emb_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtemplate_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mtag_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname2idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m===============Training Model=================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m         train_model(processor, model, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 39\u001b[0m, in \u001b[0;36mClassificationModels.__init__\u001b[1;34m(self, embedding_matrix, type_vocab_size, dtype_vocab_size, type_emb_dim, dtype_emb_dim, model_type, hidden_dim, template_classes, tag_classes, num_layers, nhead)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_tag \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(hidden_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, tag_classes)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 39\u001b[0m     encoder_layer \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformerEncoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnhead\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnhead\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformerEncoder(encoder_layer, num_layers\u001b[38;5;241m=\u001b[39mnum_layers)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_cls \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(input_dim, template_classes)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLPCodingTest\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:589\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.__init__\u001b[1;34m(self, d_model, nhead, dim_feedforward, dropout, activation, layer_norm_eps, batch_first, norm_first, bias, device, dtype)\u001b[0m\n\u001b[0;32m    587\u001b[0m factory_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m: device, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m: dtype}\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m MultiheadAttention(d_model, nhead, dropout\u001b[38;5;241m=\u001b[39mdropout,\n\u001b[0;32m    590\u001b[0m                                     bias\u001b[38;5;241m=\u001b[39mbias, batch_first\u001b[38;5;241m=\u001b[39mbatch_first,\n\u001b[0;32m    591\u001b[0m                                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;66;03m# Implementation of Feedforward model\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m Linear(d_model, dim_feedforward, bias\u001b[38;5;241m=\u001b[39mbias, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NLPCodingTest\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1011\u001b[0m, in \u001b[0;36mMultiheadAttention.__init__\u001b[1;34m(self, embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first, device, dtype)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;241m=\u001b[39m batch_first\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m=\u001b[39m embed_dim \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_heads\n\u001b[1;32m-> 1011\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim \u001b[38;5;241m*\u001b[39m num_heads \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membed_dim must be divisible by num_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qkv_same_embed_dim:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((embed_dim, embed_dim), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mAssertionError\u001b[0m: embed_dim must be divisible by num_heads"
     ]
    }
   ],
   "source": [
    "# Note: we use the following hyperparameter tuning method to explore our experiment\n",
    "# We manually setting different dimensions of additional information embedding to observe how these dimensions impact each models performance\n",
    "# And propose the hypothesis why such dimensions can get the best accuracy\n",
    "test_type_emb_dim = [8, 16, 32, 50, 64]\n",
    "test_dtype_emb_dim = [8, 16, 32, 50, 64]\n",
    "optimal_params = []\n",
    "\n",
    "processor = atisDataProcessor(data_file, type_file, glove_path)\n",
    "model_set = [\"linear\", \"feedforward\", \"lstm\"]\n",
    "for model_type in model_set:\n",
    "    acc_list = []\n",
    "    params = []\n",
    "    for dim1 in test_type_emb_dim:\n",
    "        for dim2 in test_dtype_emb_dim:\n",
    "            model = ClassificationModels(embedding_matrix=processor.embedding_matrix,\n",
    "                               type_vocab_size=len(processor.var2idx),\n",
    "                               dtype_vocab_size=len(processor.dtype2idx),\n",
    "                               type_emb_dim=dim1, dtype_emb_dim=dim2,\n",
    "                               model_type=model_type,\n",
    "                               hidden_dim=128,\n",
    "                               template_classes=processor.template_classes,\n",
    "                               tag_classes=len(processor.name2idx),\n",
    "                               num_layers=1, nhead=5)\n",
    "            print(f\"===============Training Model=================\")\n",
    "            train_model(processor, model, epochs=20, lr=1e-3, patience=5)\n",
    "            print(f\"===============Testing Model=================\")\n",
    "            acc_cls, acc_tag, acc_strict = evaluate_model(processor, model)\n",
    "            print(f\"Test set {model_type} —  Classification Acc: {acc_cls:.4f},  Tagging Acc: {acc_tag:.4f}, Overall Acc:{acc_strict:.4f}\")\n",
    "            print(f\"Overall Acc:{acc_strict:.4f}, Params: (type_emb_dim: {dim1}, dtype_emb_dim:{dim2})\")\n",
    "            acc_list.append(acc_strict)\n",
    "            params.append([dim1, dim2])\n",
    "\n",
    "    best_acc = max(acc_list)\n",
    "    best_params = params[acc_list.index(best_acc)]\n",
    "    print(f\"Best accuracy of {model_type} - Acc: {best_acc}, params: (type_emb_dim: {best_params[0]}, dtype_emb_dim:{best_params[1]})\")\n",
    "    optimal_params.append({\"model_type\": model_type, \"type_dim\": best_params[0], \"dtype_param\": best_params[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c66cc1f1-c704-4a57-a936-4a48b6346a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datatype of variables for additional information on learning...\n",
      "Loading all data in json...\n",
      "Loading sql template...\n",
      "944\n",
      "processing samples...\n",
      "length of training set: 46419\n",
      "length of training set: 5207\n",
      "length of training set: 4030\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.5844, Train_tag_acc=0.9155, Val_cls_acc=0.6503, Val_tag_acc=0.9206\n",
      "Epoch 2: Train_cls_acc=0.9405, Train_tag_acc=0.9310, Val_cls_acc=0.6666, Val_tag_acc=0.9291\n",
      "Epoch 3: Train_cls_acc=0.9806, Train_tag_acc=0.9429, Val_cls_acc=0.6944, Val_tag_acc=0.9318\n",
      "Epoch 4: Train_cls_acc=0.9859, Train_tag_acc=0.9533, Val_cls_acc=0.6724, Val_tag_acc=0.9377\n",
      "Epoch 5: Train_cls_acc=0.9928, Train_tag_acc=0.9627, Val_cls_acc=0.6712, Val_tag_acc=0.9388\n",
      "Epoch 6: Train_cls_acc=0.9920, Train_tag_acc=0.9696, Val_cls_acc=0.6712, Val_tag_acc=0.9422\n",
      "Epoch 7: Train_cls_acc=0.9944, Train_tag_acc=0.9747, Val_cls_acc=0.6562, Val_tag_acc=0.9440\n",
      "Epoch 8: Train_cls_acc=0.9951, Train_tag_acc=0.9782, Val_cls_acc=0.6482, Val_tag_acc=0.9413\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4496,  Tagging Acc: 0.9206, Overall Acc:0.2179\n",
      "Overall Acc:0.2179, Params: (type_emb_dim: 5, dtype_emb_dim:5)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6071, Train_tag_acc=0.9143, Val_cls_acc=0.6478, Val_tag_acc=0.9195\n",
      "Epoch 2: Train_cls_acc=0.9461, Train_tag_acc=0.9283, Val_cls_acc=0.6635, Val_tag_acc=0.9289\n",
      "Epoch 3: Train_cls_acc=0.9813, Train_tag_acc=0.9411, Val_cls_acc=0.6822, Val_tag_acc=0.9344\n",
      "Epoch 4: Train_cls_acc=0.9878, Train_tag_acc=0.9522, Val_cls_acc=0.6731, Val_tag_acc=0.9361\n",
      "Epoch 5: Train_cls_acc=0.9913, Train_tag_acc=0.9615, Val_cls_acc=0.6689, Val_tag_acc=0.9421\n",
      "Epoch 6: Train_cls_acc=0.9914, Train_tag_acc=0.9686, Val_cls_acc=0.6597, Val_tag_acc=0.9439\n",
      "Epoch 7: Train_cls_acc=0.9957, Train_tag_acc=0.9742, Val_cls_acc=0.6781, Val_tag_acc=0.9457\n",
      "Epoch 8: Train_cls_acc=0.9943, Train_tag_acc=0.9773, Val_cls_acc=0.6681, Val_tag_acc=0.9459\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4181,  Tagging Acc: 0.9204, Overall Acc:0.1715\n",
      "Overall Acc:0.1715, Params: (type_emb_dim: 5, dtype_emb_dim:10)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6319, Train_tag_acc=0.9150, Val_cls_acc=0.6772, Val_tag_acc=0.9232\n",
      "Epoch 2: Train_cls_acc=0.9522, Train_tag_acc=0.9304, Val_cls_acc=0.6716, Val_tag_acc=0.9282\n",
      "Epoch 3: Train_cls_acc=0.9808, Train_tag_acc=0.9435, Val_cls_acc=0.6923, Val_tag_acc=0.9349\n",
      "Epoch 4: Train_cls_acc=0.9858, Train_tag_acc=0.9552, Val_cls_acc=0.6752, Val_tag_acc=0.9361\n",
      "Epoch 5: Train_cls_acc=0.9915, Train_tag_acc=0.9644, Val_cls_acc=0.6923, Val_tag_acc=0.9390\n",
      "Epoch 6: Train_cls_acc=0.9919, Train_tag_acc=0.9710, Val_cls_acc=0.6722, Val_tag_acc=0.9412\n",
      "Epoch 7: Train_cls_acc=0.9943, Train_tag_acc=0.9756, Val_cls_acc=0.6691, Val_tag_acc=0.9399\n",
      "Epoch 8: Train_cls_acc=0.9927, Train_tag_acc=0.9781, Val_cls_acc=0.6660, Val_tag_acc=0.9426\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4514,  Tagging Acc: 0.9222, Overall Acc:0.1945\n",
      "Overall Acc:0.1945, Params: (type_emb_dim: 5, dtype_emb_dim:25)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6559, Train_tag_acc=0.9138, Val_cls_acc=0.6779, Val_tag_acc=0.9220\n",
      "Epoch 2: Train_cls_acc=0.9548, Train_tag_acc=0.9261, Val_cls_acc=0.6829, Val_tag_acc=0.9253\n",
      "Epoch 3: Train_cls_acc=0.9759, Train_tag_acc=0.9374, Val_cls_acc=0.6806, Val_tag_acc=0.9292\n",
      "Epoch 4: Train_cls_acc=0.9844, Train_tag_acc=0.9480, Val_cls_acc=0.6608, Val_tag_acc=0.9385\n",
      "Epoch 5: Train_cls_acc=0.9887, Train_tag_acc=0.9582, Val_cls_acc=0.6758, Val_tag_acc=0.9442\n",
      "Epoch 6: Train_cls_acc=0.9912, Train_tag_acc=0.9661, Val_cls_acc=0.6956, Val_tag_acc=0.9478\n",
      "Epoch 7: Train_cls_acc=0.9920, Train_tag_acc=0.9723, Val_cls_acc=0.6854, Val_tag_acc=0.9440\n",
      "Epoch 8: Train_cls_acc=0.9960, Train_tag_acc=0.9778, Val_cls_acc=0.6860, Val_tag_acc=0.9484\n",
      "Epoch 9: Train_cls_acc=0.9911, Train_tag_acc=0.9794, Val_cls_acc=0.6835, Val_tag_acc=0.9460\n",
      "Epoch 10: Train_cls_acc=0.9957, Train_tag_acc=0.9825, Val_cls_acc=0.6649, Val_tag_acc=0.9461\n",
      "Epoch 11: Train_cls_acc=0.9956, Train_tag_acc=0.9840, Val_cls_acc=0.6524, Val_tag_acc=0.9431\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4583,  Tagging Acc: 0.9304, Overall Acc:0.2164\n",
      "Overall Acc:0.2164, Params: (type_emb_dim: 5, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6727, Train_tag_acc=0.9139, Val_cls_acc=0.6422, Val_tag_acc=0.9226\n",
      "Epoch 2: Train_cls_acc=0.9571, Train_tag_acc=0.9239, Val_cls_acc=0.7021, Val_tag_acc=0.9264\n",
      "Epoch 3: Train_cls_acc=0.9759, Train_tag_acc=0.9343, Val_cls_acc=0.6887, Val_tag_acc=0.9352\n",
      "Epoch 4: Train_cls_acc=0.9866, Train_tag_acc=0.9455, Val_cls_acc=0.6768, Val_tag_acc=0.9409\n",
      "Epoch 5: Train_cls_acc=0.9878, Train_tag_acc=0.9558, Val_cls_acc=0.6681, Val_tag_acc=0.9366\n",
      "Epoch 6: Train_cls_acc=0.9882, Train_tag_acc=0.9640, Val_cls_acc=0.6921, Val_tag_acc=0.9399\n",
      "Epoch 7: Train_cls_acc=0.9928, Train_tag_acc=0.9711, Val_cls_acc=0.6378, Val_tag_acc=0.9391\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4392,  Tagging Acc: 0.9218, Overall Acc:0.1829\n",
      "Overall Acc:0.1829, Params: (type_emb_dim: 5, dtype_emb_dim:75)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6191, Train_tag_acc=0.9171, Val_cls_acc=0.6226, Val_tag_acc=0.9248\n",
      "Epoch 2: Train_cls_acc=0.9481, Train_tag_acc=0.9329, Val_cls_acc=0.6532, Val_tag_acc=0.9306\n",
      "Epoch 3: Train_cls_acc=0.9806, Train_tag_acc=0.9443, Val_cls_acc=0.6647, Val_tag_acc=0.9352\n",
      "Epoch 4: Train_cls_acc=0.9871, Train_tag_acc=0.9557, Val_cls_acc=0.6758, Val_tag_acc=0.9354\n",
      "Epoch 5: Train_cls_acc=0.9908, Train_tag_acc=0.9645, Val_cls_acc=0.6551, Val_tag_acc=0.9402\n",
      "Epoch 6: Train_cls_acc=0.9941, Train_tag_acc=0.9713, Val_cls_acc=0.6839, Val_tag_acc=0.9432\n",
      "Epoch 7: Train_cls_acc=0.9915, Train_tag_acc=0.9746, Val_cls_acc=0.6630, Val_tag_acc=0.9411\n",
      "Epoch 8: Train_cls_acc=0.9974, Train_tag_acc=0.9800, Val_cls_acc=0.6555, Val_tag_acc=0.9441\n",
      "Epoch 9: Train_cls_acc=0.9937, Train_tag_acc=0.9813, Val_cls_acc=0.6582, Val_tag_acc=0.9412\n",
      "Epoch 10: Train_cls_acc=0.9950, Train_tag_acc=0.9837, Val_cls_acc=0.6357, Val_tag_acc=0.9432\n",
      "Epoch 11: Train_cls_acc=0.9985, Train_tag_acc=0.9859, Val_cls_acc=0.6403, Val_tag_acc=0.9417\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4655,  Tagging Acc: 0.9163, Overall Acc:0.1779\n",
      "Overall Acc:0.1779, Params: (type_emb_dim: 10, dtype_emb_dim:5)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6281, Train_tag_acc=0.9161, Val_cls_acc=0.6338, Val_tag_acc=0.9242\n",
      "Epoch 2: Train_cls_acc=0.9505, Train_tag_acc=0.9312, Val_cls_acc=0.6812, Val_tag_acc=0.9321\n",
      "Epoch 3: Train_cls_acc=0.9807, Train_tag_acc=0.9441, Val_cls_acc=0.6791, Val_tag_acc=0.9382\n",
      "Epoch 4: Train_cls_acc=0.9870, Train_tag_acc=0.9551, Val_cls_acc=0.6762, Val_tag_acc=0.9400\n",
      "Epoch 5: Train_cls_acc=0.9893, Train_tag_acc=0.9643, Val_cls_acc=0.6927, Val_tag_acc=0.9399\n",
      "Epoch 6: Train_cls_acc=0.9935, Train_tag_acc=0.9712, Val_cls_acc=0.6612, Val_tag_acc=0.9385\n",
      "Epoch 7: Train_cls_acc=0.9940, Train_tag_acc=0.9755, Val_cls_acc=0.6783, Val_tag_acc=0.9432\n",
      "Epoch 8: Train_cls_acc=0.9933, Train_tag_acc=0.9785, Val_cls_acc=0.6635, Val_tag_acc=0.9438\n",
      "Epoch 9: Train_cls_acc=0.9956, Train_tag_acc=0.9819, Val_cls_acc=0.6562, Val_tag_acc=0.9442\n",
      "Epoch 10: Train_cls_acc=0.9949, Train_tag_acc=0.9836, Val_cls_acc=0.6653, Val_tag_acc=0.9453\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4677,  Tagging Acc: 0.9284, Overall Acc:0.2248\n",
      "Overall Acc:0.2248, Params: (type_emb_dim: 10, dtype_emb_dim:10)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6426, Train_tag_acc=0.9154, Val_cls_acc=0.6610, Val_tag_acc=0.9231\n",
      "Epoch 2: Train_cls_acc=0.9515, Train_tag_acc=0.9262, Val_cls_acc=0.6829, Val_tag_acc=0.9263\n",
      "Epoch 3: Train_cls_acc=0.9788, Train_tag_acc=0.9376, Val_cls_acc=0.7042, Val_tag_acc=0.9340\n",
      "Epoch 4: Train_cls_acc=0.9856, Train_tag_acc=0.9494, Val_cls_acc=0.6873, Val_tag_acc=0.9368\n",
      "Epoch 5: Train_cls_acc=0.9896, Train_tag_acc=0.9604, Val_cls_acc=0.6758, Val_tag_acc=0.9385\n",
      "Epoch 6: Train_cls_acc=0.9917, Train_tag_acc=0.9679, Val_cls_acc=0.6703, Val_tag_acc=0.9433\n",
      "Epoch 7: Train_cls_acc=0.9916, Train_tag_acc=0.9729, Val_cls_acc=0.6606, Val_tag_acc=0.9471\n",
      "Epoch 8: Train_cls_acc=0.9956, Train_tag_acc=0.9778, Val_cls_acc=0.6557, Val_tag_acc=0.9463\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4854,  Tagging Acc: 0.9214, Overall Acc:0.2308\n",
      "Overall Acc:0.2308, Params: (type_emb_dim: 10, dtype_emb_dim:25)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6708, Train_tag_acc=0.9157, Val_cls_acc=0.6637, Val_tag_acc=0.9216\n",
      "Epoch 2: Train_cls_acc=0.9578, Train_tag_acc=0.9280, Val_cls_acc=0.6781, Val_tag_acc=0.9306\n",
      "Epoch 3: Train_cls_acc=0.9798, Train_tag_acc=0.9399, Val_cls_acc=0.6701, Val_tag_acc=0.9387\n",
      "Epoch 4: Train_cls_acc=0.9849, Train_tag_acc=0.9512, Val_cls_acc=0.6681, Val_tag_acc=0.9397\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9611, Val_cls_acc=0.6603, Val_tag_acc=0.9423\n",
      "Epoch 6: Train_cls_acc=0.9907, Train_tag_acc=0.9687, Val_cls_acc=0.6587, Val_tag_acc=0.9420\n",
      "Epoch 7: Train_cls_acc=0.9946, Train_tag_acc=0.9744, Val_cls_acc=0.6678, Val_tag_acc=0.9425\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4404,  Tagging Acc: 0.9239, Overall Acc:0.2079\n",
      "Overall Acc:0.2079, Params: (type_emb_dim: 10, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6852, Train_tag_acc=0.9153, Val_cls_acc=0.6916, Val_tag_acc=0.9213\n",
      "Epoch 2: Train_cls_acc=0.9563, Train_tag_acc=0.9251, Val_cls_acc=0.6670, Val_tag_acc=0.9234\n",
      "Epoch 3: Train_cls_acc=0.9778, Train_tag_acc=0.9339, Val_cls_acc=0.6833, Val_tag_acc=0.9343\n",
      "Epoch 4: Train_cls_acc=0.9814, Train_tag_acc=0.9431, Val_cls_acc=0.6739, Val_tag_acc=0.9368\n",
      "Epoch 5: Train_cls_acc=0.9895, Train_tag_acc=0.9532, Val_cls_acc=0.6799, Val_tag_acc=0.9396\n",
      "Epoch 6: Train_cls_acc=0.9891, Train_tag_acc=0.9612, Val_cls_acc=0.6845, Val_tag_acc=0.9403\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4739,  Tagging Acc: 0.9159, Overall Acc:0.1787\n",
      "Overall Acc:0.1787, Params: (type_emb_dim: 10, dtype_emb_dim:75)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6393, Train_tag_acc=0.9148, Val_cls_acc=0.6420, Val_tag_acc=0.9248\n",
      "Epoch 2: Train_cls_acc=0.9538, Train_tag_acc=0.9272, Val_cls_acc=0.6626, Val_tag_acc=0.9253\n",
      "Epoch 3: Train_cls_acc=0.9796, Train_tag_acc=0.9387, Val_cls_acc=0.6822, Val_tag_acc=0.9360\n",
      "Epoch 4: Train_cls_acc=0.9860, Train_tag_acc=0.9499, Val_cls_acc=0.6651, Val_tag_acc=0.9330\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9597, Val_cls_acc=0.6672, Val_tag_acc=0.9405\n",
      "Epoch 6: Train_cls_acc=0.9924, Train_tag_acc=0.9676, Val_cls_acc=0.6409, Val_tag_acc=0.9393\n",
      "Epoch 7: Train_cls_acc=0.9942, Train_tag_acc=0.9731, Val_cls_acc=0.6630, Val_tag_acc=0.9428\n",
      "Epoch 8: Train_cls_acc=0.9947, Train_tag_acc=0.9771, Val_cls_acc=0.6622, Val_tag_acc=0.9436\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4898,  Tagging Acc: 0.9251, Overall Acc:0.2328\n",
      "Overall Acc:0.2328, Params: (type_emb_dim: 25, dtype_emb_dim:5)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6390, Train_tag_acc=0.9154, Val_cls_acc=0.6413, Val_tag_acc=0.9216\n",
      "Epoch 2: Train_cls_acc=0.9533, Train_tag_acc=0.9278, Val_cls_acc=0.6676, Val_tag_acc=0.9290\n",
      "Epoch 3: Train_cls_acc=0.9799, Train_tag_acc=0.9391, Val_cls_acc=0.6868, Val_tag_acc=0.9322\n",
      "Epoch 4: Train_cls_acc=0.9881, Train_tag_acc=0.9514, Val_cls_acc=0.6802, Val_tag_acc=0.9367\n",
      "Epoch 5: Train_cls_acc=0.9881, Train_tag_acc=0.9612, Val_cls_acc=0.6558, Val_tag_acc=0.9398\n",
      "Epoch 6: Train_cls_acc=0.9946, Train_tag_acc=0.9700, Val_cls_acc=0.6683, Val_tag_acc=0.9408\n",
      "Epoch 7: Train_cls_acc=0.9927, Train_tag_acc=0.9747, Val_cls_acc=0.6645, Val_tag_acc=0.9418\n",
      "Epoch 8: Train_cls_acc=0.9964, Train_tag_acc=0.9801, Val_cls_acc=0.6211, Val_tag_acc=0.9412\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4171,  Tagging Acc: 0.9244, Overall Acc:0.1945\n",
      "Overall Acc:0.1945, Params: (type_emb_dim: 25, dtype_emb_dim:10)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6609, Train_tag_acc=0.9157, Val_cls_acc=0.7012, Val_tag_acc=0.9231\n",
      "Epoch 2: Train_cls_acc=0.9575, Train_tag_acc=0.9279, Val_cls_acc=0.7110, Val_tag_acc=0.9329\n",
      "Epoch 3: Train_cls_acc=0.9804, Train_tag_acc=0.9396, Val_cls_acc=0.6948, Val_tag_acc=0.9381\n",
      "Epoch 4: Train_cls_acc=0.9853, Train_tag_acc=0.9502, Val_cls_acc=0.7000, Val_tag_acc=0.9357\n",
      "Epoch 5: Train_cls_acc=0.9893, Train_tag_acc=0.9600, Val_cls_acc=0.6676, Val_tag_acc=0.9427\n",
      "Epoch 6: Train_cls_acc=0.9920, Train_tag_acc=0.9678, Val_cls_acc=0.6683, Val_tag_acc=0.9423\n",
      "Epoch 7: Train_cls_acc=0.9934, Train_tag_acc=0.9736, Val_cls_acc=0.6716, Val_tag_acc=0.9424\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4680,  Tagging Acc: 0.9192, Overall Acc:0.2030\n",
      "Overall Acc:0.2030, Params: (type_emb_dim: 25, dtype_emb_dim:25)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6755, Train_tag_acc=0.9152, Val_cls_acc=0.6925, Val_tag_acc=0.9220\n",
      "Epoch 2: Train_cls_acc=0.9534, Train_tag_acc=0.9242, Val_cls_acc=0.6958, Val_tag_acc=0.9222\n",
      "Epoch 3: Train_cls_acc=0.9774, Train_tag_acc=0.9342, Val_cls_acc=0.6900, Val_tag_acc=0.9317\n",
      "Epoch 4: Train_cls_acc=0.9857, Train_tag_acc=0.9452, Val_cls_acc=0.6593, Val_tag_acc=0.9374\n",
      "Epoch 5: Train_cls_acc=0.9887, Train_tag_acc=0.9550, Val_cls_acc=0.6697, Val_tag_acc=0.9371\n",
      "Epoch 6: Train_cls_acc=0.9914, Train_tag_acc=0.9641, Val_cls_acc=0.6762, Val_tag_acc=0.9413\n",
      "Epoch 7: Train_cls_acc=0.9908, Train_tag_acc=0.9701, Val_cls_acc=0.6749, Val_tag_acc=0.9424\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4779,  Tagging Acc: 0.9260, Overall Acc:0.1888\n",
      "Overall Acc:0.1888, Params: (type_emb_dim: 25, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6911, Train_tag_acc=0.9148, Val_cls_acc=0.6512, Val_tag_acc=0.9197\n",
      "Epoch 2: Train_cls_acc=0.9543, Train_tag_acc=0.9245, Val_cls_acc=0.6806, Val_tag_acc=0.9220\n",
      "Epoch 3: Train_cls_acc=0.9758, Train_tag_acc=0.9338, Val_cls_acc=0.6833, Val_tag_acc=0.9308\n",
      "Epoch 4: Train_cls_acc=0.9811, Train_tag_acc=0.9434, Val_cls_acc=0.6631, Val_tag_acc=0.9336\n",
      "Epoch 5: Train_cls_acc=0.9844, Train_tag_acc=0.9524, Val_cls_acc=0.6852, Val_tag_acc=0.9391\n",
      "Epoch 6: Train_cls_acc=0.9911, Train_tag_acc=0.9610, Val_cls_acc=0.6699, Val_tag_acc=0.9395\n",
      "Epoch 7: Train_cls_acc=0.9896, Train_tag_acc=0.9669, Val_cls_acc=0.6731, Val_tag_acc=0.9436\n",
      "Epoch 8: Train_cls_acc=0.9939, Train_tag_acc=0.9732, Val_cls_acc=0.6799, Val_tag_acc=0.9430\n",
      "Epoch 9: Train_cls_acc=0.9930, Train_tag_acc=0.9761, Val_cls_acc=0.6843, Val_tag_acc=0.9442\n",
      "Epoch 10: Train_cls_acc=0.9946, Train_tag_acc=0.9796, Val_cls_acc=0.6704, Val_tag_acc=0.9407\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4256,  Tagging Acc: 0.9269, Overall Acc:0.1754\n",
      "Overall Acc:0.1754, Params: (type_emb_dim: 25, dtype_emb_dim:75)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6592, Train_tag_acc=0.9150, Val_cls_acc=0.6543, Val_tag_acc=0.9203\n",
      "Epoch 2: Train_cls_acc=0.9524, Train_tag_acc=0.9256, Val_cls_acc=0.6927, Val_tag_acc=0.9264\n",
      "Epoch 3: Train_cls_acc=0.9794, Train_tag_acc=0.9370, Val_cls_acc=0.7042, Val_tag_acc=0.9362\n",
      "Epoch 4: Train_cls_acc=0.9826, Train_tag_acc=0.9464, Val_cls_acc=0.6727, Val_tag_acc=0.9388\n",
      "Epoch 5: Train_cls_acc=0.9888, Train_tag_acc=0.9571, Val_cls_acc=0.6931, Val_tag_acc=0.9377\n",
      "Epoch 6: Train_cls_acc=0.9905, Train_tag_acc=0.9652, Val_cls_acc=0.7033, Val_tag_acc=0.9406\n",
      "Epoch 7: Train_cls_acc=0.9919, Train_tag_acc=0.9708, Val_cls_acc=0.6582, Val_tag_acc=0.9440\n",
      "Epoch 8: Train_cls_acc=0.9951, Train_tag_acc=0.9762, Val_cls_acc=0.6941, Val_tag_acc=0.9438\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4757,  Tagging Acc: 0.9268, Overall Acc:0.1978\n",
      "Overall Acc:0.1978, Params: (type_emb_dim: 50, dtype_emb_dim:5)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6761, Train_tag_acc=0.9154, Val_cls_acc=0.6639, Val_tag_acc=0.9221\n",
      "Epoch 2: Train_cls_acc=0.9557, Train_tag_acc=0.9247, Val_cls_acc=0.7008, Val_tag_acc=0.9268\n",
      "Epoch 3: Train_cls_acc=0.9791, Train_tag_acc=0.9358, Val_cls_acc=0.6818, Val_tag_acc=0.9346\n",
      "Epoch 4: Train_cls_acc=0.9857, Train_tag_acc=0.9484, Val_cls_acc=0.6789, Val_tag_acc=0.9419\n",
      "Epoch 5: Train_cls_acc=0.9889, Train_tag_acc=0.9584, Val_cls_acc=0.6808, Val_tag_acc=0.9410\n",
      "Epoch 6: Train_cls_acc=0.9909, Train_tag_acc=0.9667, Val_cls_acc=0.6676, Val_tag_acc=0.9410\n",
      "Epoch 7: Train_cls_acc=0.9936, Train_tag_acc=0.9732, Val_cls_acc=0.6914, Val_tag_acc=0.9404\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4891,  Tagging Acc: 0.9265, Overall Acc:0.2315\n",
      "Overall Acc:0.2315, Params: (type_emb_dim: 50, dtype_emb_dim:10)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6772, Train_tag_acc=0.9154, Val_cls_acc=0.6766, Val_tag_acc=0.9228\n",
      "Epoch 2: Train_cls_acc=0.9540, Train_tag_acc=0.9244, Val_cls_acc=0.6633, Val_tag_acc=0.9300\n",
      "Epoch 3: Train_cls_acc=0.9783, Train_tag_acc=0.9356, Val_cls_acc=0.6916, Val_tag_acc=0.9331\n",
      "Epoch 4: Train_cls_acc=0.9839, Train_tag_acc=0.9467, Val_cls_acc=0.6977, Val_tag_acc=0.9390\n",
      "Epoch 5: Train_cls_acc=0.9864, Train_tag_acc=0.9574, Val_cls_acc=0.7060, Val_tag_acc=0.9385\n",
      "Epoch 6: Train_cls_acc=0.9907, Train_tag_acc=0.9659, Val_cls_acc=0.6789, Val_tag_acc=0.9434\n",
      "Epoch 7: Train_cls_acc=0.9913, Train_tag_acc=0.9722, Val_cls_acc=0.6858, Val_tag_acc=0.9401\n",
      "Epoch 8: Train_cls_acc=0.9926, Train_tag_acc=0.9766, Val_cls_acc=0.6712, Val_tag_acc=0.9428\n",
      "Epoch 9: Train_cls_acc=0.9949, Train_tag_acc=0.9797, Val_cls_acc=0.6701, Val_tag_acc=0.9428\n",
      "Epoch 10: Train_cls_acc=0.9956, Train_tag_acc=0.9822, Val_cls_acc=0.6883, Val_tag_acc=0.9426\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4759,  Tagging Acc: 0.9185, Overall Acc:0.2270\n",
      "Overall Acc:0.2270, Params: (type_emb_dim: 50, dtype_emb_dim:25)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6983, Train_tag_acc=0.9158, Val_cls_acc=0.6295, Val_tag_acc=0.9206\n",
      "Epoch 2: Train_cls_acc=0.9548, Train_tag_acc=0.9239, Val_cls_acc=0.6854, Val_tag_acc=0.9268\n",
      "Epoch 3: Train_cls_acc=0.9758, Train_tag_acc=0.9339, Val_cls_acc=0.6474, Val_tag_acc=0.9342\n",
      "Epoch 4: Train_cls_acc=0.9820, Train_tag_acc=0.9432, Val_cls_acc=0.6789, Val_tag_acc=0.9407\n",
      "Epoch 5: Train_cls_acc=0.9868, Train_tag_acc=0.9531, Val_cls_acc=0.6772, Val_tag_acc=0.9415\n",
      "Epoch 6: Train_cls_acc=0.9889, Train_tag_acc=0.9629, Val_cls_acc=0.6852, Val_tag_acc=0.9480\n",
      "Epoch 7: Train_cls_acc=0.9886, Train_tag_acc=0.9695, Val_cls_acc=0.6824, Val_tag_acc=0.9488\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4692,  Tagging Acc: 0.9210, Overall Acc:0.2169\n",
      "Overall Acc:0.2169, Params: (type_emb_dim: 50, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6985, Train_tag_acc=0.9152, Val_cls_acc=0.6589, Val_tag_acc=0.9215\n",
      "Epoch 2: Train_cls_acc=0.9530, Train_tag_acc=0.9230, Val_cls_acc=0.6679, Val_tag_acc=0.9231\n",
      "Epoch 3: Train_cls_acc=0.9762, Train_tag_acc=0.9307, Val_cls_acc=0.6962, Val_tag_acc=0.9303\n",
      "Epoch 4: Train_cls_acc=0.9819, Train_tag_acc=0.9389, Val_cls_acc=0.6729, Val_tag_acc=0.9340\n",
      "Epoch 5: Train_cls_acc=0.9844, Train_tag_acc=0.9468, Val_cls_acc=0.6758, Val_tag_acc=0.9372\n",
      "Epoch 6: Train_cls_acc=0.9887, Train_tag_acc=0.9559, Val_cls_acc=0.6822, Val_tag_acc=0.9393\n",
      "Epoch 7: Train_cls_acc=0.9908, Train_tag_acc=0.9636, Val_cls_acc=0.6497, Val_tag_acc=0.9433\n",
      "Epoch 8: Train_cls_acc=0.9950, Train_tag_acc=0.9705, Val_cls_acc=0.6681, Val_tag_acc=0.9423\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4811,  Tagging Acc: 0.9245, Overall Acc:0.2055\n",
      "Overall Acc:0.2055, Params: (type_emb_dim: 50, dtype_emb_dim:75)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6850, Train_tag_acc=0.9158, Val_cls_acc=0.6065, Val_tag_acc=0.9186\n",
      "Epoch 2: Train_cls_acc=0.9556, Train_tag_acc=0.9258, Val_cls_acc=0.6674, Val_tag_acc=0.9272\n",
      "Epoch 3: Train_cls_acc=0.9767, Train_tag_acc=0.9362, Val_cls_acc=0.6608, Val_tag_acc=0.9334\n",
      "Epoch 4: Train_cls_acc=0.9833, Train_tag_acc=0.9472, Val_cls_acc=0.6910, Val_tag_acc=0.9379\n",
      "Epoch 5: Train_cls_acc=0.9856, Train_tag_acc=0.9567, Val_cls_acc=0.6939, Val_tag_acc=0.9410\n",
      "Epoch 6: Train_cls_acc=0.9914, Train_tag_acc=0.9661, Val_cls_acc=0.6472, Val_tag_acc=0.9396\n",
      "Epoch 7: Train_cls_acc=0.9925, Train_tag_acc=0.9716, Val_cls_acc=0.7017, Val_tag_acc=0.9443\n",
      "Epoch 8: Train_cls_acc=0.9915, Train_tag_acc=0.9759, Val_cls_acc=0.6558, Val_tag_acc=0.9445\n",
      "Epoch 9: Train_cls_acc=0.9963, Train_tag_acc=0.9802, Val_cls_acc=0.6877, Val_tag_acc=0.9402\n",
      "Epoch 10: Train_cls_acc=0.9922, Train_tag_acc=0.9813, Val_cls_acc=0.6720, Val_tag_acc=0.9432\n",
      "Epoch 11: Train_cls_acc=0.9949, Train_tag_acc=0.9836, Val_cls_acc=0.6777, Val_tag_acc=0.9441\n",
      "Epoch 12: Train_cls_acc=0.9991, Train_tag_acc=0.9865, Val_cls_acc=0.6910, Val_tag_acc=0.9407\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4648,  Tagging Acc: 0.9278, Overall Acc:0.2189\n",
      "Overall Acc:0.2189, Params: (type_emb_dim: 75, dtype_emb_dim:5)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6914, Train_tag_acc=0.9154, Val_cls_acc=0.6551, Val_tag_acc=0.9231\n",
      "Epoch 2: Train_cls_acc=0.9529, Train_tag_acc=0.9251, Val_cls_acc=0.6841, Val_tag_acc=0.9276\n",
      "Epoch 3: Train_cls_acc=0.9765, Train_tag_acc=0.9359, Val_cls_acc=0.6593, Val_tag_acc=0.9329\n",
      "Epoch 4: Train_cls_acc=0.9839, Train_tag_acc=0.9471, Val_cls_acc=0.6824, Val_tag_acc=0.9328\n",
      "Epoch 5: Train_cls_acc=0.9873, Train_tag_acc=0.9562, Val_cls_acc=0.6914, Val_tag_acc=0.9396\n",
      "Epoch 6: Train_cls_acc=0.9889, Train_tag_acc=0.9641, Val_cls_acc=0.6799, Val_tag_acc=0.9426\n",
      "Epoch 7: Train_cls_acc=0.9913, Train_tag_acc=0.9702, Val_cls_acc=0.6706, Val_tag_acc=0.9421\n",
      "Epoch 8: Train_cls_acc=0.9940, Train_tag_acc=0.9750, Val_cls_acc=0.6451, Val_tag_acc=0.9390\n",
      "Epoch 9: Train_cls_acc=0.9944, Train_tag_acc=0.9779, Val_cls_acc=0.6610, Val_tag_acc=0.9432\n",
      "Epoch 10: Train_cls_acc=0.9919, Train_tag_acc=0.9795, Val_cls_acc=0.6566, Val_tag_acc=0.9407\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4677,  Tagging Acc: 0.9326, Overall Acc:0.2273\n",
      "Overall Acc:0.2273, Params: (type_emb_dim: 75, dtype_emb_dim:10)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.6919, Train_tag_acc=0.9157, Val_cls_acc=0.6539, Val_tag_acc=0.9205\n",
      "Epoch 2: Train_cls_acc=0.9541, Train_tag_acc=0.9241, Val_cls_acc=0.6827, Val_tag_acc=0.9249\n",
      "Epoch 3: Train_cls_acc=0.9750, Train_tag_acc=0.9329, Val_cls_acc=0.6847, Val_tag_acc=0.9351\n",
      "Epoch 4: Train_cls_acc=0.9831, Train_tag_acc=0.9433, Val_cls_acc=0.6989, Val_tag_acc=0.9379\n",
      "Epoch 5: Train_cls_acc=0.9872, Train_tag_acc=0.9536, Val_cls_acc=0.6977, Val_tag_acc=0.9409\n",
      "Epoch 6: Train_cls_acc=0.9879, Train_tag_acc=0.9612, Val_cls_acc=0.7019, Val_tag_acc=0.9427\n",
      "Epoch 7: Train_cls_acc=0.9919, Train_tag_acc=0.9692, Val_cls_acc=0.7117, Val_tag_acc=0.9440\n",
      "Epoch 8: Train_cls_acc=0.9917, Train_tag_acc=0.9740, Val_cls_acc=0.6537, Val_tag_acc=0.9449\n",
      "Epoch 9: Train_cls_acc=0.9964, Train_tag_acc=0.9781, Val_cls_acc=0.6944, Val_tag_acc=0.9445\n",
      "Epoch 10: Train_cls_acc=0.9911, Train_tag_acc=0.9794, Val_cls_acc=0.6923, Val_tag_acc=0.9442\n",
      "Epoch 11: Train_cls_acc=0.9989, Train_tag_acc=0.9836, Val_cls_acc=0.6933, Val_tag_acc=0.9450\n",
      "Epoch 12: Train_cls_acc=0.9923, Train_tag_acc=0.9831, Val_cls_acc=0.6666, Val_tag_acc=0.9460\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4677,  Tagging Acc: 0.9258, Overall Acc:0.2290\n",
      "Overall Acc:0.2290, Params: (type_emb_dim: 75, dtype_emb_dim:25)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.7026, Train_tag_acc=0.9150, Val_cls_acc=0.6628, Val_tag_acc=0.9234\n",
      "Epoch 2: Train_cls_acc=0.9542, Train_tag_acc=0.9226, Val_cls_acc=0.6927, Val_tag_acc=0.9250\n",
      "Epoch 3: Train_cls_acc=0.9719, Train_tag_acc=0.9286, Val_cls_acc=0.6835, Val_tag_acc=0.9306\n",
      "Epoch 4: Train_cls_acc=0.9845, Train_tag_acc=0.9364, Val_cls_acc=0.6908, Val_tag_acc=0.9332\n",
      "Epoch 5: Train_cls_acc=0.9839, Train_tag_acc=0.9434, Val_cls_acc=0.6610, Val_tag_acc=0.9340\n",
      "Epoch 6: Train_cls_acc=0.9882, Train_tag_acc=0.9511, Val_cls_acc=0.6635, Val_tag_acc=0.9367\n",
      "Epoch 7: Train_cls_acc=0.9906, Train_tag_acc=0.9581, Val_cls_acc=0.6929, Val_tag_acc=0.9373\n",
      "Epoch 8: Train_cls_acc=0.9910, Train_tag_acc=0.9646, Val_cls_acc=0.6829, Val_tag_acc=0.9407\n",
      "Epoch 9: Train_cls_acc=0.9924, Train_tag_acc=0.9702, Val_cls_acc=0.6745, Val_tag_acc=0.9390\n",
      "Epoch 10: Train_cls_acc=0.9966, Train_tag_acc=0.9750, Val_cls_acc=0.6800, Val_tag_acc=0.9393\n",
      "Epoch 11: Train_cls_acc=0.9924, Train_tag_acc=0.9760, Val_cls_acc=0.6879, Val_tag_acc=0.9401\n",
      "Epoch 12: Train_cls_acc=0.9961, Train_tag_acc=0.9795, Val_cls_acc=0.6877, Val_tag_acc=0.9410\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4864,  Tagging Acc: 0.9225, Overall Acc:0.2072\n",
      "Overall Acc:0.2072, Params: (type_emb_dim: 75, dtype_emb_dim:50)\n",
      "Initialize transformer model...\n",
      "===============Training Model=================\n",
      "Epoch 1: Train_cls_acc=0.7103, Train_tag_acc=0.9158, Val_cls_acc=0.6309, Val_tag_acc=0.9216\n",
      "Epoch 2: Train_cls_acc=0.9543, Train_tag_acc=0.9218, Val_cls_acc=0.6843, Val_tag_acc=0.9243\n",
      "Epoch 3: Train_cls_acc=0.9732, Train_tag_acc=0.9268, Val_cls_acc=0.6921, Val_tag_acc=0.9255\n",
      "Epoch 4: Train_cls_acc=0.9793, Train_tag_acc=0.9320, Val_cls_acc=0.6752, Val_tag_acc=0.9320\n",
      "Epoch 5: Train_cls_acc=0.9845, Train_tag_acc=0.9370, Val_cls_acc=0.6896, Val_tag_acc=0.9323\n",
      "Epoch 6: Train_cls_acc=0.9869, Train_tag_acc=0.9415, Val_cls_acc=0.6968, Val_tag_acc=0.9351\n",
      "Epoch 7: Train_cls_acc=0.9883, Train_tag_acc=0.9461, Val_cls_acc=0.6775, Val_tag_acc=0.9362\n",
      "Epoch 8: Train_cls_acc=0.9912, Train_tag_acc=0.9516, Val_cls_acc=0.6741, Val_tag_acc=0.9343\n",
      "Epoch 9: Train_cls_acc=0.9920, Train_tag_acc=0.9569, Val_cls_acc=0.6931, Val_tag_acc=0.9380\n",
      "Epoch 10: Train_cls_acc=0.9937, Train_tag_acc=0.9624, Val_cls_acc=0.6503, Val_tag_acc=0.9358\n",
      "Epoch 11: Train_cls_acc=0.9946, Train_tag_acc=0.9668, Val_cls_acc=0.6910, Val_tag_acc=0.9387\n",
      "The accuracy of dev set seems not increase for 5 epoches, stop training...\n",
      "===============Testing Model=================\n",
      "Test set transformer —  Classification Acc: 0.4784,  Tagging Acc: 0.9248, Overall Acc:0.1859\n",
      "Overall Acc:0.1859, Params: (type_emb_dim: 75, dtype_emb_dim:75)\n",
      "Best accuracy of transformer - Acc: 0.2327543424317618, params: (type_emb_dim: 25, dtype_emb_dim:5)\n"
     ]
    }
   ],
   "source": [
    "# Note: we use the following hyperparameter tuning method to explore our experiment\n",
    "# We manually setting different dimensions of additional information embedding to observe how these dimensions impact each models performance\n",
    "# And propose the hypothesis why such dimensions can get the best accuracy\n",
    "# In transformer, the input dimension(concatenate by word embedding and additional info embedding) \n",
    "# should be divisible by n_heads, we change the pending options of dimensions to maintain n_head variable\n",
    "test_type_emb_dim = [5, 10, 25, 50, 75]\n",
    "test_dtype_emb_dim = [5, 10, 25, 50, 75]\n",
    "optimal_params = []\n",
    "\n",
    "processor = atisDataProcessor(data_file, type_file, glove_path)\n",
    "acc_list = []\n",
    "params = []\n",
    "for dim1 in test_type_emb_dim:\n",
    "    for dim2 in test_dtype_emb_dim:\n",
    "        model = ClassificationModels(embedding_matrix=processor.embedding_matrix,\n",
    "                               type_vocab_size=len(processor.var2idx),\n",
    "                               dtype_vocab_size=len(processor.dtype2idx),\n",
    "                               type_emb_dim=dim1, dtype_emb_dim=dim2,\n",
    "                               model_type=\"transformer\",\n",
    "                               hidden_dim=128,\n",
    "                               template_classes=processor.template_classes,\n",
    "                               tag_classes=len(processor.name2idx),\n",
    "                               num_layers=1, nhead=5)\n",
    "        print(f\"===============Training Model=================\")\n",
    "        train_model(processor, model, epochs=20, lr=1e-3, patience=5)\n",
    "        print(f\"===============Testing Model=================\")\n",
    "        acc_cls, acc_tag, acc_strict = evaluate_model(processor, model)\n",
    "        print(f\"Test set {model_type} —  Classification Acc: {acc_cls:.4f},  Tagging Acc: {acc_tag:.4f}, Overall Acc:{acc_strict:.4f}\")\n",
    "        print(f\"Overall Acc:{acc_strict:.4f}, Params: (type_emb_dim: {dim1}, dtype_emb_dim:{dim2})\")\n",
    "        acc_list.append(acc_strict)\n",
    "        params.append([dim1, dim2])\n",
    "\n",
    "best_acc = max(acc_list)\n",
    "best_params = params[acc_list.index(best_acc)]\n",
    "print(f\"Best accuracy of {model_type} - Acc: {best_acc}, params: (type_emb_dim: {best_params[0]}, dtype_emb_dim:{best_params[1]})\")\n",
    "optimal_params.append({\"model_type\": model_type, \"type_dim\": best_params[0], \"dtype_param\": best_params[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2189962-9c20-4c5c-bead-f0c412c6f93d",
   "metadata": {},
   "source": [
    "#### Experiment Findings\n",
    "\n",
    "As the word limit of experiment answer, the full version of our experiment findings are shown as follows:\n",
    "\n",
    "From the perspective of the semantic types of the variables, type is essentially the category of a label—in fact, it corresponds to the name of a database—so it carries a wide variety of concrete meanings. Some of these meanings may be similar, and thus require relatively higher-dimensional embeddings to capture subtle distinctions. By contrast, dtype is fundamentally the data type within a database: it is itself a label, albeit not unique. Therefore, in principle it needs only a small number of dimensions to represent its more salient, coarse-grained features. We applied hyperparameter tuning by manually specifying a range of embedding dimensions to test how different dimension combinations affect model performance (the detailed code and its outputs are provided in the accompanying Jupyter notebook). For the transformer in particular, because of the multi-head attention mechanism, each embedding dimension must be divisible by the number of heads.\n",
    "\n",
    "As for the results, since the overall accuracies are relatively low and thus susceptible to random variation, we collected the best-performing configuration for each model:\n",
    "\n",
    "Transformer: Best overall accuracy 0.23275 with (type_emb_dim=25, dtype_emb_dim=5)\n",
    "\n",
    "LSTM: Best overall accuracy 0.27965 with (type_emb_dim=8, dtype_emb_dim=50)\n",
    "\n",
    "Feedforward: Best overall accuracy 0.18015 with (type_emb_dim=16, dtype_emb_dim=50)\n",
    "\n",
    "Linear: Best overall accuracy 0.23573 with (type_emb_dim=64, dtype_emb_dim=8)\n",
    "\n",
    "For the linear, FFN, and LSTM models, we tested dimensions in [8, 16, 32, 50, 64], whereas for the transformer—due to its requirement that dimensions be divisible by the number of heads—we tested [5, 10, 25, 50, 75]. Beyond the optimal points, we observed that transformer and LSTM models tend to perform better at lower embedding dimensions. For example, LSTM’s runner-up configurations were (8,32), (16,8), and (32,16), and for a fixed type_emb_dim, transformer’s accuracy decreased as dtype_emb_dim increased—consistent with our semantic analysis.\n",
    "\n",
    "For the feedforward network, besides the best configuration, strong performances also appeared at (32,32), (64,50), (16,32), and (16,50). Since the FFN has only a single hidden layer, it requires more complex embeddings to learn the input features effectively.\n",
    "\n",
    "For the linear model, runner-up configurations included (32,8), (8,32), and (64,32). Because the linear model relies solely on the linear separability of the concatenated inputs, these combinations further confirm that type and dtype act as peer label types with similar representational capacity. Both FFN and linear models thus benefit from higher-dimensional embeddings to achieve better performance.\n",
    "\n",
    "All of these findings align well with our semantic reasoning: transformer and LSTM models—with self-attention and hidden-state mechanisms that learn token-level features—require smaller dimensions to avoid noise and overfitting, whereas feedforward and linear models—whose context-capture abilities are weaker (single-layer FFN) or purely linear—need higher-dimensional embeddings to distinguish semantic types effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a91db-82d1-46b6-a462-3d1fd40a6a74",
   "metadata": {},
   "source": [
    "#### Transformer Model Performance\n",
    "\n",
    "| type\\_emb\\_dim | dtype\\_emb\\_dim | Overall Acc |\n",
    "| -------------- | --------------- | ----------- |\n",
    "| 5              | 5               | 0.2179      |\n",
    "| 5              | 10              | 0.1715      |\n",
    "| 5              | 25              | 0.1945      |\n",
    "| 5              | 50              | 0.2164      |\n",
    "| 5              | 75              | 0.1829      |\n",
    "| 10             | 5               | 0.2248      |\n",
    "| 10             | 10              | 0.2308      |\n",
    "| 10             | 25              | 0.2079      |\n",
    "| 10             | 50              | 0.1787      |\n",
    "| 10             | 75              | 0.1859      |\n",
    "| 25             | 5               | **0.2328**  |\n",
    "| 25             | 10              | 0.1945      |\n",
    "| 25             | 25              | 0.2164      |\n",
    "| 25             | 50              | 0.2079      |\n",
    "| 25             | 75              | 0.2328      |\n",
    "| 50             | 5               | 0.1978      |\n",
    "| 50             | 10              | 0.2290      |\n",
    "| 50             | 25              | 0.2072      |\n",
    "| 50             | 50              | 0.1859      |\n",
    "| 50             | 75              | 0.2189      |\n",
    "| 75             | 5               | 0.2328      |\n",
    "| 75             | 10              | 0.2273      |\n",
    "| 75             | 25              | 0.1978      |\n",
    "| 75             | 50              | 0.2315      |\n",
    "| 75             | 75              | 0.2189      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59914b28-6074-41d3-b91c-fc45347b7887",
   "metadata": {},
   "source": [
    "#### LSTM Model Performance\n",
    "\n",
    "| type\\_emb\\_dim | dtype\\_emb\\_dim | Overall Acc |\n",
    "| -------------- | --------------- | ----------- |\n",
    "| 8              | 8               | 0.2380      |\n",
    "| 8              | 16              | 0.2675      |\n",
    "| 8              | 32              | 0.2707      |\n",
    "| 8              | 50              | **0.2797**  |\n",
    "| 8              | 64              | 0.2454      |\n",
    "| 16             | 8               | 0.2707      |\n",
    "| 16             | 16              | 0.2675      |\n",
    "| 16             | 32              | 0.2481      |\n",
    "| 16             | 50              | 0.2670      |\n",
    "| 16             | 64              | 0.2481      |\n",
    "| 32             | 8               | 0.2412      |\n",
    "| 32             | 16              | 0.2670      |\n",
    "| 32             | 32              | 0.2561      |\n",
    "| 32             | 50              | 0.2328      |\n",
    "| 32             | 64              | 0.2561      |\n",
    "| 50             | 8               | 0.2506      |\n",
    "| 50             | 16              | 0.2670      |\n",
    "| 50             | 32              | 0.2538      |\n",
    "| 50             | 50              | 0.2538      |\n",
    "| 50             | 64              | 0.2417      |\n",
    "| 64             | 8               | 0.2581      |\n",
    "| 64             | 16              | 0.2144      |\n",
    "| 64             | 32              | 0.2670      |\n",
    "| 64             | 50              | 0.2581      |\n",
    "| 64             | 64              | 0.2412      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e92a47-dc29-4350-b87b-94bf47200281",
   "metadata": {},
   "source": [
    "#### FeedForward Model Performance\n",
    "\n",
    "| type\\_emb\\_dim | dtype\\_emb\\_dim | Overall Acc |\n",
    "| -------------- | --------------- | ----------- |\n",
    "| 8              | 8               | 0.1801      |\n",
    "| 8              | 16              | 0.2380      |\n",
    "| 8              | 32              | 0.2707      |\n",
    "| 8              | 50              | **0.2797**  |\n",
    "| 8              | 64              | 0.2454      |\n",
    "| 16             | 8               | 0.2481      |\n",
    "| 16             | 16              | 0.2675      |\n",
    "| 16             | 32              | 0.2454      |\n",
    "| 16             | 50              | 0.2670      |\n",
    "| 16             | 64              | 0.2481      |\n",
    "| 32             | 8               | 0.2412      |\n",
    "| 32             | 16              | 0.2707      |\n",
    "| 32             | 32              | 0.2670      |\n",
    "| 32             | 50              | 0.2538      |\n",
    "| 32             | 64              | 0.2561      |\n",
    "| 50             | 8               | 0.2670      |\n",
    "| 50             | 16              | 0.2300      |\n",
    "| 50             | 32              | 0.2670      |\n",
    "| 50             | 50              | 0.2300      |\n",
    "| 50             | 64              | 0.2328      |\n",
    "| 64             | 8               | 0.2581      |\n",
    "| 64             | 16              | 0.2144      |\n",
    "| 64             | 32              | 0.2670      |\n",
    "| 64             | 50              | 0.2581      |\n",
    "| 64             | 64              | 0.2412      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b791ee8-f19d-45be-aa3d-47fcafbe6692",
   "metadata": {},
   "source": [
    "## Linear Model Performance\n",
    "\n",
    "| type_emb_dim | dtype_emb_dim | Overall Acc |\n",
    "|--------------|---------------|-------------|\n",
    "| 8            | 8             | 0.2357      |\n",
    "| 8            | 16            | 0.2380      |\n",
    "| 8            | 32            | 0.2675      |\n",
    "| 8            | 50            | 0.2707      |\n",
    "| 8            | 64            | 0.2454      |\n",
    "| 16           | 8             | 0.2707      |\n",
    "| 16           | 16            | 0.2675      |\n",
    "| 16           | 32            | 0.2481      |\n",
    "| 16           | 50            | 0.2670      |\n",
    "| 16           | 64            | 0.2481      |\n",
    "| 32           | 8             | 0.2412      |\n",
    "| 32           | 16            | 0.2670      |\n",
    "| 32           | 32            | 0.2561      |\n",
    "| 32           | 50            | 0.2328      |\n",
    "| 32           | 64            | 0.2561      |\n",
    "| 50           | 8             | 0.2357  |\n",
    "| 50           | 16            | 0.2670      |\n",
    "| 50           | 32            | 0.2538      |\n",
    "| 50           | 50            | 0.2454      |\n",
    "| 50           | 64            | 0.2417      |\n",
    "| 64           | 8             | 0.2581      |\n",
    "| 64           | 16            | 0.2144      |\n",
    "| 64           | 32            | 0.2670      |\n",
    "| 64           | 50            | 0.2581      |\n",
    "| 64           | 64            | 0.2412      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b45e06-8c9a-404c-86e5-bab42745ae7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLPCodingTest]",
   "language": "python",
   "name": "conda-env-NLPCodingTest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
